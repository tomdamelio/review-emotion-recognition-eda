paper_id,model_id,doi,apa_citation,n,n_female,mean_age,median_age,range_age,country,revisor,comentarios
1,1,,"Zangróniz, R., Martínez-Rodrigo, A., Pastor, J. M., López, M. T., & Fernández-Caballero, A. (2017). Electrodermal Activity Sensor for Classification of Calm/Distress Condition. Sensors (Basel, Switzerland), 17(10), E2324. https://doi.org/10.3390/s17102324
",45,20,-,-,-,Spain,,
2,1,,"Liu, M., Fan, D., Zhang, X., & Gong, X. (2017). Human Emotion Recognition Based on Galvanic Skin Response Signal Feature Selection and SVM. 157–160. Scopus. https://doi.org/10.1109/ICSCSE.2016.0051
",-,-,-,-,-,China,,
3,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. E. (2018). Emotion Based Music Recommendation System Using Wearable Physiological Sensors. IEEE Transactions on Consumer Electronics, 64(2), 196–203. Scopus. https://doi.org/10.1109/TCE.2018.2844736
",32,16,26.9,-,19-37,,,
4,1,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061905",27,16,26.06,-,19-40,-,,
5,1,,"Wei, J., Chen, T., Liu, G., & Yang, J. (2016). Higher-order Multivariable Polynomial Regression to Estimate Human Affective States. Scientific Reports, 6, 23384. https://doi.org/10.1038/srep23384",27,27,19.44,-,18-22,-,,
6,1,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",121,,,,2025-01-03 00:00:00,USA,,
7,1,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",15,3,27.5,-,-,Germany,,
8,1,,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",6,-,-,-,-,-,,
9,1,,"Amalan, S., Shyam, A., Anusha, A. S., Preejith, S. P., Tony, A., Jayaraj, J., & Mohanasankar, S. (2018). Electrodermal Activity based Classification of Induced Stress in a Controlled Setting. MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings. Scopus. https://doi.org/10.1109/MeMeA.2018.8438703",30,9,,,21-30,India,,
10,1,,"Machot, F. A., Ali, M., Ranasinghe, S., Mosa, A. H., & Kyandoghere, K. (2018). Improving subject-independent human emotion recognition using electrodermal activity sensors for active and assisted living. 222–228. Scopus. https://doi.org/10.1145/3197768.3201523",27,16,26.06,-,19-40,-,,
11,1,,"Girardi, D., Lanubile, F., & Novielli, N. (2018). Emotion detection using noninvasive low cost sensors. 2018-January, 125–130. Scopus. https://doi.org/10.1109/ACII.2017.8273589",19,3,-,-,20-40,-,,
12,1,,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",20,-,22.83,-,19-30,Malasya,,
13,1,,"Setyohadi, D. B., Kusrohmaniah, S., Gunawan, S. B., Pranowo, & Prabuwono, A. S. (2018). Galvanic skin response data classification for emotion detection. International Journal of Electrical and Computer Engineering, 8(5), 4004–4014. Scopus. https://doi.org/10.11591/ijece.v8i5.pp4004-4014",39,-,-,-,-,Indonesia,,
14,1,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",52,33,25.7,-,-,-,,
15,1,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",25,-,23.92,-,21-39,Malasya,,
16,1,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion sensing from physiological signals using three defined areas in arousal-valence model. 219–223. Scopus. https://doi.org/10.1109/CADIAG.2017.8075660",27,16,26.06,-,19-40,-,,
17,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",35,14,-,-,21-25,Iran,,
18,1,,"Keren, G., Kirschstein, T., Marchi, E., Ringeval, F., & Schuller, B. (2017). End-to-end learning for dimensional emotion recognition from physiological signals. 985–990. Scopus. https://doi.org/10.1109/ICME.2017.8019533",46,27,22,-,-,-,,
19,1,,"Hernández-García, A., Fernández-Martínez, F., & Díaz-De-maría, F. (2017). Emotion and attention: Predicting electrodermal activity through video visual descriptors. 914–923. Scopus. https://doi.org/10.1145/3106426.3109418",22,12,-,-,21-59,-,,
20,1,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion assessing using valence-arousal evaluation based on peripheral physiological signals and support vector machine. 4th International Conference on Control Engineering and Information Technology, CEIT 2016. Scopus. https://doi.org/10.1109/CEIT.2016.7929117",27,16,26.06,-,19-40,-,,
21,1,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",8,-,-,-,-,-,,
22,1,,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",19,-,-,-,23-36,Malasya,,
23,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via random forest and galvanic skin response: Comparison of time based feature sets, window sizes and wavelet approaches. 2016 Medical Technologies National Conference, TIPTEKNO 2016. Scopus. https://doi.org/10.1109/TIPTEKNO.2016.7863130",32,16,26.9,-,19-37,,,
24,1,,"Greco, A., Valenza, G., Citi, L., & Scilingo, E. P. (2017). Arousal and valence recognition of affective sounds based on electrodermal activity. IEEE Sensors Journal, 17(3), 716–725. Scopus. https://doi.org/10.1109/JSEN.2016.2623677",25,-,-,-,25-35,-,,
25,1,,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",23,15,-,-,23-36,Malasya,,
26,1,,"Zhang, Q., Lai, X., & Liu, G. (2016). Emotion recognition of GSR based on an improved quantum neural network. 1, 488–492. Scopus. https://doi.org/10.1109/IHMSC.2016.66",35,-,-,-,18-22,China,,
27,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",11,11,22.73,-,-,Iran,,
28,1,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",-,,,,,,,
29,1,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",33,12,29.7,-,-,Canada,,
30,1,,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",20,4,22.83,-,-,Malasya,,
31,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",11,11,22.73,-,-,Iran,,
32,1,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",40,13,28.3,-,-,-,,
33,1,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",11,11,22.73,-,-,-,,
34,1,,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516647",10,6,-,-,-,-,,
35,1,,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",27,16,26.06,-,19-40,-,,
36,1,,"Zhang, S., Liu, G., & Lai, X. (2015). Classification of evoked emotions using an artificial neural network based on single, short-term physiological signals. Journal of Advanced Computational Intelligence and Intelligent Informatics, 19(1), 118-126.",255,117,22.1,-,19-25,China,,
37,1,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",58,21,30,-,-,-,,
37,2,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",32,16,26.9,-,19-37,,,
37,3,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",10,7,35.6,-,23-57,-,,
37,4,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",27,16,26.06,-,19-40,-,,
37,5,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",40,13,28.3,-,-,-,,
38,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",32,16,26.9,-,19-37,,,
39,1,,"Martínez-Rodrigo, A., Zangróniz, R., Pastor, J. M., & Sokolova, M. V. (2017). Arousal level classification of the aging adult from electro-dermal activity: From hardware development to software architecture. Pervasive and Mobile Computing, 34, 46–59. Scopus. https://doi.org/10.1016/j.pmcj.2016.04.006",21,12,-,-,-,-,,
40,1,,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",-,-,-,-,-,-,,
41,1,,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",46,27,22,-,-,-,,
42,1,,"Kostoulas, T., Chanel, G., Muszynski, M., Lombardo, P., & Pun, T. (2017). Films, affective computing and aesthetic experience: Identifying emotional and aesthetic highlights from multimodal signals in a social setting. Frontiers in ICT, 4(JUN). Scopus. https://doi.org/10.3389/fict.2017.00011",13,11,36.1,,22-45,French,,
43,1,,"Barral, O., Kosunen, I., & Jacucci, G. (2017). No need to laugh out loud: Predicting humor appraisal of comic strips based on physiological signals in a realistic environment. ACM Transactions on Computer-Human Interaction, 24(6). Scopus. https://doi.org/10.1145/3157730",25,12,26.3,25,20-35,Finland,,
44,1,,"Lanatà, A., Valenza, G., & Scilingo, E. P. (2012). A novel EDA glove based on textile-integrated electrodes for affective computing. Medical & Biological Engineering & Computing, 50(11), 1163–1172. doi:10.1007/s11517-012-0921-9",35,-,-,-,21-24,-,,
45,1,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",42,19,27.5,-,20-50,-,,
46,1,,"GOUIZI, K., BEREKSI REGUIG, F., & MAAOUI, C. (2011). Emotion recognition from physiological signals. Journal of Medical Engineering & Technology, 35(6-7), 300–307. doi:10.3109/03091902.2011.601784",4,2,-,-,25-28,-,,
47,1,,"Bornoiu, I.-V., Strungaru, R., & Grigore, O. (2015). Intelligent System for Emotion Recognition Based on Electrodermal Activity Processing. 6th European Conference of the International Federation for Medical and Biological Engineering, 70–73. doi:10.1007/978-3-319-11128-5_18 ",-,-,-,-,25-65,-,,
48,1,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",31,18,30.8,-,21-38,-,,
49,1,,"Drungilas, D., Bielskis, A. A., & Denisov, V. (2010). An intelligent control system based on non-invasive man machine interaction. In Innovations in Computing Sciences and Software Engineering (pp. 63-68). Springer, Dordrecht.",-,-,-,-,-,-,,
50,1,,"Wu, G., Liu, G., & Hao, M. (2010). The Analysis of Emotion Recognition from GSR Based on PSO. 2010 International Symposium on Intelligence Information Processing and Trusted Computing. doi:10.1109/iptc.2010.60",254,-,-,-,-,-,,
51,1,,"Giakoumis, D., Tzovaras, D., Moustakas, K., & Hassapis, G. (2011). Automatic Recognition of Boredom in Video Games Using Novel Biosignal Moment-Based Features. IEEE Transactions on Affective Computing, 2(3), 119–133. doi:10.1109/t-affc.2011.4 ",19,4,-,-,23-44,-,,
52,1,,"Safta, I., Grigore, O., & Căruntu, C.(2011). Emotion Detection Using Psycho-Physiological Signal Processing. Computer, 3, 4.",13,-,-,-,20-25,-,,
53,1,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",30,-,-,-,-,-,,
54,1,,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",-,-,20,-,-,-,,
55,1,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",30,16,26.8,-,24-34,-,,
56,1,,"Guo, R., Li, S., He, L., Gao, W., Qi, H., & Owens, G. (2013, May). Pervasive and unobtrusive emotion sensing for human mental health. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops (pp. 436-439). IEEE.",4,-,-,-,-,-,,
57,1,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",26,-,21,-,19-24,-,,
57,2,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",13,5,-,-,-,-,,
58,1,,"Li, S., Guo, R., He, L., Gao, W., Qi, H., & Owens, G. (2014). MoodMagician. Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems - SenSys ’14. doi:10.1145/2668332.2668371",4,-,-,-,-,-,,
59,1,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",27,16,26.06,-,19-40,-,,
60,1,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",32,16,26.9,-,19-37,,,
60,2,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",27,16,26.06,-,19-40,-,,
61,1,,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",28,15,23.62,,20-34,Korea,,
62,1,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",32,-,-,-,-,-,,
63,1,,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",32,16,26.9,-,19-37,,,
64,1,,"Dar, M. N., Akram, M. U., Khawaja, S. G., & Pujari, A. N. (2020). Cnn and lstm-based emotion charting using physiological signals. Sensors, 20(16), 4551.",40,13,28.3,-,-,-,,
65,1,,"Greco, A., Marzi, C., Lanata, A., Scilingo, E. P., & Vanello, N. (2019, July). Combining electrodermal activity and speech analysis towards a more accurate emotion recognition system. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 229-232). IEEE.",18,12,,,,Italy,,
66,1,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",32,16,26.9,-,19-37,,,
67,1,,"Lee, S., Lee, T., Yang, T., Yoon, C., & Kim, S. P. (2020). Detection of drivers’ anxiety invoked by driving situations using multimodal biosignals. Processes, 8(2), 155.",31,15,23.26,-,-,-,,
68,1,,"García-Faura, Á., Hernández-García, A., Fernández-Martínez, F., Díaz-de-María, F., & San-Segundo, R. (2019, January). Emotion and attention: Audiovisual models for group-level skin response recognition in short movies. In Web Intelligence (Vol. 17, No. 1, pp. 29-40). IOS Press.",-,-,23.11,-,17-60,-,,
69,1,,"Wei, W., Jia, Q., Feng, Y., & Chen, G. (2018). Emotion recognition based on weighted fusion strategy of multichannel physiological signals. Computational intelligence and neuroscience, 2018.",27,16,26.06,-,19-40,-,,
70,1,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",32,16,26.9,-,19-37,,,
71,1,,"Tung, K., Liu, P. K., Chuang, Y. C., Wang, S. H., & Wu, A. Y. A. (2018, December). Entropy-assisted multi-modal emotion recognition framework based on physiological signals. In 2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 22-26). IEEE.",40,13,28.3,-,-,-,,
72,1,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",-,-,-,-,-,-,,
73,1,,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",100,45,20,,,,,
74,1,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",40,13,28.3,-,-,-,,
75,1,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",162,76,23.21,,18-29,,,
76,1,,"Thammasan, N., Hagad, J. L., Fukui, K. I., & Numao, M. (2017, October). Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals. In 2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) (pp. 44-49). IEEE.",9,1,27.96,,22-32,,,
77,1,,"Pinto, G., Carvalho, J. M., Barros, F., Soares, S. C., Pinho, A. J., & Brás, S. (2020). Multimodal emotion evaluation: A physiological model for cost-effective emotion classification. Sensors, 20(12), 3510.",55,37,21,,18-28,,,
78,1,,"Raheel, A., Majid, M., Alnowami, M., & Anwar, S. M. (2020). Physiological sensors based emotion recognition while experiencing tactile enhanced multimedia. Sensors, 20(14), 4037.",21,10,21.1,,,,,
79,1,,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",10,4,,,19-25,,,
80,1,,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",457,236,-,-,-,-,,
81,1,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",30,12,,,20-26,,,
82,1,,"Santamaria-Granados, L., Munoz-Organero, M., Ramirez-Gonzalez, G., Abdulhay, E., & Arunkumar, N. J. I. A. (2018). Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMIGOS). IEEE Access, 7, 57-67.",40,13,28.3,-,-,-,,
83,1,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",21,,,,20-36,,,
84,1,,"Liapis, A., Katsanos, C., Karousos, N., Xenos, M., & Orphanoudakis, T. (2019, September). UDSP+ stress detection based on user-reported emotional ratings and wearable skin conductance sensor. In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers (pp. 125-128).",24,10,32.3,-,18-45,,,
85,1,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",860,,,,,,,
86,1,,"Ganapathy, N., & Swaminathan, R. (2020). Emotion Analysis Using Electrodermal Signals and Spiking Deep Belief Network. In Digital Personalized Health and Medicine (pp. 1269-1270). IOS Press.",32,16,26.9,-,19-37,,,
87,1,,"Yasemin, M., Sarıkaya, M. A., & Ince, G. (2019, July). Emotional state estimation using sensor fusion of EEG and EDA. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 5609-5612). IEEE.",10,5,,,21-28,,,
88,1,,"Ghiasi, S., Greco, A., Barbieri, R., Scilingo, E. P., & Valenza, G. (2020). Assessing autonomic function from electrodermal activity and heart rate variability during cold-pressor test and emotional challenge. Scientific reports, 10(1), 1-13.",26,8,26,,21-38,,,
89,1,,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",15,10,21.4,,20-23,,,
90,1,,"Katada, S., Okada, S., Hirano, Y., & Komatani, K. (2020, October). Is She Truly Enjoying the Conversation? Analysis of Physiological Signals toward Adaptive Dialogue Systems. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 315-323).",-,-,-,-,-,-,,
91,1,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",457,236,-,-,-,-,,
92,1,,"Rahman, J. S., Hossain, M. Z., & Gedeon, T. (2019, December). Measuring Observers' EDA Responses to Emotional Videos. In Proceedings of the 31st Australian Conference on Human-Computer-Interaction (pp. 457-461).",20,14,23,-,-,-,,
93,1,,"Rahim, A., Sagheer, A., Nadeem, K., Dar, M. N., Rahim, A., & Akram, U. (2019, October). Emotion Charting Using Real-time Monitoring of Physiological Signals. In 2019 International Conference on Robotics and Automation in Industry (ICRAI) (pp. 1-5). IEEE.",40,13,28.3,-,-,-,,
94,1,,"Yin, G., Sun, S., Zhang, H., Yu, D., Li, C., Zhang, K., & Zou, N. (2019, September). User Independent Emotion Recognition with Residual Signal-Image Network. In 2019 IEEE International Conference on Image Processing (ICIP) (pp. 3277-3281). IEEE.",457,236,-,-,-,-,,
95,1,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",40,13,28.3,-,-,-,,
96,1,,"Kołodziej, M., Tarnowski, P., Majkowski, A., & Rak, R. J. (2019). Electrodermal activity measurements for detection of emotional arousal. Bulletin of the Polish Academy of Sciences. Technical Sciences, 67(4).",22,,20,,,Poland,,
97,1,,"Ganapathy, N., & Swaminathan, R. (2019). Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolution Neural Network. Studies in health technology and informatics, 258, 140-140.",32,16,26.9,-,19-37,,,
98,1,,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",58,21,30,-,-,-,,
99,1,,"Yun, H., Fortenbacher, A., Helbig, R., & Pinkwart, N. (2019). In Search of Learning Indicators: A Study on Sensor Data and IAPS Emotional Pictures. In CSEDU (2) (pp. 111-121).",27,,,,,,,
100,1,10.1016/j.trf.2024.12.031,"Kim, T., Kim, S., Lee, M., Kang, Y., & Hwang, S. (2025). Assessing human emotional experience in pedestrian environments using wearable sensing and machine learning with anomaly detection. Transportation Research Part F: Traffic Psychology and Behaviour, 109, 540-555.",40,31,,-,-,South Korea,Tomi,
101,1,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",30,15,27.15,-,22-37,Germany,Tomi,
102,1,10.1109/TVCG.2024.3372101,"Li, M., Pan, J., Li, Y., Gao, Y., Qin, H., & Shen, Y. (2024). Multimodal physiological analysis of impact of emotion on cognitive control in VR. IEEE Transactions on Visualization and Computer Graphics.",26,12,31.2,-,21-45,-,Tomi,
103,1,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",32,16,26.9,-,19-37,-,Tomi,
104,1,10.1109/JSEN.2024.3354553,"Veeranki, Y. R., Mercado Diaz, L. R., Swaminathan, R., & Posada-Quintero, H. F. (2024). Nonlinear Signal Processing Methods for Automatic Emotion Recognition Using Electrodermal Activity. IEEE Sensors Journal, 24(6), 3354553.",30,15,27.15,-,22-37,Germany,Tomi,
105,1,10.1109/ACII55700.2022.9953862,"Surely, A., Taherzadeh, S., Misal, V., & Kleinsmith, A. (2022, October). Exploring Affective Dimension Perception from Bodily Expressions and Electrodermal Activity in Paramedic Simulation Training. In 2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",11,3,,-,-,US,Tomi,
106,1,10.1038/s41597-024-03676-4,"Yang, P., Liu, N., Liu, X., Shu, Y., Ji, W., Ren, Z., ... & Liu, Y. J. (2024). A Multimodal Dataset for Mixed Emotion Recognition. Scientific Data, 11(1), 847.",80,48,23.06,-,18-35,China,Tomi,
107,1,10.1515/cdbme-2021-2220,"Rao Veeranki, Y., Ganapathy, N., & Swaminathan, R. (2021). Electrodermal activity based emotion recognition using time-frequency methods and machine learning algorithms. Current Directions in Biomedical Engineering, 7(2), 863-866.",32,16,26.9,-,19-37,-,Tomi,
108,1,10.1109/ICCCMLA58983.2023.10346619,"Ronickom, J. F. A. (2023, October). Enhancing emotion recognition: Machine learning with phasic spectrogram texture features. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 600-603). IEEE.",30,15,27.15,-,22-37,Germany,Tomi,
109,1,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",40,13,28.3,-,21 – 40,-,Tomi,
109,2,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",32,12,23.8,-,19–36,South Korea,Tomi,
110,1,10.1109/TIPTEKNO56568.2022.9960200,"Semerci, Y. C., Akgün, G., Toprak, E., & Barkana, D. E. (2022, October). A comparative analysis of deep learning methods for emotion recognition using physiological signals for robot-based intervention studies. In 2022 Medical Technologies Congress (TIPTEKNO) (pp. 1-4). IEEE.",15,10,21.4,-,20-23,-,Tomi,
111,1,10.34107/YHPN9422.04322,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2021). Differentiation of dichotomous emotional states in electrodermal activity signals using higher-order crossing features and parametric classifiers. Biomed. Sci. Instr, 57(2), 322-332.",40,13,28.3,-,21 – 40,-,Tomi,
112,1,10.1149/10701.12535ecst,"Dutta, S., Mishra, B. K., Mitra, A., & Chakraborty, A. (2022). An analysis of emotion recognition based on GSR signal. ECS Transactions, 107(1), 12535.",58,21,30,-,-,-,Tomi,
113,1,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",58,21,30,-,-,-,Tomi,
114,1,10.1088/1742-6596/1878/1/012020,"Bulagang, A. F., Mountstephens, J., & Teo, J. (2021, May). Support Vector Machine Tuning for Improving Four-Quadrant Emotion Prediction in Virtual Reality (VR) using Wearable Electrodermography (EDG). In Journal of Physics: Conference Series (Vol. 1878, No. 1, p. 012020). IOP Publishing.",10,1,,-,20-28,-,Tomi,
115,1,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",40,13,28.3,-,21 – 40,-,Tomi,
115,2,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",58,21,30,-,-,-,Tomi,
116,1,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",32,16,26.9,-,19-37,-,Tomi,
117,1,10.1016/j.teler.2024.100131,"Saffaryazdi, N., Kirkcaldy, N., Lee, G., Loveys, K., Broadbent, E., & Billinghurst, M. (2024). Exploring the impact of computer-mediated emotional interactions on human facial and physiological responses. Telematics and Informatics Reports, 14, 100131.",15,7,28.6,-,21-36,-,Tomi,
118,1,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",25,-,23.92,-,21-39,Malaysia,Tomi,
119,1,10.1109/ACCESS.2024.3361832,"Veeranki, Y. R., Ganapathy, N., Swaminathan, R., & Posada-Quintero, H. F. (2024). Comparison of electrodermal activity signal decomposition techniques for emotion recognition. IEEE Access, 12, 19952-19966.",32,16,26.9,-,19-37,-,Tomi,
120,1,10.1109/ACIIW52867.2021.9666360,"Bhatti, A., Behinaein, B., Rodenburg, D., Hungler, P., & Etemad, A. (2021, September). Attentive cross-modal connections for deep multimodal wearable-based emotion recognition. In 2021 9th international conference on affective computing and intelligent interaction workshops and demos (ACIIW) (pp. 01-05). IEEE.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
121,1,10.3389/fpsyg.2022.895929,"Chong, D., Yu, A., Su, H., & Zhou, Y. (2022). The impact of emotional states on construction workers’ recognition ability of safety hazards based on social cognitive neuroscience. Frontiers in psychology, 13, 895929.",40,0,,-,,-,Tomi,
122,1,10.1145/3534615,"Gupta, K., Chan, S. W., Pai, Y. S., Strachan, N., Su, J., Sumich, A., ... & Billinghurst, M. (2022). Total vrecall: Using biosignals to recognize emotional autobiographical memory in virtual reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 6(2), 1-21.",20,8,27,-,20-36,-,Tomi,
123,1,10.3233/shti240569,"Banik, S., Kumar, H., Ganapathy, N., & Swaminathan, R. (2024). Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers. In Digital Health and Informatics Innovations for Sustainable Health Care Systems (pp. 953-957). IOS Press.",32,16,26.9,-,19-37,-,Tomi,
124,1,10.3389/fnins.2023.1180407,"Wang, K., Zhao, Z., Shen, X., & Yamauchi, T. (2023). Video elicited physiological signal dataset considering indoor temperature factors. Frontiers in Neuroscience, 17, 1180407.",25,-,,-,-,-,Tomi,
125,1,10.1109/JBHI.2022.3225330,"Zitouni, M. S., Park, C. Y., Lee, U., Hadjileontiadis, L. J., & Khandoker, A. (2022). LSTM-modeling of emotion recognition using peripheral physiological signals in naturalistic conversations. IEEE Journal of Biomedical and Health Informatics, 27(2), 912-923.",32,12,23.8,-,19–36,South Korea,Tomi,
126,1,10.1109/ACII52823.2021.9597451,"Khan, A., Hopkins, J., & Gunes, H. (2021, September). Multi-dimensional Affect in Poetry (POCA) Dataset: Acquisition, Annotation and Baseline Results. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",30,14,,-,19-34,UK,Tomi,
127,1,10.1515/cdbme-2023-1139,"Anthiyur Aravindan, A., Kalyan Chappidi, S., Thumma, A., & Palanisamy, R. (2023, September). Prediction of arousal and valence state from electrodermal activity using wavelet based resnet50 model. In Current Directions in Biomedical Engineering (Vol. 9, No. 1, pp. 555-558). De Gruyter.",30,15,27.15,-,22-37,Germany,Tomi,
128,1,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",40,20,22.3,-,20-25,,Tomi,
129,1,10.1007/s10916-020-01676-6,"Ganapathy, N., Veeranki, Y. R., Kumar, H., & Swaminathan, R. (2021). Emotion recognition using electrodermal activity signals and multiscale deep convolutional neural network. Journal of Medical Systems, 45(4), 49.",32,16,26.9,-,19-37,-,Tomi,
130,1,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",30,15,27.15,-,22-37,Germany,Tomi,
130,2,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
131,1,10.14236/ewic/HCI2022.19,"Pidgeon, M., Kanwal, N., Murray, N., & Asghar, M. (2022, July). End-to-End Emotion Recognition using Peripheral Physiological Signals. In 35th International BCS Human-Computer Interaction Conference (pp. 1-10). BCS Learning & Development.",32,16,26.9,-,19-37,-,Tomi,
132,1,10.1109/AIHCIR61661.2023.00066,"He, Y., Chen, L., Zhao, Q., Hong, Z., & Chen, Y. (2023, December). MEDA-CBLSTM: Data Acquisition, Processing and Emotion Recognition Based on Multi-Layer EDA. In 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) (pp. 380-384). IEEE.",5,-,5,-,20-30,-,Tomi,
133,1,10.3390/electronics12132795,"Dessai, A., & Virani, H. (2023). Emotion classification based on CWT of ECG and GSR signals using various CNN models. Electronics, 12(13), 2795.",40,13,28.3,-,21 – 40,-,Tomi,
134,1,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",30,15,27.15,-,22-37,Germany,Tomi,
135,1,10.1016/j.bspc.2024.106353,"Gahlan, N., & Sethia, D. (2024). AFLEMP: Attention-based federated learning for emotion recognition using multi-modal physiological data. Biomedical Signal Processing and Control, 94, 106353.",40,13,28.3,-,21 – 40,-,Tomi,
136,1,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",30,15,27.15,-,22-37,Germany,Tomi,
137,1,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
137,2,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",62,17,-,-,20 – 50,-,Tomi,
138,1,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",40,13,28.3,-,21 – 40,-,Tomi,
138,2,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",58,21,30,-,-,-,Tomi,
138,3,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",27,17,26.06,-,19-40 ,United Kingdom​​,Tomi,
138,4,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",62,17,-,-,20 – 50,-,Tomi,
139,1,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",80,6,20,-,-,-,Tomi,
140,1,10.1109/ACII52823.2021.9597434,"Di Lascio, E., Gashi, S., Debus, M. E., & Santini, S. (2021, September). Automatic recognition of flow during work activities using context and physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",13,4,,-,20-40,-,Tomi,
141,1,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",10,5,,-,-,-,Tomi,
142,1,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",32,16,26.9,-,19-37,-,Tomi,
142,2,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",24,16,24,23,-,China,Tomi,
143,1,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",32,16,26.9,-,19-37,-,Tomi,
143,2,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",90,45,-,-,18–65 ​,Germany,Tomi,
143,3,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",33,-,-,-,-,Italy,Tomi,
144,1,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",40,13,28.3,-,21 – 40,-,Tomi,
145,1,10.1109/ICC45041.2023.10278603,"Zhu, L., Spachos, P., & Gregori, S. (2023, May). Electrodermal activity for emotion recognition using cnn and bi-gru model. In ICC 2023-IEEE International Conference on Communications (pp. 5533-5538). IEEE.",40,13,28.3,-,21 – 40,-,Tomi,
146,1,10.1007/s11042-022-12711-8,"Katada, S., & Okada, S. (2022). Biosignal-based user-independent recognition of emotion and personality with importance weighting. Multimedia Tools and Applications, 81(21), 30219-30241.",40,13,28.3,-,21 – 40,-,Tomi,
147,1,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
148,1,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",40,12,,-,20-49,Spain,Tomi,
149,1,10.1109/JSEN.2020.3031163,"Woodward, K., & Kanjo, E. (2020). iFidgetCube: tangible fidgeting interfaces (TFIs) to monitor and improve mental wellbeing. IEEE Sensors Journal, 21(13), 14300-14307.",9,-,,-,-,-,Tomi,
150,1,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",32,16,26.9,-,19-37,-,Tomi,
150,2,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",40,13,28.3,-,21 – 40,-,Tomi,
150,3,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",457,236,-,-,-,China,Tomi,
151,1,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",32,0,,-,25-45,-,Tomi,
152,1,10.3389/fnins.2023.1138091,"Li, Z., Xing, Y., Pi, Y., Jiang, M., & Zhang, L. (2023). A novel physiological feature selection method for emotional stress assessment based on emotional state transition. Frontiers in Neuroscience, 17, 1138091.",85,46,23.1,-,-,-,Tomi,
153,1,10.3390/s21113760,"Alanazi, S.A.; Alruwaili, M.; Ahmad, F.; Alaerjan, A.; Alshammari, N. Estimation of Organizational Competitiveness by a Hybrid of One-Dimensional Convolutional Neural Networks and Self-Organizing Maps Using Physiological Signals for Emotional Analysis of Employees. Sensors 2021, 21, 3760.",1200,574,44.2,-,-,-,Tomi,
154,1,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",34,17,25,-,18-61,United Kingdom,Tomi,
155,1,10.3390/s21062166,"Oh, G., Ryu, J., Jeong, E., Yang, J. H., Hwang, S., Lee, S., & Lim, S. (2021). Drer: Deep learning–based driver’s real emotion recognizer. Sensors, 21(6), 2166.",13,7,,-,-,-,Tomi,
156,1,10.1016/j.inffus.2020.08.007,"Raheel, A., Majid, M., & Anwar, S. M. (2021). DEAR-MULSEMEDIA: Dataset for emotion analysis and recognition in response to multiple sensorial media. Information Fusion, 65, 37-49.",18,9,20.92,-,-,-,Tomi,
157,1,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",32,16,26.9,-,19-37,-,Tomi,
158,1,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",15,3,27.5 ± 2.4,-,-,-,Tomi,
158,2,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",10,5,29.9,-,24–59,Tunisia,Tomi,
158,3,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",21,-,28,-,-,Slovenia,Tomi,
158,4,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",21,3,32 ± 3.1,-,-,-,Tomi,
159,1,10.2478/jaiscr-2021-0001,"Rahman, J. S., Gedeon, T., Caldwell, S., Jones, R., & Jin, Z. (2021). Towards effective music therapy for mental health care using machine learning tools: human affective reasoning and music genres. Journal of Artificial Intelligence and Soft Computing Research, 11(1), 5-20.",24,11,21,-,-,-,Tomi,
160,1,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",56,46,21.8,-,19-38,-,Tomi,
161,1,10.1109/TAFFC.2019.2901673,"Shukla, J., Barreda-Ángeles, M., Oliver, J., Puig, D., & Nandi, G. C. (2019). Feature Extraction and Selection for Emotion Recognition from Electrodermal Activity. IEEE Transactions on Affective Computing, 12(4), 858-866.",40,13,28.3,-,21 – 40,-,Tomi,
162,1,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",58,21,30,-,-,-,Tomi,
163,1,10.1145/3495002,"Tabbaa, L., Searle, R., Bafti, S. M., Hossain, M. M., Intarasisrisawat, J., Glancy, M., & Ang, C. S. (2021). Vreed: Virtual reality emotion recognition dataset using eye tracking & physiological measures. Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies, 5(4), 1-20.",34,17,,-,18-61,-,Tomi,
164,1,10.1049/ccs2.12107,"Zou, C., Deng, Z., He, B., Yan, M., Wu, J., & Zhu, Z. (2024). Emotion classification with multi‐modal physiological signals using multi‐attention‐based neural network. Cognitive Computation and Systems, 6(1-3), 1-11.",15,3,27.5 ± 2.4,-,-,-,Tomi,
165,1,10.2478/joeb-2021-0021,"Jacobsen, F. A., Hafli, E. W., Tronstad, C., & Martinsen, Ø. G. (2021). Classification of emotions based on electrodermal activity and transfer learning-a pilot study. Journal of Electrical Bioimpedance, 12(1), 178.",10,5,,-,20-30,-,Tomi,
166,1,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",32,16,26.9,-,19-37,-,Tomi,
167,1,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",62,17,-,-,20 – 50,-,Tomi,
167,2,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",20,6,25.6,-,19 – 33,-,Tomi,
167,3,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
167,4,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",55,23,22.32,-,18-30,United States,Tomi,
168,1,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",32,16,26.9,-,19-37,-,Tomi,
169,1,10.1016/j.bspc.2024.106224,"Umair, M., Rashid, N., Khan, U. S., Hamza, A., & Iqbal, J. (2024). Emotion fusion-sense (Emo Fu-sense)–a novel multimodal emotion classification technique. Biomedical Signal Processing and Control, 94, 106224.",27,17,26.06,-,19-40 ,-,Tomi,
170,1,10.1109/TAFFC.2018.2884461,"Miranda-Correa, J. A., Khomami Abadi, M., Sebe, N., & Patras, I. (2017). AMIGOS: A dataset for affect, personality and mood research on individuals and groups. IEEE Transactions on Affective Computing.",40,13,28.3,-,21-40,-,Tomi,
171,1,10.1109/BIBM58861.2023.10385273,"Singh, A., Wittenberg, T., Salman, M. M., Holzer, N., Göb, S., Pahl, J., ... & Sawant, S. (2023, December). Bio-Signal Based Multimodal Fusion with Bilinear Model for Emotion Recognition. In 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) (pp. 4834-4839). IEEE.",27,17,26.06,-,19-40 ,-,Tomi,
172,1,10.1109/BSN63547.2024.10780682,"Gahlan, N., Sethia, D., & Ray, S. B. (2024, October). Emotion Analysis Using Auditory ASMR via Physiological Signals and Federated Learning. In 2024 IEEE 20th International Conference on Body Sensor Networks (BSN) (pp. 1-4). IEEE.",23,11,20.13,-,17-23,,Tomi,
173,1,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",30,15,27.15,-,22-37,India,Tomi,
173,2,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",15,3,27.5 ± 2.4,-,-,India,Tomi,
174,1,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",32,16,26.9,-,19-37,-,Tomi,
174,2,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",27,17,26.06,-,19-40 ,-,Tomi,
175,1,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",14,,,-,,-,Tomi,
176,1,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",36,0,,-,20-35,-,Tomi,
177,1,10.1109/HRI53351.2022.9889545,"Mohamed, Y., Ballardini, G., Parreira, M. T., Lemaignan, S., & Leite, I. (2022, March). Automatic frustration detection using thermal imaging. In 2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI) (pp. 451-459). IEEE.",18,9,27.28,-,21-39,-,Tomi,
178,1,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",14,5,-,-,20-25,,Tomi,
179,1,10.1145/3544793.3563427,"Alchieri, L., Abdalazim, N., Alecci, L., Gashi, S., Di Lascio, E., & Santini, S. (2022, September). On the impact of lateralization in physiological signals from wearable sensors. In Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers (pp. 472-477).",34,6,26.7,-,22-37,,Tomi,
180,1,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",15,3,27.5 ± 2.4,-,-,Germany,Tomi,
181,1,10.1016/j.bspc.2021.102756,"Acevedo, C. M. D., Gómez, J. K. C., & Rojas, C. A. A. (2021). Academic stress detection on university students during COVID-19 outbreak by using an electronic nose and the galvanic skin response. Biomedical Signal Processing and Control, 68, 102756.",25,7,,,18-30,Colombia,Tomi,
182,1,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",32,16,26.9,-,19-37,-,Tomi,
182,2,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",40,13,28.3,-,21 – 40,-,Tomi,
