paper_id,model_id,doi,apa_citation,year,affective_model,is_classifier,class_model_output_number,class_model_output_categories,class_logistic_regression,class_support_vector_machine,class_k_nearest_neighbor,class_quadratic_discrimant_classifier,class_linear_discriminant_analysis,class_tree_based_models,class_naive_bayes,class_avg,class_lasso_t,class_ridge_t,class_lasso_var,class_ridge_var,class_tpa,class_hdc_mer,class_hmm,class_gradient_boostingclass,class_regre_fully_connected_neuronal_network_or_multi_layer_perceptron,class_convolutional_neuronal_network,class_recurrent_neuronal_network,class_gated_recurrent_units,class_lstm,class_cellular_neural_networks,class_adaboost_dt,class_quantum_neural_network,class_probabilistic_neural_network,class_backpropagation,class_extreme_learning_machine,class_ann,class_spiking_deep_belief_network,class_radial_basis_function,class_1r_rule,class_jrip,class_other,is_regressor,regre_model_output_number,regre_model_output_dimensions,regre_linear_regression,regre_support_vector_regression,regre_polynomial_regression,regre_ridge_regression,regre_logistic_regression,regre_knn,regre_decision_tree,regre_multilayer_regression,regre_boosted_regression_trees,regre_fully_connected_neuronal_network_or_multi_layer_perceptron,regre_convolutional_neuronal_network,regre_recurrent_neuronal_network,regre_lstm,regre_probabilistic_neural_network,regre_other,model_level_intersubject,model_level_intrasubject,n_model_input,is_physiologically_interpreted,model_interpretation,is_public_code,public_code_location,accuracy,precision,f_measure,recall_sensitivity_true_positive_rate,specificity_true_negative_rate,false_positive_rate,false_negative_rate,roc_auc,r2,r,mean_absolute_error,concordance_correlation_coefficient,spearmans_ranking_correlation,mean_square_error,root_mean_square_error,pearson_correlation_coefficient,unweighted_average_recall,matthews_correlation_coefficient,geometric_mean,metric_other,revisor,comentarios,Full_Judgement,Full_exclusion_category,Full_Evidence
1,1,,"Zangróniz, R., Martínez-Rodrigo, A., Pastor, J. M., López, M. T., & Fernández-Caballero, A. (2017). Electrodermal Activity Sensor for Classification of Calm/Distress Condition. Sensors (Basel, Switzerland), 17(10), E2324. https://doi.org/10.3390/s17102324
",2017.0,dimensional,x,2,"calm, distress",-,-,-,,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,x,-,-,-,-,-,-,89.18,-,-,93.9,85.36,-,,-,-,,-,,,,,,,,,,,,,,
2,1,,"Liu, M., Fan, D., Zhang, X., & Gong, X. (2017). Human Emotion Recognition Based on Galvanic Skin Response Signal Feature Selection and SVM. 157–160. Scopus. https://doi.org/10.1109/ICSCSE.2016.0051
",2016.0,categorical,x,5,"Happiness, Grief, Fear, Anger, Calm",-,x,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,,-,-,-,-,66.67,-,-,,,,,-,-,,-,,,,,,,,,,,,,,
3,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. E. (2018). Emotion Based Music Recommendation System Using Wearable Physiological Sensors. IEEE Transactions on Consumer Electronics, 64(2), 196–203. Scopus. https://doi.org/10.1109/TCE.2018.2844736
",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,71.53,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
3,2,,"Ayata, D., Yaslan, Y., & Kamasak, M. E. (2018). Emotion Based Music Recommendation System Using Wearable Physiological Sensors. IEEE Transactions on Consumer Electronics, 64(2), 196–203. Scopus. https://doi.org/10.1109/TCE.2018.2844736
",2018.0,dimensional,x,2,"LV, HV",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,,,-,-,x,-,71.04,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
4,1,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061905",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,64,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
4,2,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061906",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,53,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
4,3,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061907",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,60,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
4,4,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061908",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,68,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
4,5,,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061909",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,x,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,75,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
5,1,,"Wei, J., Chen, T., Liu, G., & Yang, J. (2016). Higher-order Multivariable Polynomial Regression to Estimate Human Affective States. Scientific Reports, 6, 23384. https://doi.org/10.1038/srep23384",2016.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,-,arousal,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,x,"By using the gradient fields (see Fig. 6(c,d)), the affective HMPM indirectly supports that the affective valence
and arousal have their origins in human brain’s motivational circuits. It seems to be reasonable that evaluative
affective components (valence and arousal) are associated with the broad functions of brain’s motivational circuits—appetitive subcircuits activation (pleasant) and defensive subcircuits activation (unpleasant) and an intensity of these two subcircuits activation (arousal)9
. Affective cues can induce skin conductance activations through
the limbic-hypothalamic EDA1 pathway, and the pleasant affect may additionally induce skin conductance activations through the premotor-basal ganglia EDA2 pathway37. The gradient field of valence (Fig. 6(c)) indicates
that the valence factor is mainly determined by the two dimensions: gain, that has neural activation intensity
meanings, and decay time constant, that has the meanings of skin conductance different pathways37,45. The gradient field of arousal (Fig. 6(d)) indicates that arousal factor is mainly determined by the gain dimension. These
findings may indirectly support prior researches9,48.
The HMPR is an important supplement to emotional estimation methodology. The HMPR, in fact, is not only
theoretically supported by the Taylor theorem, but also able to obtain an intuitive HMPM to efficiently estimate
the affective valence and arousal from pure skin conductance responses. Moreover, the result of comparing the
HMPR with the ANN models (see Supplementary Table S7) showed that both the HMPR and ANN can obtain
relative accurate computing results. Such accurate estimation results surely increases the impact in the wearable
computing fields such as smart watches, Mi Band, and Google Glass, etc. It is a trend now to detect human affect
by multimodal signals (e.g., neural activations, facial videos, voice recordings, body gestures, and physiological
signals, etc.",-,-,-,-,-,-,-,-,-,-,-,0.96,,,,,,,,,,,,,,,
5,2,,"Wei, J., Chen, T., Liu, G., & Yang, J. (2016). Higher-order Multivariable Polynomial Regression to Estimate Human Affective States. Scientific Reports, 6, 23384. https://doi.org/10.1038/srep23384",2016.0,categorical,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,,valence,-,-,x,,,,,,,-,-,-,-,-,,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,0.98,,,,,,,,,,,,,,,
6,1,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"acceptance, boredom",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,75,81,,71,,,,75,,,,,,,,,,,,,,,,,
6,2,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"acceptance, joy",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,84,85,,84,-,-,-,89,-,-,-,,,,,,,,,,,,,,
6,3,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"boredom, joy",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,90,82,,88,-,-,-,87,-,-,-,,,,,,,,,,,,,,
6,4,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,3,"acceptance, joy, boredom",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,69,,,,-,-,-,,-,-,-,,,,,,,,,,,,,,
6,5,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"acceptance, boredom",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,70,71,,70,-,-,-,63,-,-,-,,,,,,,,,,,,,,
6,6,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"acceptance, joy",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,82,80,-,82,-,-,-,81,-,-,-,,,,,,,,,,,,,,
6,7,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,2,"boredom, joy",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,85,77,,85,-,-,-,86,-,-,-,,,,,,,,,,,,,,
6,8,,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,?,?,-,-,-,-,-,66,-,,,-,-,-,,-,-,-,,,,,,,,,,,,,,
7,1,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,54.36,-,45.48,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,2,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,56.67,-,45.74,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,3,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,59.85,-,49.06,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,4,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,62.32,-,42.72,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,5,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,54.98,-,45.2,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,6,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,48.49,-,43.88,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,7,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,45,-,42.4,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,8,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,54.06,-,48.33,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,9,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,categorical,x,3,"baseline, stress, amusement",-,-,-,-,x,-,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,67.07,-,46.83,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,10,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,40.03,-,37.26,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,11,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,76.21,-,70.95,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,12,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,76.29,-,70.88,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,13,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,x,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,79.71,-,75.34,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,14,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,78.08,-,69.86,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,15,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,73.13,-,68.3,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,16,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,73.55,-,69.88,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,17,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,77.51,-,73.63,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,18,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,75.5,-,71.97,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,19,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,-,-,x,-,-,,,,,,,,,,-,,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,81.7,-,74.51,-,-,-,,-,-,,-,,,,,,,,,,,,,,
7,20,,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018.0,dimensional,x,2,"stress,  not stress",-,-,x,-,-,,-,,,,,,,,,,-,,-,,-,,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,69.73,-,66.64,-,-,-,,-,-,,-,,,,,,,,,,,,,,
8,1,,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018.0,dimensional,x,2,"relaxed, stress",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,54,-,65,-,55,35,-,-,,-,,,,,,,,,,,,,,
8,2,,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018.0,categorical,x,2,"relaxed, stress",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,52,-,80,-,73,20,-,-,,-,,,,,,,,,,,,,,
8,3,,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,56,-,56,-,43,44,-,-,,-,,,,,,,,,,,,,,
9,1,,"Amalan, S., Shyam, A., Anusha, A. S., Preejith, S. P., Tony, A., Jayaraj, J., & Mohanasankar, S. (2018). Electrodermal Activity based Classification of Induced Stress in a Controlled Setting. MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings. Scopus. https://doi.org/10.1109/MeMeA.2018.8438703",2018.0,dimensional,x,2,"stress, not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,,,,94,93,,,,,,,,,,,,,,,,,,,,
10,1,,"Machot, F. A., Ali, M., Ranasinghe, S., Mosa, A. H., & Kyandoghere, K. (2018). Improving subject-independent human emotion recognition using electrodermal activity sensors for active and assisted living. 222–228. Scopus. https://doi.org/10.1145/3197768.3201523",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,-,68,75,-,-,-,-,-,-,,,,,,,,,,,,,,
11,1,,"Girardi, D., Lanubile, F., & Novielli, N. (2018). Emotion detection using noninvasive low cost sensors. 2018-January, 125–130. Scopus. https://doi.org/10.1109/ACII.2017.8273589",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,67,63,64,,,,,,,,,,,,,,,,,,,,,
11,2,,"Girardi, D., Lanubile, F., & Novielli, N. (2018). Emotion detection using noninvasive low cost sensors. 2018-January, 125–130. Scopus. https://doi.org/10.1109/ACII.2017.8273589",2018.0,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,58,35,50,,,,,,,,,,,,,,,,,,,,,
12,1,,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018.0,categorical,x,2,"neutral, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Figure 6 shows similar EDA signal behaviour during resting and recovery phases.
Signal constantly rises to a limit at this point before declining and rising again. Signals at
these phases had low fluctuation and sudden rise of amplitude because the subject sits in
a relaxed phase. This situation is similar to a neutral simulated driving condition. The
most frequent fluctuation of EDA signal was observed during anger-simulated driving,
followed by stress and neutral driving. This finding shows that the subject is endowed
with the most intense sympathetic response during anger, followed by stress and neutral
emotion. Further processing was required to determine significant differences of EDA
properties during different simulated driving tasks.
Figure 7 indicates that band-pass-filtered EDA signals at neutral simulated driving
tasks had similar response to control and recovery sessions, wherein the subject
demonstrates the least physiological response because of the simplicity of driving
scenario. The subject possesses a high level of physiological response during states of
anger than in stress-simulated driving tasks. The overall amplitude of signals is high and
the fluctuations of spikes occurred frequently.",-,-,100,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
12,2,,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018.0,categorical,x,2,"neutral, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
12,3,,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018.0,categorical,x,2,"stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,65,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
12,4,,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018.0,categorical,x,3,"neutral, stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,77,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
13,1,,"Setyohadi, D. B., Kusrohmaniah, S., Gunawan, S. B., Pranowo, & Prabuwono, A. S. (2018). Galvanic skin response data classification for emotion detection. International Journal of Electrical and Computer Engineering, 8(5), 4004–4014. Scopus. https://doi.org/10.11591/ijece.v8i5.pp4004-4014",2018.0,dimensional,x,3,"neutral, negative, positive",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,75.65,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
14,1,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.28,-,0.14,,,,,,,,,,,,
14,2,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.27,-,0.02,,,,,,,,,,,,
14,3,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.19,-,0.24,,,,,,,,,,,,
14,4,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.28,-,0.23,,,,,,,,,,,,
14,5,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.23,-,0.29,,,,,,,,,,,,
14,6,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.29,-,0.05,,,,,,,,,,,,
14,7,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.32,-,0.03,,,,,,,,,,,,
14,8,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.24,-,0.08,,,,,,,,,,,,
14,9,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.33,-,0.14,,,,,,,,,,,,
14,10,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,,-,x,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.28,-,0.13,,,,,,,,,,,,
14,11,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,,x,-,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.3,-,0.02,,,,,,,,,,,,
14,12,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,,x,-,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.34,-,0.04,,,,,,,,,,,,
14,13,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,,x,-,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.24,-,0.01,,,,,,,,,,,,
14,14,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,,x,-,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.34,-,0.02,,,,,,,,,,,,
14,15,,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,,x,-,,-,-,,,-,-,-,-,-,-,-,-,-,-,0.29,-,0.01,,,,,,,,,,,,
15,1,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,56.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,2,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,66.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,3,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,70,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,4,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,80,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,5,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,66.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,6,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,83.33,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,7,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,70.83,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,8,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,79.17,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,9,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,66.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,10,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,75,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,11,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,60,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,12,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,75,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,13,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,79.17,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,14,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,79.17,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,15,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,80,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,16,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,83.33,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,17,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,65,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,18,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,19,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,2,"stress, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,20,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,40,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,21,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,46.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,22,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,30.56,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,23,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,44.44,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,24,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,40,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,25,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,53.33,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
15,26,,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017.0,categorical,x,3,"anges, stress, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,76.67,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
16,27,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion sensing from physiological signals using three defined areas in arousal-valence model. 219–223. Scopus. https://doi.org/10.1109/CADIAG.2017.8075660",2017.0,dimensional,x,3,"calm arousal, medium arousal, excited arousal",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,,-,-,-,-,-,50.52,,,,,,,,,,,,,,,,,,,,,,,,
16,28,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion sensing from physiological signals using three defined areas in arousal-valence model. 219–223. Scopus. https://doi.org/10.1109/CADIAG.2017.8075660",2017.0,dimensional,x,3,"LV, neutral valence, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,,-,-,-,-,-,48.93,,,,,,,,,,,,,,,,,,,,,,,,
17,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,67.58,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,2,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.7,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,3,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.84,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,4,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.82,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,5,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,69.29,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,6,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,55.88,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,7,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.92,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,8,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"happiness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.91,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,9,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.87,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,10,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.86,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,11,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.91,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,12,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.93,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,13,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,64.47,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,14,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,57.55,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,15,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,75.34,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,16,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"peacefulness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,70.37,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,17,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,68.69,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,18,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.75,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,19,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.98,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,20,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,95.49,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,21,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,67.35,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,22,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,57.97,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,23,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.93,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,24,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"sadness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,67.99,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,25,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,76.09,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,26,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,74.87,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,27,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.89,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,28,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.84,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,29,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,70.21,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,30,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,69.24,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,31,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.95,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
17,32,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017.0,categorical,x,2,"fear, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-,99.96,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
18,1,,"Keren, G., Kirschstein, T., Marchi, E., Ringeval, F., & Schuller, B. (2017). End-to-end learning for dimensional emotion recognition from physiological signals. 985–990. Scopus. https://doi.org/10.1109/ICME.2017.8019533",2017.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,x,1,arousal,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.284,,,,,,,,,,,,,
18,2,,"Keren, G., Kirschstein, T., Marchi, E., Ringeval, F., & Schuller, B. (2017). End-to-end learning for dimensional emotion recognition from physiological signals. 985–990. Scopus. https://doi.org/10.1109/ICME.2017.8019533",2017.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,valence,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.336,,,,,,,,,,,,,
19,1,,"Hernández-García, A., Fernández-Martínez, F., & Díaz-De-maría, F. (2017). Emotion and attention: Predicting electrodermal activity through video visual descriptors. 914–923. Scopus. https://doi.org/10.1145/3106426.3109418",2017.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,x,1,arousal,x,-,-,,,,,,,-,-,-,-,-,,?,?,-,x,"The relationship between visual descriptors and other kind of
subjective information like aesthetics or appeal reported deliberately by participants via a score, for instance, had been already
demonstrated in previous works [16]. However, finding some correlation with EDA has a great interest because it is a psychophysiological reaction controlled by the autonomous nervous system,
thus it is automatic and is directly related to actual emotional and
attentional activation, avoiding the implicit bias of opinions and
judgments.
Correlation between the set of visual descriptors and SCL and
SCR was not so clear as in the case of SUM. One explanation for
this is that these measures alone reflect subtleties that are more
difficult to capture by simple methods and a relatively small set of
features",-,-,-,-,-,-,-,-,-,-,0.06,-,0.93,,,,,,,,,,,,,,
20,1,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion assessing using valence-arousal evaluation based on peripheral physiological signals and support vector machine. 4th International Conference on Control Engineering and Information Technology, CEIT 2016. Scopus. https://doi.org/10.1109/CEIT.2016.7929117",2017.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,62.23,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
20,2,,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion assessing using valence-arousal evaluation based on peripheral physiological signals and support vector machine. 4th International Conference on Control Engineering and Information Technology, CEIT 2016. Scopus. https://doi.org/10.1109/CEIT.2016.7929117",2017.0,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,,-,-,,x,-,-,-,-,-,-,55.78,-,-,-,-,-,-,,-,-,-,-,,,,,,,,,,,,,
21,1,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,2,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,3,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,4,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,5,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,6,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,7,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,8,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,9,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,10,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,11,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
21,12,,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017.0,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.
",,,,,,,,,,,,,,,,,,,,,,,,,,,
22,1,,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,,,67.1-72.1,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
22,2,,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,,,43.1-62.5,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
22,3,,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,,,40.2-53.2,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
23,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via random forest and galvanic skin response: Comparison of time based feature sets, window sizes and wavelet approaches. 2016 Medical Technologies National Conference, TIPTEKNO 2016. Scopus. https://doi.org/10.1109/TIPTEKNO.2016.7863130",2017.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,1280,-,-,-,-,71.53,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
23,2,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via random forest and galvanic skin response: Comparison of time based feature sets, window sizes and wavelet approaches. 2016 Medical Technologies National Conference, TIPTEKNO 2016. Scopus. https://doi.org/10.1109/TIPTEKNO.2016.7863130",2017.0,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,71.04,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
24,1,,"Greco, A., Valenza, G., Citi, L., & Scilingo, E. P. (2017). Arousal and valence recognition of affective sounds based on electrodermal activity. IEEE Sensors Journal, 17(3), 716–725. Scopus. https://doi.org/10.1109/JSEN.2016.2623677",2017.0,dimensional,x,3,"LA, medium arousal, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,,-,-,,,,,,,-,-,-,-,-,,x,-,75,-,-,-,-,77.33,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
24,2,,"Greco, A., Valenza, G., Citi, L., & Scilingo, E. P. (2017). Arousal and valence recognition of affective sounds based on electrodermal activity. IEEE Sensors Journal, 17(3), 716–725. Scopus. https://doi.org/10.1109/JSEN.2016.2623677",2017.0,dimensional,x,2,"LV, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,,-,-,,,,,,,-,-,-,-,-,,x,-,150,-,-,-,-,84,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,,
25,1,,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,-,-,55.28,-,-,66.2,68.56,-,-,-,-,-,-,,,,,,,,,,,,,,
25,2,,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,-,-,48.46,-,-,65,62.18,-,-,-,-,-,-,,,,,,,,,,,,,,
25,3,,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017.0,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,-,-,-,69.86,-,-,58.96,70.94,-,-,-,-,-,-,,,,,,,,,,,,,,
26,1,,"Zhang, Q., Lai, X., & Liu, G. (2016). Emotion recognition of GSR based on an improved quantum neural network. 1, 488–492. Scopus. https://doi.org/10.1109/IHMSC.2016.66",2016.0,categorical,x,5,"happy, grief, fear, angry, calm",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,x,,,,,,,,-,,,-,-,,-,-,,,,,,,-,-,-,-,-,,x,-,175,-,-,-,-,84.9,-,-,-,-,-,,-,-,-,-,-,,,,,,,,,,,,,
27,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016.0,categorical,x,5,"happy, sad, scary, peaceful, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,69.93,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
27,2,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016.0,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,79.02,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
27,3,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016.0,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,81.82,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,1,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, sad",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,2,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, sad",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,3,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, sad",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,4,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,83.13,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,5,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, neutral",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,90.58,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,6,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"happy, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,84.58,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,7,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"sad, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,100,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,8,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"sad, neutral",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,95.76,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
28,9,,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016.0,categorical,x,2,"sad, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,97.75,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,1,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,52,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,2,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,55,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,3,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,52,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,4,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LV, HV",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,52,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,5,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LL, HL",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,52,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
29,6,,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016.0,dimensional,x,2,"LL, HL",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,,x,-,-,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-,-,-,53,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
30,1,,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016.0,categorical,x,2,"neutral, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-,85,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
30,2,,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016.0,categorical,x,2,"neutral, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-,85,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
30,3,,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016.0,categorical,x,2,"stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-,70,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
31,1,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016.0,categorical,x,5,"happy, sad, scary, peaceful, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,95.1,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
31,2,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016.0,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,95.8,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
31,3,,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016.0,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,97.9,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,1,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,64.84,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,2,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,2,"LV, HV",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,63.28,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,3,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,2,"LL, HL",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,70,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,4,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,2,"LD, HD",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,59.38,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,5,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,33.59,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
32,6,,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018.0,dimensional,x,8,"pleased, excited, annoying, nervous, sad, sleepy, calm, relaxed",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,128,-,-,-,-,24.22,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,1,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,categorical,x,5,"happiness, sadness, scary, peacefulness, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,79.53,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,2,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,85.23,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,3,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,85.53,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,4,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,categorical,x,5,"happiness, sadness, scary, peacefulness, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,x,-,-,-,-,-,94.75,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,5,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,x,-,-,-,-,-,94.63,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
33,6,,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017.0,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,x,-,-,-,-,-,92.58,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
34,1,,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516647",2018.0,dimensional,x,2,"LV, HV, neutral",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,40,-,41,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
34,2,,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516648",2018.0,dimensional,x,3,"LV, HV, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,99,-,90,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
34,3,,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516649",2018.0,dimensional,x,2,"LV, HV, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,,-,-,,x,-,-,-,-,-,-,-,44,-,63,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
34,4,,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516649",2018.0,dimensional,x,2,"LV, HV, neutral",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,-,66,-,59,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
35,1,,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018.0,dimensional,x,3,"calm, medium aroused, excited",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-,77.8,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
35,2,,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018.0,dimensional,x,3,"LV, neutral valence, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,x,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-,74.6,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
35,3,,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018.0,dimensional,x,3,"LV, neutral valence, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-,75.5,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
35,4,,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018.0,dimensional,x,3,"calm, medium aroused, excited",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,-,x,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-,77.3,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
36,1,,"Zhang, S., Liu, G., & Lai, X. (2015). Classification of evoked emotions using an artificial neural network based on single, short-term physiological signals. Journal of Advanced Computational Intelligence and Intelligent Informatics, 19(1), 118-126.",2015.0,categorical,x,5,"anger, fear, grief, happiness, calmness",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,-,-,-,-,x,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,82.29,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,1,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,64,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,2,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,66,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,3,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,64,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,4,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,63.3,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,5,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,59,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,6,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,60,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,7,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,64,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,8,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,50.3,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,9,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,52.5,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,10,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,50,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,11,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,48.5,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,12,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,49.6,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,13,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,53.7,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,14,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,54.2,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,,
37,15,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,78,,,,,,,,,,,,,,,,,,,,,,,,
37,16,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,79.5,,,,,,,,,,,,,,,,,,,,,,,,
37,17,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,80,,,,,,,,,,,,,,,,,,,,,,,,
37,18,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,75,,,,,,,,,,,,,,,,,,,,,,,,
37,19,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,79.5,,,,,,,,,,,,,,,,,,,,,,,,
37,20,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,54,,,,,,,,,,,,,,,,,,,,,,,,
37,21,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,76.5,,,,,,,,,,,,,,,,,,,,,,,,
37,22,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,76.3,,,,,,,,,,,,,,,,,,,,,,,,
37,23,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,71.2,,,,,,,,,,,,,,,,,,,,,,,,
37,24,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,74.3,,,,,,,,,,,,,,,,,,,,,,,,
37,25,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,74,,,,,,,,,,,,,,,,,,,,,,,,
37,26,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,77.2,,,,,,,,,,,,,,,,,,,,,,,,
37,27,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,80.3,,,,,,,,,,,,,,,,,,,,,,,,
37,28,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,73.4,,,,,,,,,,,,,,,,,,,,,,,,
37,29,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,61.1,,,,,,,,,,,,,,,,,,,,,,,,
37,30,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,58.8,,,,,,,,,,,,,,,,,,,,,,,,
37,31,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,60.9,,,,,,,,,,,,,,,,,,,,,,,,
37,32,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,58.9,,,,,,,,,,,,,,,,,,,,,,,,
37,33,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,60.5,,,,,,,,,,,,,,,,,,,,,,,,
37,34,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,62.4,,,,,,,,,,,,,,,,,,,,,,,,
37,35,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,58.3,,,,,,,,,,,,,,,,,,,,,,,,
37,36,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,47.3,,,,,,,,,,,,,,,,,,,,,,,,
37,37,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,47,,,,,,,,,,,,,,,,,,,,,,,,
37,38,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,52.7,,,,,,,,,,,,,,,,,,,,,,,,
37,39,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,51.4,,,,,,,,,,,,,,,,,,,,,,,,
37,40,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,53.3,,,,,,,,,,,,,,,,,,,,,,,,
37,41,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,45.4,,,,,,,,,,,,,,,,,,,,,,,,
37,42,,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,--,-,-,-,-,,x,-,-,-,-,-,-,48.3,,,,,,,,,,,,,,,,,,,,,,,,
38,1,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,58.12,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,2,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,59.21,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,3,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,71.53,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,4,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,71.4,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,5,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LV, HV",-,-,x,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,60.54,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,6,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,59.2,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,7,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,71.04,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
38,8,,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017.0,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,x,-,-,-,-,-,-,70.54,-,-,-,-,,-,-,-,-,-,-,,,,,,,,,,,,,
39,1,,"Martínez-Rodrigo, A., Zangróniz, R., Pastor, J. M., & Sokolova, M. V. (2017). Arousal level classification of the aging adult from electro-dermal activity: From hardware development to software architecture. Pervasive and Mobile Computing, 34, 46–59. Scopus. https://doi.org/10.1016/j.pmcj.2016.04.006",2017.0,dimensional,x,2,"sleepiness, stressed",x,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,,-,-,-,-,83.33,,,,,,,,,,,,,,,,,,,,,,,,
40,1,,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,arousal,x,-,-,,,,,,-,,-,-,-,-,,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,0.09,-,,,,,,,,,,,,
40,2,,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,arousal,-,-,-,,,,,,x,,-,-,-,-,,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,0.056,-,,,,,,,,,,,,
40,3,,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,valence,x,-,-,,,,,,-,,-,-,-,-,,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,0.113,-,,,,,,,,,,,,
40,4,,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,valence,-,-,-,,,,,,x,,-,-,-,-,,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,0.107,-,,,,,,,,,,,,
41,1,,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,arousal,-,-,-,,,,,,-,-,-,-,-,-,,?,?,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.057,-,,,,,,,,,,,,
41,2,,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,1,valence,-,-,-,,,,,,-,-,-,-,-,-,,?,?,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.109,-,,,,,,,,,,,,
41,3,,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,2,"arousal, valence",-,-,-,,,,,,-,-,-,-,-,-,,?,?,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.053,-,,,,,,,,,,,,
41,4,,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015.0,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,x,2,"arousal, valence",-,-,-,,,,,,-,-,-,-,-,-,,?,?,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,0.122,-,,,,,,,,,,,,
42,1,,"Kostoulas, T., Chanel, G., Muszynski, M., Lombardo, P., & Pun, T. (2017). Films, affective computing and aesthetic experience: Identifying emotional and aesthetic highlights from multimodal signals in a social setting. Frontiers in ICT, 4(JUN). Scopus. https://doi.org/10.3389/fict.2017.00011",2017.0,dimensional,x,2,"LV,HV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,,79.94,-,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,
42,2,,"Kostoulas, T., Chanel, G., Muszynski, M., Lombardo, P., & Pun, T. (2017). Films, affective computing and aesthetic experience: Identifying emotional and aesthetic highlights from multimodal signals in a social setting. Frontiers in ICT, 4(JUN). Scopus. https://doi.org/10.3389/fict.2017.00011",2017.0,categorical,x,2,"LA, HA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,,80.7,-,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,
43,1,,"Barral, O., Kosunen, I., & Jacucci, G. (2017). No need to laugh out loud: Predicting humor appraisal of comic strips based on physiological signals in a realistic environment. ACM Transactions on Computer-Human Interaction, 24(6). Scopus. https://doi.org/10.1145/3157730",2017.0,categorical,x,2,"funny, not funny",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,,-,-,-,-,-,,,,,,-,-,-,-,-,-,,,,,x," Electrodermal Activity. Interestingly, EDA seems to be the most generalizable signal as
it performed the best in the across prediction setup compared to the other physiological sources,
and also performed better than EDA in the within prediction setup. It is also interesting that the
low classification performances of some participants in the within setup (e.g., “P10,” “P17,” “P22”)
were largely improved in the across setup. One possible explanation is that EDA features are quite
generalizable across participants; for some participants, the effect might be small, and therefore the model’s performance improves when the amount of training data increases, even when the
data belongs to other participants.

Figure 5 shows the grand average across participants and trials of the EDA for the time-locked,
fixed-time windows (initial, end, and special windows). EDA is known to present a relatively high
latency as compared to other physiological signals. As a matter of fact, capturing the EDA responses to the humor appraisal was one of the main motivations to define the special window that
continues for 5 seconds after the end of a trial. The grand average of the EDA signal shows a very
large difference in the signal from 2 to 4 seconds after the end of a trial. More specifically, “Funny”
trials elicited higher EDA than “Not funny” trials. This is captured in the most relevant features
for the trained models (see Table 4), as the top EDA features are the ones capturing the amount of
activity (i.e., wS.sum.Eda) and amount of change (i.e., wS.diff.Eda, wS.diffsq.Eda) within the special
window


EDA
showed increased values for humorous content, as expected because of increased activity of the
sympathetic nervous system due to the feeling of amusement (Foster et al. 1998; Martin 2010)
(Figure 5). In addition, the results indicate that the most discriminative differences in the physiological signals related to humor appraisal occur in the later stages of the information consumption
process, as shown in the most highly weighted features of the predictive models (see Table 4). This
finding is compatible with the incongruity model of humor, which posits that humor results from
solving ambiguities and conceptual incongruities using alternative formulations to the discrepancy. To put it in colloquial terms, the punchline comes at the end (Polimeni and Reiss 2006).
As a matter of fact, the discriminative physiological differences were mostly found in the special
window, which continued for several seconds after the trial ended, overlapping with the next
stimulus. Initially, we expected this to be the case only for the EDA signal, which is known to have
a temporal delay; but the same post-decision changes were apparent in EEG and ECG features as
well. This holds important implications for the design of affective systems for humor appraisal, as
it proves the delayed nature of physiological responses related to humor appraisal, as well as their
capability to capture it, despite overlapping with the next stimulus",-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,,,,,,,,,,,
44,1,,"Lanatà, A., Valenza, G., & Scilingo, E. P. (2012). A novel EDA glove based on textile-integrated electrodes for affective computing. Medical & Biological Engineering & Computing, 50(11), 1163–1172. doi:10.1007/s11517-012-0921-9",2012.0,dimensional,x,5,"neutral, arousal1, arousal2, arousal3, arousal4",-,-,-,X,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,,,-,,-,-,-,-,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
45,1,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013.0,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,-,-,43,,-,-,-,60,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
45,2,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,-,-,43,,-,-,-,63.57,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
45,3,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,-,-,43,,-,-,-,60.71,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
45,4,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,,,-,-,43,,-,-,-,63.57,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
45,5,,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,,-,-,-,-,,,,,,,,-,-,-,-,,,-,-,43,,-,-,-,63.57,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
46,1,,"GOUIZI, K., BEREKSI REGUIG, F., & MAAOUI, C. (2011). Emotion recognition from physiological signals. Journal of Medical Engineering & Technology, 35(6-7), 300–307. doi:10.3109/03091902.2011.601784",2011.0,categorical,x,6,"joy, sadness, fear, disgust, neutrality,  amusement",-,X,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,,-,,,,,,,,-,-,-,-,,,-,-,-,-,-,-,-,-,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
47,1,,"Bornoiu, I.-V., Strungaru, R., & Grigore, O. (2015). Intelligent System for Emotion Recognition Based on Electrodermal Activity Processing. 6th European Conference of the International Federation for Medical and Biological Engineering, 70–73. doi:10.1007/978-3-319-11128-5_18 ",2015.0,dimensional,x,2,"relaxed, stress",-,-,X,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,?,,-,-,-,75.39,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,,,,,,
48,1,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015.0,categorical,x,2,"stress, not stress",,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,140,-,-,-,-,75.8,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
48,2,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015.0,dimensional,x,2,"stress, not stress",,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,140,-,-,-,-,61.6,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
48,3,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015.0,dimensional,x,2,"stress, not stress",,-,-,X,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,140,-,-,-,-,65,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
48,4,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015.0,dimensional,x,2,"stress, not stress",,-,-,-,X,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,140,-,-,-,-,71.4,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
48,5,,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015.0,dimensional,x,2,"stress, not stress",,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,140,-,-,-,-,65.1,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
49,1,,"Drungilas, D., Bielskis, A. A., & Denisov, V. (2010). An intelligent control system based on non-invasive man machine interaction. In Innovations in Computing Sciences and Software Engineering (pp. 63-68). Springer, Dordrecht.",2010.0,categorical,x,8,"Fear, Surprise, Happy, Calmness, Sleepiness, Sad, Disgust, Anger",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,75,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
50,1,,"Wu, G., Liu, G., & Hao, M. (2010). The Analysis of Emotion Recognition from GSR Based on PSO. 2010 International Symposium on Intelligence Information Processing and Trusted Computing. doi:10.1109/iptc.2010.60",2010.0,categorical,x,6,"happy, Suprise, Disgust, Grief, Angry, Fear",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,65.59,-,,,,-,,-,,,,,,,,,,,,,,
51,1,,"Giakoumis, D., Tzovaras, D., Moustakas, K., & Hassapis, G. (2011). Automatic Recognition of Boredom in Video Games Using Novel Biosignal Moment-Based Features. IEEE Transactions on Affective Computing, 2(3), 119–133. doi:10.1109/t-affc.2011.4 ",2011.0,categorical,x,2,"bored, not bored",-,-,-,-,X,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,X,-,-,-,-,-,-,82.1,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
52,1,,"Safta, I., Grigore, O., & Căruntu, C.(2011). Emotion Detection Using Psycho-Physiological Signal Processing. Computer, 3, 4.",2011.0,dimensional,x,2,"pleaseant, unpleaseant ",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,,-,-,,X,-,-,-,-,-,-,-,-,-,66,67,34,33,-,-,,-,,,,,,,,,,,,,,
53,1,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012.0,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,63.33,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
53,2,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,61.67,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
53,3,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,60,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
53,4,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,57.22,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
53,5,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,61.11,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
54,1,,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013.0,categorical,x,2,"hapinees, sadness and fear",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,X,-,-,-,-,-,-,-,-,-,92.33,-,14.31,,-,-,,-,,,,,,,,,,,,,,
54,2,,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013.0,categorical,x,2," sadness and fears , hapiness",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,X,-,-,-,-,-,-,-,-,-,75,-,13.42,,-,-,,-,,,,,,,,,,,,,,
54,3,,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013.0,categorical,x,2,"fear and hapiness, sadness",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,X,-,-,-,-,-,-,-,-,-,70.71,-,17.24,,-,-,,-,,,,,,,,,,,,,,
55,1,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013.0,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,,,,,,,,-,-,-,-,-,65.79,-,-,-,-,-,,,-,,-,,,,,,,,,,,,,,
55,2,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,54.61,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
55,3,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,58.55,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
55,4,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,,-,-,-,55.92,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
55,5,,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013.0,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,55.26,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
56,1,,"Guo, R., Li, S., He, L., Gao, W., Qi, H., & Owens, G. (2013, May). Pervasive and unobtrusive emotion sensing for human mental health. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops (pp. 436-439). IEEE.",2013.0,categorical,x,4,"Amusement, fear, relax, sadness",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,70.2,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
56,2,,"Guo, R., Li, S., He, L., Gao, W., Qi, H., & Owens, G. (2013, May). Pervasive and unobtrusive emotion sensing for human mental health. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops (pp. 436-439). IEEE.",2013.0,categorical,x,4,"Amusement, fear, relax, sadness",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,59.25,-,-,-,-,,,-,-,,-,,,,,,,,,,,,,,
57,1,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,2,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,,,,,,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,-,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,3,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,-,-,-,-,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,,-,-,,-,-,,,-,-,,-,,,,,,,,,,,,,,
57,4,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,-,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,5,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,-,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,6,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,44,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,7,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,43,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
57,8,,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013.0,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-,44,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
58,1,,"Li, S., Guo, R., He, L., Gao, W., Qi, H., & Owens, G. (2014). MoodMagician. Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems - SenSys ’14. doi:10.1145/2668332.2668371",2014.0,categorical,x,4,"amusement,fear, relax, sadness",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,,-,-,-,-,,,,,,,,-,-,-,-,-,,-,-,-,-,-,-,-,54.08,-,-,-,-,-,,-,-,,-,,,,,,,,,,,,,,
59,1,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,x,,,,,-,-,-,-,-,,,86.92,,85.96,,,,,,,,,,,,,,,,,,,,,,
59,2,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,,x,,,,-,-,-,-,-,,,75.58,,74.71,,,,,,,,,,,,,,,,,,,,,,
59,3,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,x,x,,,,-,-,-,-,-,,,81.34,,80.7,,,,,,,,,,,,,,,,,,,,,,
59,4,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,x,,,,,-,-,-,-,-,,,86.73,,85.71,,,,,,,,,,,,,,,,,,,,,,
59,5,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,,x,,,,-,-,-,-,-,,,82.12,,81.46,,,,,,,,,,,,,,,,,,,,,,
59,6,,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,x,x,,,,-,-,-,-,-,,,82.53,,80.82,,,,,,,,,,,,,,,,,,,,,,
60,1,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,59,60,58,60,,,,,,,,,,,,,,,,,,,,,
60,2,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,74,76,75,75,,,,,,,,,,,,,,,,,,,,,
60,3,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,44,48,42,44,,,,,,,,,,,,,,,,,,,,,
60,4,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,80,80,80,80,,,,,,,,,,,,,,,,,,,,,
60,5,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,85,85,85,85,,,,,,,,,,,,,,,,,,,,,
60,6,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,55,53,51,56,,,,,,,,,,,,,,,,,,,,,
60,7,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,68,70,70,70,,,,,,,,,,,,,,,,,,,,,
60,8,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,37,43,35,39,,,,,,,,,,,,,,,,,,,,,
60,9,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,74,76,75,75,,,,,,,,,,,,,,,,,,,,,
60,10,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,81,81,81,81,,,,,,,,,,,,,,,,,,,,,
60,11,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,41,70,45,42,,,,,,,,,,,,,,,,,,,,,
60,12,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,64,65,65,65,,,,,,,,,,,,,,,,,,,,,
60,13,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,27,43,33,27,,,,,,,,,,,,,,,,,,,,,
60,14,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,72,73,72,73,,,,,,,,,,,,,,,,,,,,,
60,15,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,78,78,78,78,,,,,,,,,,,,,,,,,,,,,
60,16,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,44,50,40,44,,,,,,,,,,,,,,,,,,,,,
60,17,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,69,70,69,69,,,,,,,,,,,,,,,,,,,,,
60,18,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,36,31,28,36,,,,,,,,,,,,,,,,,,,,,
60,19,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,75,76,76,75,,,,,,,,,,,,,,,,,,,,,
60,20,,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,,82,83,83,82,,,,,,,,,,,,,,,,,,,,,
61,1,,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019.0,dimensional,x,2,"weak boredom, strong boredom",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,,68.33,,,,,,,,,,,,,,,,,,,,,,,,
61,2,,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019.0,dimensional,x,2,"weak boredom, strong boredom",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,,66.86,,,,,,,,,,,,,,,,,,,,,,,,
61,3,,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019.0,dimensional,x,2,"weak boredom, strong boredom",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,,70.03,,,,,,,,,,,,,,,,,,,,,,,,
62,1,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,77.3,78.5,79.7,,,,,,,,,,,,,,,,,,,,,
62,2,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,99.2,99.2,99.2,,,,,,,,,,,,,,,,,,,,,
62,3,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,96.9,96.9,96.9,,,,,,,,,,,,,,,,,,,,,
62,4,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,85.9,84,82.3,,,,,,,,,,,,,,,,,,,,,
62,5,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,95.3,95.3,95.3,,,,,,,,,,,,,,,,,,,,,
62,6,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,81.4,74,73.9,,,,,,,,,,,,,,,,,,,,,
62,7,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,95.2,95.1,95.1,,,,,,,,,,,,,,,,,,,,,
62,8,,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019.0,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,89.2,87.8,86.4,,,,,,,,,,,,,,,,,,,,,
63,1,,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,79,,,,,,,,,,,,,,,,,,,,,,,,
63,2,,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,69.8,,,,,,,,,,,,,,,,,,,,,,,,
63,3,,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019.0,dimensional,x,2,"high dominance, low dominance",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,71.4,,,,,,,,,,,,,,,,,,,,,,,,
64,1,,"Dar, M. N., Akram, M. U., Khawaja, S. G., & Pujari, A. N. (2020). Cnn and lstm-based emotion charting using physiological signals. Sensors, 20(16), 4551.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another
reason for the better performance of AMIGOS as compared to DREAMER is due to the nature of
the self-assessment acquisition process. Self-assessment for the AMIGOS dataset was obtained on
a scale of 1–9 for arousal and valence separately. However, for the DREAMER dataset, self-assessment rom subjects was acquired on the scale of 1–5 for both valence and arousal. The scale of 1–5 not only
exhibits half the freedom of choice on an intensity scale of emotion but also restricts the imbalance
created by avoiding the midpoint between 1–5 scale as participants can only provide integer data for
the intensity of arousal and valence. However, AMIGOS gives participants the liberty to self-assess
in a floating-point number for the scale of 1–9, hence better categorization of emotion can be made
which implied better performance of the algorithm on this dataset comparatively",,,63.67,,,,,,,,,,,,,,,,,,,,,,,,
65,1,,"Greco, A., Marzi, C., Lanata, A., Scilingo, E. P., & Vanello, N. (2019, July). Combining electrodermal activity and speech analysis towards a more accurate emotion recognition system. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 229-232). IEEE.",2019.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Particularly, although EDA is one of
the most popular signals for measuring emotional arousal,
and the same processing methods have been successfully
applied in previous studies using emotional videos, images,
sounds, and touch [28]–[30], the recognition accuracy obtained in this case was not much higher than 50%. The cause
could be found in the altered respiration activity induced
by speech that affects ANS dynamics and covers up the
sympathetic arousal response",,,52.04,,,,,,,,,,,,,,,,,,,,,,,,
66,1,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,72,55.78,71.41,99.24,,,,,,,,,,,,,,,,,,,,,
66,2,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,58.52,54.74,51.19,51.76,,,,,,,,,,,,,,,,,,,,,
66,3,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,54.5,54.79,69.92,96.61,,,,,,,,,,,,,,,,,,,,,
66,4,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,51.9,53.67,61.32,71.53,,,,,,,,,,,,,,,,,,,,,
66,5,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,52.7,55.05,68.88,91.99,,,,,,,,,,,,,,,,,,,,,
66,6,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,50.8,56.86,57.51,58.18,,,,,,,,,,,,,,,,,,,,,
66,7,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,75,66.1,79.3,99.2,,,,,,,,,,,,,,,,,,,,,
66,8,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,54.05,49.88,49.87,49.86,,,,,,,,,,,,,,,,,,,,,
66,9,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,64.4,66.05,78.25,95.9,,,,,,,,,,,,,,,,,,,,,
66,10,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,65.5,64.34,78.3,100,,,,,,,,,,,,,,,,,,,,,
66,12,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,63.3,64.14,77.13,96.71,,,,,,,,,,,,,,,,,,,,,
66,12,,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020.0,dimensional,x,2,"HA, LA",x,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,63.28,64.19,77.25,96.96,,,,,,,,,,,,,,,,,,,,,
67,1,,"Lee, S., Lee, T., Yang, T., Yoon, C., & Kim, S. P. (2020). Detection of drivers’ anxiety invoked by driving situations using multimodal biosignals. Processes, 8(2), 155.",2020.0,categorical,x,2,"anxiety, neutral",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,42.53,,,,,,,,,,,,,,,,,,,,,,,,
68,1,,"García-Faura, Á., Hernández-García, A., Fernández-Martínez, F., Díaz-de-María, F., & San-Segundo, R. (2019, January). Emotion and attention: Audiovisual models for group-level skin response recognition in short movies. In Web Intelligence (Vol. 17, No. 1, pp. 29-40). IOS Press.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,x,,,,,,,,,,,,,,,,,,-,-,,,74.86,,,,,,,,,,,,,,,,,,,,,,,,
69,1,,"Wei, W., Jia, Q., Feng, Y., & Chen, G. (2018). Emotion recognition based on weighted fusion strategy of multichannel physiological signals. Computational intelligence and neuroscience, 2018.",2018.0,categorical,x,5,"sadness, happiness, disgust, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,57.69,,,,,,,,,,,,,,,,,,,,,,,,
70,1,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"happy, neutral, sad",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,93,,,,,,,,,,,,,,,,,,,,,,,,
70,2,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"happy, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,92.3,,,,,,,,,,,,,,,,,,,,,,,,
70,3,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"happy, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,93,,,,,,,,,,,,,,,,,,,,,,,,
70,4,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"excited, calm, sleepy",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,91.3,,,,,,,,,,,,,,,,,,,,,,,,
70,5,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"excited, calm, sleepy",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,90.3,,,,,,,,,,,,,,,,,,,,,,,,
70,6,,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019.0,dimensional,x,3,"excited, calm, sleepy",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,92,,,,,,,,,,,,,,,,,,,,,,,,
71,1,,"Tung, K., Liu, P. K., Chuang, Y. C., Wang, S. H., & Wu, A. Y. A. (2018, December). Entropy-assisted multi-modal emotion recognition framework based on physiological signals. In 2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 22-26). IEEE.",2019.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,69.2,,,,,,,,,,,,,,,,,,,,,,
71,2,,"Tung, K., Liu, P. K., Chuang, Y. C., Wang, S. H., & Wu, A. Y. A. (2018, December). Entropy-assisted multi-modal emotion recognition framework based on physiological signals. In 2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 22-26). IEEE.",2019.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,79.6,,,,,,,,,,,,,,,,,,,,,,
72,1,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020.0,dimensional,x,3,"stressful, normal, relaxing",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,81.81,,,,,,,,,,,,,,,,,,,,,,,,
72,2,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020.0,dimensional,x,3,"stressful, normal, relaxing",,,,,,,,,,,,,,,,,x,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,71.21,,,,,,,,,,,,,,,,,,,,,,,,
72,3,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020.0,dimensional,x,3,"stressful, normal, relaxing",,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,67.05,,,,,,,,,,,,,,,,,,,,,,,,
72,4,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020.0,dimensional,x,3,"stressful, normal, relaxing",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,70.16,,,,,,,,,,,,,,,,,,,,,,,,
72,5,,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020.0,dimensional,x,3,"stressful, normal, relaxing",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,73.2,,,,,,,,,,,,,,,,,,,,,,,,
73,1,,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019.0,categorical,x,6,"sad, angry, happy, surprise, fear, disgust ",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,46.94,43.16,41.46,,,,,,,,,,,,,,,,,,,,,
73,2,,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019.0,categorical,x,6,"sad, angry, happy, surprise, feadr, disgust ",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,71.32,72.06,76.99,,,,,,,,,,,,,,,,,,,,,
73,3,,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019.0,categorical,x,6,"sad, angry, happy, surprise, feadr, disgust ",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,71.89,74.28,77.34,,,,,,,,,,,,,,,,,,,,,
74,1,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HV, LV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,53.8,,,,,,,,,,,,,,,,,,,,,,,,
74,2,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,64,,,,,,,,,,,,,,,,,,,,,,,,
74,3,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,77.6,,,,,,,,,,,,,,,,,,,,,,,,
74,4,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,82.2,,,,,,,,,,,,,,,,,,,,,,,,
74,5,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HA, LA",,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,55.3,,,,,,,,,,,,,,,,,,,,,,,,
74,6,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HA, LA",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,64.4,,,,,,,,,,,,,,,,,,,,,,,,
74,7,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,68.2,,,,,,,,,,,,,,,,,,,,,,,,
74,8,,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,69.4,,,,,,,,,,,,,,,,,,,,,,,,
75,1,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,21.21,,,,,,,,,,,,,,,,,,,,,,,,
75,2,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,18.63,,,,,,,,,,,,,,,,,,,,,,,,
75,3,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,31.19,,,,,,,,,,,,,,,,,,,,,,,,
75,4,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,58.7,,,,,,,,,,,,,,,,,,,,,,,,
75,5,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,46.78,,,,,,,,,,,,,,,,,,,,,,,,
75,6,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,60.24,,,,,,,,,,,,,,,,,,,,,,,,
75,7,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,21.21,,,,,,,,,,,,,,,,,,,,,,,,
75,8,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,18.63,,,,,,,,,,,,,,,,,,,,,,,,
75,9,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,31.19,,,,,,,,,,,,,,,,,,,,,,,,
75,10,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, anger",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,42.45,,,,,,,,,,,,,,,,,,,,,,,,
75,11,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, anger",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,42.43,,,,,,,,,,,,,,,,,,,,,,,,
75,12,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, anger",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,63.95,,,,,,,,,,,,,,,,,,,,,,,,
75,13,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,50.7,,,,,,,,,,,,,,,,,,,,,,,,
75,14,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,45.37,,,,,,,,,,,,,,,,,,,,,,,,
75,15,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, fear",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,33.67,,,,,,,,,,,,,,,,,,,,,,,,
75,16,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, disgust",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,39.06,,,,,,,,,,,,,,,,,,,,,,,,
75,17,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, disgust",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,39.58,,,,,,,,,,,,,,,,,,,,,,,,
75,18,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, disgust",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,57.71,,,,,,,,,,,,,,,,,,,,,,,,
75,19,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,45.08,,,,,,,,,,,,,,,,,,,,,,,,
75,20,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,41.73,,,,,,,,,,,,,,,,,,,,,,,,
75,21,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"joy, neutral, sad",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,63.16,,,,,,,,,,,,,,,,,,,,,,,,
75,22,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, anger",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,48.68,,,,,,,,,,,,,,,,,,,,,,,,
75,23,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, anger",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,47.56,,,,,,,,,,,,,,,,,,,,,,,,
75,24,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, anger",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,67.69,,,,,,,,,,,,,,,,,,,,,,,,
75,25,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,47.71,,,,,,,,,,,,,,,,,,,,,,,,
75,26,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,47.39,,,,,,,,,,,,,,,,,,,,,,,,
75,27,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, fear",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,62.42,,,,,,,,,,,,,,,,,,,,,,,,
75,28,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, disgust",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,46.23,,,,,,,,,,,,,,,,,,,,,,,,
75,29,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, disgust",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,43.76,,,,,,,,,,,,,,,,,,,,,,,,
75,30,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, disgust",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,63.55,,,,,,,,,,,,,,,,,,,,,,,,
75,31,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,44.06,,,,,,,,,,,,,,,,,,,,,,,,
75,32,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,46.25,,,,,,,,,,,,,,,,,,,,,,,,
75,33,,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019.0,categorical,x,3,"funny, neutral, sad",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,,61.99,,,,,,,,,,,,,,,,,,,,,,,,
76,1,,"Thammasan, N., Hagad, J. L., Fukui, K. I., & Numao, M. (2017, October). Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals. In 2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) (pp. 44-49). IEEE.",2018.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,,,,0.273,,,,,,,
76,2,,"Thammasan, N., Hagad, J. L., Fukui, K. I., & Numao, M. (2017, October). Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals. In 2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) (pp. 44-49). IEEE.",2018.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,,,,0.371,,,,,,,
77,1,,"Pinto, G., Carvalho, J. M., Barros, F., Soares, S. C., Pinho, A. J., & Brás, S. (2020). Multimodal emotion evaluation: A physiological model for cost-effective emotion classification. Sensors, 20(12), 3510.",2020.0,categorical,x,3,"neutral, fear, happy",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"This research analyzed the physiological component of emotion in different emotional conditions
(fear, happiness and neutral), using automatic systems for emotion identification. Our results suggest
that the ECG signal seems to be the most informative in emotion stratification. The use of facial EMG
in emotion is dependent on monitoring two (or more) muscles, allowing to identify facial expression
changes by corresponding muscular contractions. Nevertheless, if all signals are used on emotion
identification, a higher accuracy is achieved, since all signals are representative of different information.
This physiological model of emotions has important research and clinical implications, by providing
valuable information about the value and weight of physiological signals for emotional classification,
which can critically drive effective evaluation, monitoring, and intervention regarding emotional
processing and regulation, considering multiple contexts",,,,,58,,,,,,,,,,,,,,,,,,,,,,
77,2,,"Pinto, G., Carvalho, J. M., Barros, F., Soares, S. C., Pinho, A. J., & Brás, S. (2020). Multimodal emotion evaluation: A physiological model for cost-effective emotion classification. Sensors, 20(12), 3510.",2020.0,categorical,x,3,"neutral, fear, happy",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"This research analyzed the physiological component of emotion in different emotional conditions
(fear, happiness and neutral), using automatic systems for emotion identification. Our results suggest
that the ECG signal seems to be the most informative in emotion stratification. The use of facial EMG
in emotion is dependent on monitoring two (or more) muscles, allowing to identify facial expression
changes by corresponding muscular contractions. Nevertheless, if all signals are used on emotion
identification, a higher accuracy is achieved, since all signals are representative of different information.
This physiological model of emotions has important research and clinical implications, by providing
valuable information about the value and weight of physiological signals for emotional classification,
which can critically drive effective evaluation, monitoring, and intervention regarding emotional
processing and regulation, considering multiple contexts",,,,,62,,,,,,,,,,,,,,,,,,,,,,
78,1,,"Raheel, A., Majid, M., Alnowami, M., & Anwar, S. M. (2020). Physiological sensors based emotion recognition while experiencing tactile enhanced multimedia. Sensors, 20(14), 4037.",2020.0,categorical,x,4,"happy, relaxed, angry, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"While our study shows that with TEM, the emotion
recognition accuracy increases, which could mean that the users were able to better feel the emotions
as the video content intended to deliver. The use of physiological sensors also ensures that the true
sensation of emotion is detected which is subjectively independent of users.",,,72.61,,,,,,,,,,,,,,,,,,,,,,,,
79,1,,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019.0,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,65.38,,,,,,,,,,,,,,,,,,,,,,,,
79,2,,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019.0,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,87.5,,,,,,,,,,,,,,,,,,,,,,,,
79,3,,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019.0,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,78.22,,,,,,,,,,,,,,,,,,,,,,,,
79,4,,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019.0,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,89,,,,,,,,,,,,,,,,,,,,,,,,
80,1,,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,x,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.139,0.063,,,,,,,,,
80,2,,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,x,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.141,0.017,,,,,,,,,
80,3,,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,x,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.186,0.011,,,,,,,,,
80,4,,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,x,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.194,0.04,,,,,,,,,
81,1,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,-,-,-,-,-,,,62,,,,,,,,,,,,,,,,,,,,,,,,
81,2,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,-,-,-,-,-,,,77,,,,,,,,,,,,,,,,,,,,,,,,
81,3,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,-,-,-,-,-,,,71,,,,,,,,,,,,,,,,,,,,,,,,
81,4,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,78,,,,,,,,,,,,,,,,,,,,,,,,
81,5,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,-,-,-,-,-,,,51,,,,,,,,,,,,,,,,,,,,,,,,
81,6,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,-,-,-,-,-,,,65,,,,,,,,,,,,,,,,,,,,,,,,
81,7,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,-,-,-,-,-,,,51,,,,,,,,,,,,,,,,,,,,,,,,
81,8,,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,62,,,,,,,,,,,,,,,,,,,,,,,,
82,1,,"Santamaria-Granados, L., Munoz-Organero, M., Ramirez-Gonzalez, G., Abdulhay, E., & Arunkumar, N. J. I. A. (2018). Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMIGOS). IEEE Access, 7, 57-67.",2019.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Physiological datasets with a large number of instances are
optimal for the proposed experiments since these directly
influence the emotion prediction, a the greater the number
of instances, the more effective the model. Consequently,
several annotations of arousal and valence must be recorded,
since, when subjecting a participant to the stimulus of a short
video, it can manifest different levels of emotion during of
experiment.",,,69,,,,,,,,,,,,,,,,,,,,,,,,
82,2,,"Santamaria-Granados, L., Munoz-Organero, M., Ramirez-Gonzalez, G., Abdulhay, E., & Arunkumar, N. J. I. A. (2018). Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMIGOS). IEEE Access, 7, 57-67.",2019.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Physiological datasets with a large number of instances are
optimal for the proposed experiments since these directly
influence the emotion prediction, a the greater the number
of instances, the more effective the model. Consequently,
several annotations of arousal and valence must be recorded,
since, when subjecting a participant to the stimulus of a short
video, it can manifest different levels of emotion during of
experiment.",,,67,,,,,,,,,,,,,,,,,,,,,,,,
83,1,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,x,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.037,,,,,,,,,,
83,2,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,x,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.027,,,,,,,,,,
83,3,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,x,,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.026,,,,,,,,,,
83,4,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,x,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.026,,,,,,,,,,
83,5,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,x,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.035,,,,,,,,,,
83,6,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,x,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.019,,,,,,,,,,
83,7,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,x,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.047,,,,,,,,,,
83,8,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,x,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.023,,,,,,,,,,
83,9,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,x,,,,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.043,,,,,,,,,,
83,10,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,x,,,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.043,,,,,,,,,,
83,11,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,x,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.055,,,,,,,,,,
83,12,,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019.0,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,x,,,,,,,,,,-,-,-,-,-,,,,,,,,,,,,,,,,,0.027,,,,,,,,,,
84,1,,"Liapis, A., Katsanos, C., Karousos, N., Xenos, M., & Orphanoudakis, T. (2019, September). UDSP+ stress detection based on user-reported emotional ratings and wearable skin conductance sensor. In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers (pp. 125-128).",2019.0,dimensional,x,2,"stress, not stress",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,86.4,,,,,,,,,,,,,,,,,,,,,,,,
84,2,,"Liapis, A., Katsanos, C., Karousos, N., Xenos, M., & Orphanoudakis, T. (2019, September). UDSP+ stress detection based on user-reported emotional ratings and wearable skin conductance sensor. In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers (pp. 125-128).",2019.0,dimensional,x,2,"stress, not stress",,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,85.2,,,,,,,,,,,,,,,,,,,,,,,,
85,1,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,70.1,,,,,,,,,,,,,,,,,,,,,,,,
85,2,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,65.83,,,,,,,,,,,,,,,,,,,,,,,,
85,3,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,X,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,71.2,,,,,,,,,,,,,,,,,,,,,,,,
85,4,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,X,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,63.19,,,,,,,,,,,,,,,,,,,,,,,,
85,5,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,63.26,,,,,,,,,,,,,,,,,,,,,,,,
85,6,,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018.0,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,,51.13,,,,,,,,,,,,,,,,,,,,,,,,
86,1,,"Ganapathy, N., & Swaminathan, R. (2020). Emotion Analysis Using Electrodermal Signals and Spiking Deep Belief Network. In Digital Personalized Health and Medicine (pp. 1269-1270). IOS Press.",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,72.08,74.7,,83.23,,,,,,,,,,,,,,,,,,,,,
86,2,,"Ganapathy, N., & Swaminathan, R. (2020). Emotion Analysis Using Electrodermal Signals and Spiking Deep Belief Network. In Digital Personalized Health and Medicine (pp. 1269-1270). IOS Press.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,68.9,50.96,,61.26,,,,,,,,,,,,,,,,,,,,,
87,1,,"Yasemin, M., Sarıkaya, M. A., & Ince, G. (2019, July). Emotional state estimation using sensor fusion of EEG and EDA. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 5609-5612). IEEE.",2019.0,categorical,x,3,"funny, horror, weepy",,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,73.8,,,,,,,,,,,,,,,,,,,,,,,,
88,1,,"Ghiasi, S., Greco, A., Barbieri, R., Scilingo, E. P., & Valenza, G. (2020). Assessing autonomic function from electrodermal activity and heart rate variability during cold-pressor test and emotional challenge. Scientific reports, 10(1), 1-13.",2020.0,dimensional,x,2,"pleasent, unpleasent",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x," relevant information on the ANS activity can be retrieved from the superimposed phasic behavior of
HRV time-varying bispectral measures. Furthermore, the proposed new indices characterizing the cardiovascular
control through EDA and HRV seem to provide a more effective indicator of the sympathovagal balance then
traditional indices from HRV series onl",,,68.48,,,,,,,,,,,,,,,,,,,,,,,,
89,1,,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020.0,dimensional,x,2,"pleasant, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,57.41,,57,,,,,,,,,,,,,,,,,,,,,,
89,2,,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020.0,dimensional,x,2,"pleasant, neutral",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,56.37,,56,,,,,,,,,,,,,,,,,,,,,,
89,3,,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020.0,dimensional,x,2,"neutral, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,56.55,,57,,,,,,,,,,,,,,,,,,,,,,
89,4,,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020.0,dimensional,x,3,"pleasant, neutral, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,38.32,,5,,,,,,,,,,,,,,,,,,,,,,
90,1,,"Katada, S., Okada, S., Hirano, Y., & Komatani, K. (2020, October). Is She Truly Enjoying the Conversation? Analysis of Physiological Signals toward Adaptive Dialogue Systems. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 315-323).",2020.0,dimensional,x,2,"high enjoy, low enjoy",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,,,61.6,,,,,,,,,,,,,,,,,,,,,,,,
90,2,,"Katada, S., Okada, S., Hirano, Y., & Komatani, K. (2020, October). Is She Truly Enjoying the Conversation? Analysis of Physiological Signals toward Adaptive Dialogue Systems. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 315-323).",2020.0,dimensional,x,2,"high enjoy, low enjoy",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,-,-,-,-,,,62.2,,,,,,,,,,,,,,,,,,,,,,,,
91,1,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,59.71,,,,,,,,,,,,,,,,,,,,,,,,
91,2,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,59.77,,,,,,,,,,,,,,,,,,,,,,,,
91,3,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,60.16,,,,,,,,,,,,,,,,,,,,,,,,
91,4,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,59.78,,,,,,,,,,,,,,,,,,,,,,,,
91,5,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,60,,,,,,,,,,,,,,,,,,,,,,,,
91,6,,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,60.47,,,,,,,,,,,,,,,,,,,,,,,,
92,1,,"Rahman, J. S., Hossain, M. Z., & Gedeon, T. (2019, December). Measuring Observers' EDA Responses to Emotional Videos. In Proceedings of the 31st Australian Conference on Human-Computer-Interaction (pp. 457-461).",2019.0,categorical,x,7,"surprise, sad, neutral, happy, fear, disgust, anger",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"the initial analysis also shows some noticeable difference
of our data driven arousal model from our observers’ perspective, when compared to the (abstract) standard models
in the literature. The data-derived model with neutral as the
baseline is quite similar to the standard abstract model, with
the only changes being Happy and Sad changing sides as
Low/High arousal. Further analysis will be conducted and
evaluated to identify the reasons. Questions to be answered
are whether the dataset was biased, whether our 20 participants were somehow different from the expected population
reaction, or whether the abstract model is just incorrect. It
is also important to point out that EDA activity can vary
according to the difference in stimuli types, participants’ age,
gender etc [6]. Also the number of samples might be considered small, although experiments have shown that it is
reasonable [9]. Arguably, it makes more sense to use the overall average reaction to be the baseline between high and low
arousal, which spreads the emotional reactions over a wider
range. This differs more from the standard model.",,,94.8,75.3,84.2,95.8,94.7,,,,,,,,,,,,,,0.952,,,,,,
93,1,,"Rahim, A., Sagheer, A., Nadeem, K., Dar, M. N., Rahim, A., & Akram, U. (2019, October). Emotion Charting Using Real-time Monitoring of Physiological Signals. In 2019 International Conference on Robotics and Automation in Industry (ICRAI) (pp. 1-5). IEEE.",2020.0,categorical,x,7,"anger, disgust, fear, happy, neutral, sad, surprise",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,92.7,,,,,,,,,,,,,,,,,,,,,,,,
93,2,,"Rahim, A., Sagheer, A., Nadeem, K., Dar, M. N., Rahim, A., & Akram, U. (2019, October). Emotion Charting Using Real-time Monitoring of Physiological Signals. In 2019 International Conference on Robotics and Automation in Industry (ICRAI) (pp. 1-5). IEEE.",2020.0,categorical,x,7,"anger, disgust, fear, happy, neutral, sad, surprise",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,68,,,,,,,,,,,,,,,,,,,,,,,,
94,1,,"Yin, G., Sun, S., Zhang, H., Yu, D., Li, C., Zhang, K., & Zou, N. (2019, September). User Independent Emotion Recognition with Residual Signal-Image Network. In 2019 IEEE International Conference on Image Processing (ICIP) (pp. 3277-3281). IEEE.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,55.92,,58.83,,,,,,,,,,,,,,,,,,,,,,
94,2,,"Yin, G., Sun, S., Zhang, H., Yu, D., Li, C., Zhang, K., & Zou, N. (2019, September). User Independent Emotion Recognition with Residual Signal-Image Network. In 2019 IEEE International Conference on Image Processing (ICIP) (pp. 3277-3281). IEEE.",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,57.24,,60.12,,,,,,,,,,,,,,,,,,,,,,
95,1,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.566,,,,,,,,
95,2,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.555,,,,,,,,
95,3,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.587,,,,,,,,
95,4,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.56,,,,,,,,
95,5,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.628,,,,,,,,
95,6,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.544,,,,,,,,
95,7,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.535,,,,,,,,
95,8,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.55,,,,,,,,
95,9,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.54,,,,,,,,
95,10,,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,,,,,,,,,,,,,,,,,,0.567,,,,,,,,
96,1,,"Kołodziej, M., Tarnowski, P., Majkowski, A., & Rak, R. J. (2019). Electrodermal activity measurements for detection of emotional arousal. Bulletin of the Polish Academy of Sciences. Technical Sciences, 67(4).",2020.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The best features that were repeated
in the selection results were: MaxAmpPeak, VarAmpPeak,
StdAmpPeak, MaxAbsAmpPeak, VarSC, StdSC, ActivitySC,
MaxDeltaForward, MaxDeltaBack, KurtosisAmpPeak,
SkewnessAmpPeak. These features are related to the maximum
values, energy or statistical properties of the phasic component.
The results indicate that such features should be used in the
analysis of the EDA for the level of arousal recognition. Of
great importance is the quality of the recorded SC signals and
the pre-processing methods. In conjunction with the features
of other physiological signals (such as ECG, EEG, and EMG),
the proposed analysis can produce better results.",,,79,78.38,77.85,77.33,77.78,,,,,,,,,,,,,,,,,,,,
97,1,,"Ganapathy, N., & Swaminathan, R. (2019). Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolution Neural Network. Studies in health technology and informatics, 258, 140-140.",2020.0,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,65.63,65.76,72.63,81.11,,,,,,,,,,,,,,,,,,,,,
97,2,,"Ganapathy, N., & Swaminathan, R. (2019). Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolution Neural Network. Studies in health technology and informatics, 258, 140-140.",2020.0,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,68.75,45.41,50,55.6,,,,,,,,,,,,,,,,,,,,,
98,1,,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018.0,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,64,,,,,,,,,,,,,,,,,,,,,,
98,2,,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018.0,dimensional,x,2,"HV, LV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,68,,,,,,,,,,,,,,,,,,,,,,
98,3,,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018.0,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,61,,,,,,,,,,,,,,,,,,,,,,
98,4,,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018.0,dimensional,x,2,"HA, LA",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,,,,66,,,,,,,,,,,,,,,,,,,,,,
99,1,,"Yun, H., Fortenbacher, A., Helbig, R., & Pinkwart, N. (2019). In Search of Learning Indicators: A Study on Sensor Data and IAPS Emotional Pictures. In CSEDU (2) (pp. 111-121).",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,,,,,,,,,,,,,,,,,,,,,,,,,,
99,2,,"Yun, H., Fortenbacher, A., Helbig, R., & Pinkwart, N. (2019). In Search of Learning Indicators: A Study on Sensor Data and IAPS Emotional Pictures. In CSEDU (2) (pp. 111-121).",2019.0,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,,,,,,,,,,,,,,,,,,,,,,,,,,
100,1,10.1016/j.trf.2024.12.031,"Kim, T., Kim, S., Lee, M., Kang, Y., & Hwang, S. (2025). Assessing human emotional experience in pedestrian environments using wearable sensing and machine learning with anomaly detection. Transportation Research Part F: Traffic Psychology and Behaviour, 109, 540-555.",,Dimensional,x,3,Pleasant; Neutral; Unpleasant,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3036,-,-,-,-,0.5497,-,0.7011,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,,yes,include,participants were equipped with wearable devices and collected data along the designated walking path. The wearable device used was the “Empatica E4”
101,1,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.821,0.795,0.798,0.783,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,2,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.835,0.81,0.798,0.786,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,3,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.792,0.762,0.756,0.75,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,4,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.81,0.78,0.775,0.77,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,5,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.831,0.803,0.795,0.787,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,6,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.805,0.775,0.768,0.761,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,7,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.843,0.815,0.802,0.789,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
101,8,10.3390/s24248130,"Mercado-Diaz, L. R., Veeranki, Y. R., Large, E. W., & Posada-Quintero, H. F. (2024). Fractal Analysis of Electrodermal Activity for Emotion Recognition: A Novel Approach Using Detrended Fluctuation Analysis and Wavelet Entropy. Sensors, 24(24), 8130.",,Dimensional,x,5,Neutral; Amused; Bored; Relaxed; Scared,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that wavelet entropy features were particularly effective in differentiating emotional states, suggesting that these features capture the complexity of EDA signals across multiple time scales.",-,-,0.808,0.778,0.771,0.764,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study exclusively uses EDA signals for emotion recognition and presents unimodal models.
102,1,10.1109/TVCG.2024.3372101,"Li, M., Pan, J., Li, Y., Gao, Y., Qin, H., & Shen, Y. (2024). Multimodal physiological analysis of impact of emotion on cognitive control in VR. IEEE Transactions on Visualization and Computer Graphics.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,,-,-,0.7088,-,0.6451,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA and includes EDA-only models for emotion prediction.
102,2,10.1109/TVCG.2024.3372101,"Li, M., Pan, J., Li, Y., Gao, Y., Qin, H., & Shen, Y. (2024). Multimodal physiological analysis of impact of emotion on cognitive control in VR. IEEE Transactions on Visualization and Computer Graphics.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,,-,-,0.7103,-,0.6488,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA and includes EDA-only models for emotion prediction.
103,1,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",-,-,0.55,-,0.71,1,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,.. The study evaluated the performance of these classifiers in characterizing emotional dimensions (arousal and valence) using phasic EDA signals only.”
103,2,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",-,-,0.55,-,0.66,0.8,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,.. The study evaluated the performance of these classifiers in characterizing emotional dimensions (arousal and valence) using phasic EDA signals only.”
103,3,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,,,,,,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,0.53,-,0.61,0.68,,,,,,,,,,,,,,,,,Tomi,,yes,include,
103,4,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Multi layer perceptron,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,0.52,-,0.61,0.71,,,,,,,,,,,,,,,,,Tomi,,yes,include,
103,5,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,-,0.58,0.72,1,,,,,,,,,,,,,,,,,Tomi,,yes,include,
103,6,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,-,-,0.68,-,-,,,,,,,,,,,,,,,,Tomi,,yes,include,
103,7,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,,,,,,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,-,-,0.63,0.75,,,,,,,,,,,,,,,,,Tomi,,yes,include,
103,8,10.1016/j.irbm.2024.100849,"Veeranki, Y. R., Posada-Quintero, H. F., & Swaminathan, R. (2024). Transition Network-Based Analysis of Electrodermal Activity Signals for Emotion Recognition. IRBM, 45(4), 100849.",,Dimensional,x,2,HA; LA,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Multi layer perceptron,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,1280,x,"Firstly, the EDA signals exhibit inherent non-linear characteristics, which are influenced by physiological factors like sweat gland density and sweat produc- tion per gland, introducing subject-specific variations. Recognizing these non-linear patterns and their dependency on individual pa- rameters is crucial for precise emotional state interpretation. This finding emphasizes the need for personalized models within af- fective computing systems to accommodate these inter-individual variances. The transformation of the phasic EDA component into binary sequences and subsequent conversion to decimal form represents a promising strategy for dimensionality reduction. This approach not only simplifies data representation but also reduces computa- tional cost. Additionally, it is evident that binary sequence transi- tions within these symbolic representations respond dynamically to changes in the phasic component. This highlights the dynamic nature of emotional states and highlights the efficiency of symbol- ization in capturing these fluctuations in the EDA signal. The prob- ability distribution of symbolic patterns is distinct between HV, LV, HA, and LA dimensions. Patterns such as “000” and “111” have higher probabilities, indicating the presence of low frequency com- ponents in EDA signals. Also, the distinction between the arousal and the valence dimensions is evident from the probabilities of these patterns. “000” is more dominant in LA and LV, while “111” is more frequent in HA and HV dimensions. These results highlight the potential of symbolic patterns in discriminating low and high dimensions of emotions",,,-,0.57,0.64,0.79,,,,,,,,,,,,,,,,,Tomi,,yes,include,
104,1,10.1109/JSEN.2024.3354553,"Veeranki, Y. R., Mercado Diaz, L. R., Swaminathan, R., & Posada-Quintero, H. F. (2024). Nonlinear Signal Processing Methods for Automatic Emotion Recognition Using Electrodermal Activity. IEEE Sensors Journal, 24(6), 3354553.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The paper interprets the EDA-based predictive models by emphasizing that the nonlinear characteristics of the EDA signals arise from intrinsic physiological variabilities—such as differences in sweat gland density, secretion volume per gland, nerve fiber distribution, and conduction velocity—which in turn necessitate advanced signal processing techniques to accurately capture emotional dynamics. Specifically, isaxEDA is noted for its ability to capture rapid temporal fluctuations that reflect transient sympathetic responses, thereby effectively distinguishing short-term emotional changes, while comEDA’s analysis of signal complexity and regularity aligns with the modulation of emotional arousal linked to underlying autonomic control. Additionally, netEDA interprets the EDA signal as a network, revealing interaction patterns among signal elements that mirror the coordination of physiological responses during emotional experiences, and topEDA focuses on the geometric properties of the signal’s complex-plane representation, providing spatial insights that differentiate specific emotion-related patterns. Collectively, these interpretations underscore the idea that the computational features—such as skewness, Rényi entropy, area, and assortativity—derived from these nonlinear methods are not merely abstract metrics but are deeply connected to and reflective of the underlying autonomic and physiological processes that govern human emotional responses.",-,-,0.64,0.53,0.56,0.64,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study focuses on emotion recognition using EDA signals and does not combine EDA with other signals for any model. All models use only EDA features as input.
104,2,10.1109/JSEN.2024.3354553,"Veeranki, Y. R., Mercado Diaz, L. R., Swaminathan, R., & Posada-Quintero, H. F. (2024). Nonlinear Signal Processing Methods for Automatic Emotion Recognition Using Electrodermal Activity. IEEE Sensors Journal, 24(6), 3354553.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,x,"The paper interprets the EDA-based predictive models by emphasizing that the nonlinear characteristics of the EDA signals arise from intrinsic physiological variabilities—such as differences in sweat gland density, secretion volume per gland, nerve fiber distribution, and conduction velocity—which in turn necessitate advanced signal processing techniques to accurately capture emotional dynamics. Specifically, isaxEDA is noted for its ability to capture rapid temporal fluctuations that reflect transient sympathetic responses, thereby effectively distinguishing short-term emotional changes, while comEDA’s analysis of signal complexity and regularity aligns with the modulation of emotional arousal linked to underlying autonomic control. Additionally, netEDA interprets the EDA signal as a network, revealing interaction patterns among signal elements that mirror the coordination of physiological responses during emotional experiences, and topEDA focuses on the geometric properties of the signal’s complex-plane representation, providing spatial insights that differentiate specific emotion-related patterns. Collectively, these interpretations underscore the idea that the computational features—such as skewness, Rényi entropy, area, and assortativity—derived from these nonlinear methods are not merely abstract metrics but are deeply connected to and reflective of the underlying autonomic and physiological processes that govern human emotional responses.",,,0.65,0.64,0.64,0.65,,,,,,,,,,,,,,,,,Tomi,,yes,include,
104,3,10.1109/JSEN.2024.3354553,"Veeranki, Y. R., Mercado Diaz, L. R., Swaminathan, R., & Posada-Quintero, H. F. (2024). Nonlinear Signal Processing Methods for Automatic Emotion Recognition Using Electrodermal Activity. IEEE Sensors Journal, 24(6), 3354553.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,x,"The paper interprets the EDA-based predictive models by emphasizing that the nonlinear characteristics of the EDA signals arise from intrinsic physiological variabilities—such as differences in sweat gland density, secretion volume per gland, nerve fiber distribution, and conduction velocity—which in turn necessitate advanced signal processing techniques to accurately capture emotional dynamics. Specifically, isaxEDA is noted for its ability to capture rapid temporal fluctuations that reflect transient sympathetic responses, thereby effectively distinguishing short-term emotional changes, while comEDA’s analysis of signal complexity and regularity aligns with the modulation of emotional arousal linked to underlying autonomic control. Additionally, netEDA interprets the EDA signal as a network, revealing interaction patterns among signal elements that mirror the coordination of physiological responses during emotional experiences, and topEDA focuses on the geometric properties of the signal’s complex-plane representation, providing spatial insights that differentiate specific emotion-related patterns. Collectively, these interpretations underscore the idea that the computational features—such as skewness, Rényi entropy, area, and assortativity—derived from these nonlinear methods are not merely abstract metrics but are deeply connected to and reflective of the underlying autonomic and physiological processes that govern human emotional responses.",,,0.66,0.62,0.63,0.66,,,,,,,,,,,,,,,,,Tomi,,yes,include,
104,4,10.1109/JSEN.2024.3354553,"Veeranki, Y. R., Mercado Diaz, L. R., Swaminathan, R., & Posada-Quintero, H. F. (2024). Nonlinear Signal Processing Methods for Automatic Emotion Recognition Using Electrodermal Activity. IEEE Sensors Journal, 24(6), 3354553.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,x,"The paper interprets the EDA-based predictive models by emphasizing that the nonlinear characteristics of the EDA signals arise from intrinsic physiological variabilities—such as differences in sweat gland density, secretion volume per gland, nerve fiber distribution, and conduction velocity—which in turn necessitate advanced signal processing techniques to accurately capture emotional dynamics. Specifically, isaxEDA is noted for its ability to capture rapid temporal fluctuations that reflect transient sympathetic responses, thereby effectively distinguishing short-term emotional changes, while comEDA’s analysis of signal complexity and regularity aligns with the modulation of emotional arousal linked to underlying autonomic control. Additionally, netEDA interprets the EDA signal as a network, revealing interaction patterns among signal elements that mirror the coordination of physiological responses during emotional experiences, and topEDA focuses on the geometric properties of the signal’s complex-plane representation, providing spatial insights that differentiate specific emotion-related patterns. Collectively, these interpretations underscore the idea that the computational features—such as skewness, Rényi entropy, area, and assortativity—derived from these nonlinear methods are not merely abstract metrics but are deeply connected to and reflective of the underlying autonomic and physiological processes that govern human emotional responses.",,,0.69,0.36,0.65,0.69,,,,,,,,,,,,,,,,,Tomi,,yes,include,
105,1,10.1109/ACII55700.2022.9953862,"Surely, A., Taherzadeh, S., Misal, V., & Kleinsmith, A. (2022, October). Exploring Affective Dimension Perception from Bodily Expressions and Electrodermal Activity in Paramedic Simulation Training. In 2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,1,Valence,x,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1061,x,The model revealed that EDA statistically significantly predicted the VAD dimensions. An increase in EDA was associated with an increase in perceived arousal and a decrease in valence and dominance ratings.,-,-,-,-,-,-,-,-,-,-,0.2735,,,,,,0.341,-,-,-,-,-,Tomi,,yes,include,The study uses EDA data and focuses on emotion prediction using machine learning models.
105,2,10.1109/ACII55700.2022.9953862,"Surely, A., Taherzadeh, S., Misal, V., & Kleinsmith, A. (2022, October). Exploring Affective Dimension Perception from Bodily Expressions and Electrodermal Activity in Paramedic Simulation Training. In 2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Arousal,x,,,,,,,,,,,,,,,x,,1061,x,The model revealed that EDA statistically significantly predicted the VAD dimensions. An increase in EDA was associated with an increase in perceived arousal and a decrease in valence and dominance ratings.,,,,,,,,,,,0.181,,,,,,0.458,,,,,,,,yes,include,
105,3,10.1109/ACII55700.2022.9953862,"Surely, A., Taherzadeh, S., Misal, V., & Kleinsmith, A. (2022, October). Exploring Affective Dimension Perception from Bodily Expressions and Electrodermal Activity in Paramedic Simulation Training. In 2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Dominance,x,,,,,,,,,,,,,,,x,,1061,x,The model revealed that EDA statistically significantly predicted the VAD dimensions. An increase in EDA was associated with an increase in perceived arousal and a decrease in valence and dominance ratings.,,,,,,,,,,,0.083,-,-,-,-,-,0.413,,,,,,,,yes,include,
106,1,10.1038/s41597-024-03676-4,"Yang, P., Liu, N., Liu, X., Shu, Y., Ji, W., Ren, Z., ... & Liu, Y. J. (2024). A Multimodal Dataset for Mixed Emotion Recognition. Scientific Data, 11(1), 847.",,Dimensional,x,3,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2336,,,x,https://github.com/ypthu/Multimodal-dataset-for-mixed-emotion-recognition,-,-,-,-,-,-,-,-,,,,,,,,-,-,-,-,{},Tomi,"La performance aparece en un grafico, pero no da el numero concreto asi que lo deje vacio",yes,include,The study uses EDA (GSR) and includes models that use only EDA features as input.
106,2,10.1038/s41597-024-03676-4,"Yang, P., Liu, N., Liu, X., Shu, Y., Ji, W., Ren, Z., ... & Liu, Y. J. (2024). A Multimodal Dataset for Mixed Emotion Recognition. Scientific Data, 11(1), 847.",,Dimensional,x,3,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2336,,,x,https://github.com/ypthu/Multimodal-dataset-for-mixed-emotion-recognition,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,"La performance aparece en un grafico, pero no da el numero concreto asi que lo deje vacio",yes,include,The study uses EDA (GSR) and includes models that use only EDA features as input.
107,1,10.1515/cdbme-2021-2220,"Rao Veeranki, Y., Ganapathy, N., & Swaminathan, R. (2021). Electrodermal activity based emotion recognition using time-frequency methods and machine learning algorithms. Current Directions in Biomedical Engineering, 7(2), 863-866.",,Dimensional,x,2,Happy; Sad,-,,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.56,-,-,-,0.498,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents a machine learning model for emotion recognition.
107,2,10.1515/cdbme-2021-2220,"Rao Veeranki, Y., Ganapathy, N., & Swaminathan, R. (2021). Electrodermal activity based emotion recognition using time-frequency methods and machine learning algorithms. Current Directions in Biomedical Engineering, 7(2), 863-866.",,Dimensional,x,2,Happy; Sad,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,-,-,0.563,-,-,-,0.555,-,-,-,-,-,-,-,-,-,,,,,,,yes,include,
107,3,10.1515/cdbme-2021-2220,"Rao Veeranki, Y., Ganapathy, N., & Swaminathan, R. (2021). Electrodermal activity based emotion recognition using time-frequency methods and machine learning algorithms. Current Directions in Biomedical Engineering, 7(2), 863-866.",,Dimensional,x,2,Happy; Sad,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,-,-,0.469,-,-,-,0.469,-,-,-,-,-,-,-,-,-,,,,,,,yes,include,
107,4,10.1515/cdbme-2021-2220,"Rao Veeranki, Y., Ganapathy, N., & Swaminathan, R. (2021). Electrodermal activity based emotion recognition using time-frequency methods and machine learning algorithms. Current Directions in Biomedical Engineering, 7(2), 863-866.",,Dimensional,x,2,Happy; Sad,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,-,-,0.4684,-,-,-,0.417,-,-,-,-,-,-,-,-,-,,,,,,,yes,include,
108,1,10.1109/ICCCMLA58983.2023.10346619,"Ronickom, J. F. A. (2023, October). Enhancing emotion recognition: Machine learning with phasic spectrogram texture features. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 600-603). IEEE.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,x,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that texture features computed from spectrograms of the second half of the phasic signals helped to improve the classification of emotions, indicating its relevance for emotion classification.",-,-,,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,EDA signals were obtained from the continuously annotated signals of emotion (CASE) dataset
108,2,10.1109/ICCCMLA58983.2023.10346619,"Ronickom, J. F. A. (2023, October). Enhancing emotion recognition: Machine learning with phasic spectrogram texture features. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 600-603). IEEE.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that texture features computed from spectrograms of the second half of the phasic signals helped to improve the classification of emotions, indicating its relevance for emotion classification.",-,-,0.785,0.5731,0.5207,0.52,0.8461,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,EDA signals were obtained from the continuously annotated signals of emotion (CASE) dataset
108,3,10.1109/ICCCMLA58983.2023.10346619,"Ronickom, J. F. A. (2023, October). Enhancing emotion recognition: Machine learning with phasic spectrogram texture features. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 600-603). IEEE.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that texture features computed from spectrograms of the second half of the phasic signals helped to improve the classification of emotions, indicating its relevance for emotion classification.",-,-,,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,EDA signals were obtained from the continuously annotated signals of emotion (CASE) dataset
109,1,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the use of group-level information improves emotion recognition accuracy by leveraging physiological synchrony between individuals. This approach aligns with dimensional theories of emotion, where continuous dimensions like arousal and valence are used to characterize emotional states.",-,-,0.7018,-,0.6825,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,dataset  AMIGOS,yes,include,The study uses EDA data and focuses on emotion prediction using machine learning models.
109,2,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.5455,,0.5513,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,3,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.3726,,0.367,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,4,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.4137,,0.3769,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,5,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.7275,,0.6892,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,6,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.6186,,0.5695,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,7,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.6451,,0.6526,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,8,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.5246,,0.5217,,,,,,,,,,,,,,,,,,Tomi,dataset  AMIGOS,yes,include,
109,9,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.6962,,0.6788,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,10,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.9332,,0.906,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,11,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.6048,,0.6349,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,12,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.7087,,0.7683,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,13,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.7448,,0.7097,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,14,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.8476,,0.8683,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,15,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HA; LA,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.5765,,0.6127,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
109,16,10.1109/TAFFC.2023.3265433,"Bota, P., Zhang, T., El Ali, A., Fred, A., da Silva, H. P., & Cesar, P. (2023). Group synchrony for emotion recognition using physiological signals. IEEE Transactions on Affective Computing, 14(4), 2614-2625.",,Dimensional,x,2,HV; LV,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,-,,,,,0.7766,,0.8179,,,,,,,,,,,,,,,,,,Tomi,dataset K-EmoCon,yes,include,
110,1,10.1109/TIPTEKNO56568.2022.9960200,"Semerci, Y. C., Akgün, G., Toprak, E., & Barkana, D. E. (2022, October). A comparative analysis of deep learning methods for emotion recognition using physiological signals for robot-based intervention studies. In 2022 Medical Technologies Congress (TIPTEKNO) (pp. 1-4). IEEE.",,Dimensional,x,2,Pleasant; Unpleasant; Neutral,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.5254,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA (SC) data and evaluates models using only EDA features.
110,2,10.1109/TIPTEKNO56568.2022.9960200,"Semerci, Y. C., Akgün, G., Toprak, E., & Barkana, D. E. (2022, October). A comparative analysis of deep learning methods for emotion recognition using physiological signals for robot-based intervention studies. In 2022 Medical Technologies Congress (TIPTEKNO) (pp. 1-4). IEEE.",,Dimensional,x,2,Pleasant; Unpleasant; Neutral,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA (SC) data and evaluates models using only EDA features.
111,1,10.34107/YHPN9422.04322,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2021). Differentiation of dichotomous emotional states in electrodermal activity signals using higher-order crossing features and parametric classifiers. Biomed. Sci. Instr, 57(2), 322-332.",,Dimensional,x,2,Happy; Sad,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The study found that higher-order crossing features and Hjorth parameters were effective in distinguishing between happy and sad emotional states, supporting the use of EDA for emotion recognition.",-,-,0.714,0.703,0.714,0.714,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data exclusively for emotion classification without combining it with other signals.
111,2,10.34107/YHPN9422.04322,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2021). Differentiation of dichotomous emotional states in electrodermal activity signals using higher-order crossing features and parametric classifiers. Biomed. Sci. Instr, 57(2), 322-332.",,Dimensional,x,2,Happy; Sad,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.571,0.574,0.571,0.571,,,,,,,,,,,,,,,,,Tomi,,yes,include,
111,3,10.34107/YHPN9422.04322,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2021). Differentiation of dichotomous emotional states in electrodermal activity signals using higher-order crossing features and parametric classifiers. Biomed. Sci. Instr, 57(2), 322-332.",,Dimensional,x,2,Happy; Sad,-,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,-,,,,,,,,,,,,,,,,,,,x,,,,,,,0.665,0.666,0.667,0.667,,,,,,,,,,,,,,,,,Tomi,,yes,include,
111,4,10.34107/YHPN9422.04322,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2021). Differentiation of dichotomous emotional states in electrodermal activity signals using higher-order crossing features and parametric classifiers. Biomed. Sci. Instr, 57(2), 322-332.",,Dimensional,x,2,Happy; Sad,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Multi layer perceptron,,,,,,,,,,,,,,,,,,,x,,,,,,,0.857,0.86,0.856,0.857,,,,,,,,,,,,,,,,,Tomi,,yes,include,
112,1,10.1149/10701.12535ecst,"Dutta, S., Mishra, B. K., Mitra, A., & Chakraborty, A. (2022). An analysis of emotion recognition based on GSR signal. ECS Transactions, 107(1), 12535.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.4,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The current work has used GSR signals for emotion detection. The GSR sensor helps us to measure the activity of the sweat gland. These activities are very much related to the emotion arousal.
112,2,10.1149/10701.12535ecst,"Dutta, S., Mishra, B. K., Mitra, A., & Chakraborty, A. (2022). An analysis of emotion recognition based on GSR signal. ECS Transactions, 107(1), 12535.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.38,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The current work has used GSR signals for emotion detection. The GSR sensor helps us to measure the activity of the sweat gland. These activities are very much related to the emotion arousal.
112,3,10.1149/10701.12535ecst,"Dutta, S., Mishra, B. K., Mitra, A., & Chakraborty, A. (2022). An analysis of emotion recognition based on GSR signal. ECS Transactions, 107(1), 12535.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.42,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The current work has used GSR signals for emotion detection. The GSR sensor helps us to measure the activity of the sweat gland. These activities are very much related to the emotion arousal.
113,1,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,5,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6585,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,2,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6952,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,3,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Engagement; Low Engagement,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6512,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,4,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Liking; Low Liking,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.521,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,5,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Familiarity; Low Familiarity,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5328,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,6,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6534,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,7,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6485,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,8,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Engagement; Low Engagement,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6234,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,9,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Liking; Low Liking,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6385,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,10,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Familiarity; Low Familiarity,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5945,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,11,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.4515,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,12,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.4615,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,13,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Engagement; Low Engagement,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.4285,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,14,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Liking; Low Liking,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.4785,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,15,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Familiarity; Low Familiarity,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6238,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,16,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Double Deep Q‑learning (DDQ),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7896,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,17,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Double Deep Q‑learning (DDQ),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7952,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,18,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Engagement; Low Engagement,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Double Deep Q‑learning (DDQ),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7852,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,19,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Liking; Low Liking,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Double Deep Q‑learning (DDQ),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7896,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
113,20,10.1007/s11277-023-10685-w,"Selvi, R., & Vijayakumaran, C. (2023). An efficient multimodal emotion identification using FOX optimized double deep Q-learning. Wireless Personal Communications, 132(4), 2387-2406.",,Dimensional,x,2,High Familiarity; Low Familiarity,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Double Deep Q‑learning (DDQ),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7865,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA (GSR) along with ECG and EEG, but it does not explicitly mention any unimodal EDA-only models in the text or tables."
114,1,10.1088/1742-6596/1878/1/012020,"Bulagang, A. F., Mountstephens, J., & Teo, J. (2021, May). Support Vector Machine Tuning for Improving Four-Quadrant Emotion Prediction in Virtual Reality (VR) using Wearable Electrodermography (EDG). In Journal of Physics: Conference Series (Vol. 1878, No. 1, p. 012020). IOP Publishing.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The study used Support Vector Machine (SVM) with tuned parameters to classify emotional states based on EDG signals. The results showed that SVM with higher parameter values achieved better accuracy, suggesting that the model effectively captured the emotional responses evoked by the VR stimuli.",-,-,0.544,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data exclusively for emotion prediction and presents results for EDA-only models.
115,1,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,,0.96,0.9,0.85,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,2,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,x,-,-,-,-,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,,1,0.98,0.96,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,3,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0,0,0,,,,,,,,,,,,,,,,,,,yes,include,
115,4,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0.58,0.73,1,,,,,,,,,,,,,,,,,,,yes,include,
115,5,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0.55,0.59,0.64,,,,,,,,,,,,,,,,,,,yes,include,
115,6,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0.88,0.9,0.93,,,,,,,,,,,,,,,,,,,yes,include,
115,7,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Categorical,x,2,Neutral; Disgust; Happy; Surprise; Anger; Fear; Sad,-,-,-,-,-,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,0.9213,0.9157,0.9071,0.943,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,8,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Categorical,x,7,Neutral; Disgust; Happy; Surprise; Anger; Fear; Sad,x,-,-,-,-,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,0.41,0.0586,0.0829,0.1429,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,9,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Categorical,x,7,Neutral; Disgust; Happy; Surprise; Anger; Fear; Sad,-,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,0.65,0.6429,0.5986,0.57,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,10,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,,0.97,0.96,0.95,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,11,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,,-,-,-,-,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,,0.93,0.94,0.96,,,,,,,,,,,,,,,,,Tomi,,yes,include,
115,12,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0.59,0.74,1,,,,,,,,,,,,,,,,,,,yes,include,
115,13,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0,0,0,,,,,,,,,,,,,,,,,,,yes,include,
115,14,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HA; LA,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,0.58,0.62,0.67,,,,,,,,,,,,,,,,,,,yes,include,
115,15,10.1016/j.bspc.2024.107039,"Kumar, A., & Kumar, A. (2025). Human emotion recognition using Machine learning techniques based on the physiological signal. Biomedical Signal Processing and Control, 100, 107039.",,Dimensional,x,2,HV; LV,-,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,-,-,,,GitHub repo: https://github.com/Akhilesh‑BHUCS/ML_Affective_Basic_Emotion.git,,,0.4,0.35,0.32,,,,,,,,,,,,,,,,,Tomi,,yes,include,
116,1,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.707,,0.68,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_DEAP_Valence,yes,include,
116,2,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7164,,0.65,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_DEAP_Arousal,yes,include,
116,3,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,High Liking; Low Liking,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7523,,0.64,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_DEAP_Liking,yes,include,
116,4,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.4594,,0.25,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_DEAP_Emotion,yes,include,
116,5,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8063,,0.79,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_AMIGOS_Valence,yes,include,
116,6,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8094,,0.74,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_AMIGOS_Arousal,yes,include,
116,7,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,High Liking; Low Liking,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8047,,0.72,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_AMIGOS_Liking,yes,include,
116,8,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.5641,,0.34,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_AMIGOS_Emotion,yes,include,
116,9,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7898,,0.73,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_MAHNOB-HCI_Valence,yes,include,
116,10,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8184,,0.75,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_MAHNOB-HCI_Arousal,yes,include,
116,11,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.5784,,0.32,,,,,,,,,,,,,,,,,,Tomi,TABLE III. GSR_MAHNOB-HCI_Emotion,yes,include,
116,12,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5964,-,0.58,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Valence_DEAP+AMIGOS,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,13,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6361,-,0.61,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Arousal_DEAP+AMIGOS,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,14,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,High Liking; Low Liking,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6927,-,0.55,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Liking_DEAP+AMIGOS,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,15,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.3724,-,0.31,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Emotion_DEAP+AMIGOS,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,16,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5898,-,0.57,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Valence_DEAP+AMIGOS+MAHNOB-HCI,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,17,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6102,-,0.59,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Arousal_DEAP+AMIGOS+MAHNOB-HCI,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,18,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; HVLA; LVHA; LVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.3571,-,0.28,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,TABLE V. GSR_Emotion_DEAP+AMIGOS+MAHNOB-HCI,yes,include,The study uses GSR (EDA) as one of the modalities and presents performance metrics for EDA-only models.
116,19,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6496,,0.55,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP+AMIGOS→MAHNOB‑HCI_Valence,yes,include,
116,20,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.625,,0.52,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP+AMIGOS→MAHNOB‑HCI_Arousal,yes,include,
116,21,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.3864,,0.28,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP+AMIGOS→MAHNOB‑HCI_Emotion,yes,include,
116,22,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6519,,0.47,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP→MAHNOB‑HCI_Valence,yes,include,
116,23,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6323,,0.52,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP→MAHNOB‑HCI_Arousal,yes,include,
116,24,10.1109/TAFFC.2019.2916015,"Jung, T. P., & Sejnowski, T. J. (2019). Utilizing deep learning towards multi-modal bio-sensing and vision-based affective computing. IEEE Transactions on Affective Computing, 13(1), 96-107.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.3908,,0.24,,,,,,,,,,,,,,,,,,Tomi,TABLE VI. GSR_DEAP→MAHNOB‑HCI_Emotion,yes,include,
117,1,10.1016/j.teler.2024.100131,"Saffaryazdi, N., Kirkcaldy, N., Lee, G., Loveys, K., Broadbent, E., & Billinghurst, M. (2024). Exploring the impact of computer-mediated emotional interactions on human facial and physiological responses. Telematics and Informatics Reports, 14, 100131.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.577,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
117,2,10.1016/j.teler.2024.100131,"Saffaryazdi, N., Kirkcaldy, N., Lee, G., Loveys, K., Broadbent, E., & Billinghurst, M. (2024). Exploring the impact of computer-mediated emotional interactions on human facial and physiological responses. Telematics and Informatics Reports, 14, 100131.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.616,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
118,1,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Anger,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,,-,-,-,0.6667,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,2,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.7,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,3,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.8,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,4,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.6667,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,5,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.8333,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,6,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Anger,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.7083,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,7,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.7917,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,8,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.6667,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,9,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.75,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,10,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.6,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,11,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Anger,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.75,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,12,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.7917,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,13,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.7917,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,14,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.8,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,15,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.8333,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,16,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,2,Happy; Anger,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.5667,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,17,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.4,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,18,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.4667,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,19,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.3056,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,20,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.4444,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,21,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.4,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
118,22,10.1109/IECBES48179.2021.9398844,"Nisa'Minhad, K., Ooi, K. J., Bhuiyan, M. A. S., Reaz, M. B. I., & Ali, S. H. M. (2021, March). Assessments of autonomic nervous system biomarker for emotion recognition using electrodermal activity signal. In 2020 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 351-355). IEEE.",,Dimensional,x,3,Happy; Anger; Recovery,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,-,-,-,0.5333,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents models that predict emotional states.
119,1,10.1109/ACCESS.2024.3361832,"Veeranki, Y. R., Ganapathy, N., Swaminathan, R., & Posada-Quintero, H. F. (2024). Comparison of electrodermal activity signal decomposition techniques for emotion recognition. IEEE Access, 12, 19952-19966.",,Dimensional,x,2,HA;LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors note that TVSymp captures larger phasic amplitude and faster fluctuations in high‐arousal and high‐valence states—patterns that mirror increased sweat‐gland activation and stronger sympathetic nervous system engagement when emotions are more intense or positive. By retaining these subtle time‐frequency dynamics, TVSymp not only distinguishes emotional dimensions more accurately but also aligns with the physiological principle that phasic EDA responses scale with sympathetic drive—providing both robust classification and a clear link to underlying autonomic mechanisms .",-,-,0.7452,0.7395,0.7279,0.7657,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs SVM classifiers, and reports performance metrics for both arousal and valence dimensions."
119,2,10.1109/ACCESS.2024.3361832,"Veeranki, Y. R., Ganapathy, N., Swaminathan, R., & Posada-Quintero, H. F. (2024). Comparison of electrodermal activity signal decomposition techniques for emotion recognition. IEEE Access, 12, 19952-19966.",,Dimensional,x,2,HV;LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors note that TVSymp captures larger phasic amplitude and faster fluctuations in high‐arousal and high‐valence states—patterns that mirror increased sweat‐gland activation and stronger sympathetic nervous system engagement when emotions are more intense or positive. By retaining these subtle time‐frequency dynamics, TVSymp not only distinguishes emotional dimensions more accurately but also aligns with the physiological principle that phasic EDA responses scale with sympathetic drive—providing both robust classification and a clear link to underlying autonomic mechanisms .",-,-,0.7214,0.7308,0.7349,0.774,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs SVM classifiers, and reports performance metrics for both arousal and valence dimensions."
119,3,10.1109/ACCESS.2024.3361832,"Veeranki, Y. R., Ganapathy, N., Swaminathan, R., & Posada-Quintero, H. F. (2024). Comparison of electrodermal activity signal decomposition techniques for emotion recognition. IEEE Access, 12, 19952-19966.",,Dimensional,x,2,HA;LA,-,,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors note that TVSymp captures larger phasic amplitude and faster fluctuations in high‐arousal and high‐valence states—patterns that mirror increased sweat‐gland activation and stronger sympathetic nervous system engagement when emotions are more intense or positive. By retaining these subtle time‐frequency dynamics, TVSymp not only distinguishes emotional dimensions more accurately but also aligns with the physiological principle that phasic EDA responses scale with sympathetic drive—providing both robust classification and a clear link to underlying autonomic mechanisms .",-,-,0.7379,0.7377,0.7272,0.7607,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs SVM classifiers, and reports performance metrics for both arousal and valence dimensions."
119,4,10.1109/ACCESS.2024.3361832,"Veeranki, Y. R., Ganapathy, N., Swaminathan, R., & Posada-Quintero, H. F. (2024). Comparison of electrodermal activity signal decomposition techniques for emotion recognition. IEEE Access, 12, 19952-19966.",,Dimensional,x,2,HV;LV,-,,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors note that TVSymp captures larger phasic amplitude and faster fluctuations in high‐arousal and high‐valence states—patterns that mirror increased sweat‐gland activation and stronger sympathetic nervous system engagement when emotions are more intense or positive. By retaining these subtle time‐frequency dynamics, TVSymp not only distinguishes emotional dimensions more accurately but also aligns with the physiological principle that phasic EDA responses scale with sympathetic drive—providing both robust classification and a clear link to underlying autonomic mechanisms .",-,-,0.7105,0.7159,0.7281,0.7626,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs SVM classifiers, and reports performance metrics for both arousal and valence dimensions."
120,1,10.1109/ACIIW52867.2021.9666360,"Bhatti, A., Behinaein, B., Rodenburg, D., Hungler, P., & Etemad, A. (2021, September). Attentive cross-modal connections for deep multimodal wearable-based emotion recognition. In 2021 9th international conference on affective computing and intelligent interaction workshops and demos (ACIIW) (pp. 01-05). IEEE.",,Dimensional,x,2,Stress; Non-stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.7865,-,0.7047,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and includes EDA-only models for emotion recognition.
121,1,10.3389/fpsyg.2022.895929,"Chong, D., Yu, A., Su, H., & Zhou, Y. (2022). The impact of emotional states on construction workers’ recognition ability of safety hazards based on social cognitive neuroscience. Frontiers in psychology, 13, 895929.",,Dimensional,x,3,HV; LV; Neutral,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,120,,,-,-,0.867,-,0.8,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents an EDA-only model for emotion prediction.
122,1,10.1145/3534615,"Gupta, K., Chan, S. W., Pai, Y. S., Strachan, N., Su, J., Sumich, A., ... & Billinghurst, M. (2022). Total vrecall: Using biosignals to recognize emotional autobiographical memory in virtual reality. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 6(2), 1-21.",,Dimensional,x,3,HV; LV; Neutral,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,,,-,-,0.503,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data for emotion recognition and presents models that use only EDA features.
123,1,10.3233/shti240569,"Banik, S., Kumar, H., Ganapathy, N., & Swaminathan, R. (2024). Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers. In Digital Health and Informatics Innovations for Sustainable Health Care Systems (pp. 953-957). IOS Press.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5375,0.5768,0.6004,0.6452,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data in combination with EEG for emotion recognition, but also evaluates EDA-only models."
123,2,10.3233/shti240569,"Banik, S., Kumar, H., Ganapathy, N., & Swaminathan, R. (2024). Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers. In Digital Health and Informatics Innovations for Sustainable Health Care Systems (pp. 953-957). IOS Press.",,Dimensional,x,2,HV; LV,-,-,-,-,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.561,0.5615,0.6516,0.6884,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data in combination with EEG for emotion recognition, but also evaluates EDA-only models."
123,3,10.3233/shti240569,"Banik, S., Kumar, H., Ganapathy, N., & Swaminathan, R. (2024). Assessment of Valance Emotional State Using EEG-EDA Coupling and Explainable Classifiers. In Digital Health and Informatics Innovations for Sustainable Health Care Systems (pp. 953-957). IOS Press.",,Dimensional,x,2,HV; LV,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.5586,0.5766,0.6611,0.6953,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data in combination with EEG for emotion recognition, but also evaluates EDA-only models."
124,1,10.3389/fnins.2023.1180407,"Wang, K., Zhao, Z., Shen, X., & Yamauchi, T. (2023). Video elicited physiological signal dataset considering indoor temperature factors. Frontiers in Neuroscience, 17, 1180407.",,Categorical,x,5,Joy; Anger; Fear; Sadness; Calm,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.508,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,This database contains skin current response (GSR) data obtained from 25 subjects at three different indoor temperatures.
124,2,10.3389/fnins.2023.1180407,"Wang, K., Zhao, Z., Shen, X., & Yamauchi, T. (2023). Video elicited physiological signal dataset considering indoor temperature factors. Frontiers in Neuroscience, 17, 1180407.",,Categorical,x,5,Joy; Anger; Fear; Sadness; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.592,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,This database contains skin current response (GSR) data obtained from 25 subjects at three different indoor temperatures.
124,3,10.3389/fnins.2023.1180407,"Wang, K., Zhao, Z., Shen, X., & Yamauchi, T. (2023). Video elicited physiological signal dataset considering indoor temperature factors. Frontiers in Neuroscience, 17, 1180407.",,Categorical,x,5,Joy; Anger; Fear; Sadness; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.7,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,This database contains skin current response (GSR) data obtained from 25 subjects at three different indoor temperatures.
125,1,10.1109/JBHI.2022.3225330,"Zitouni, M. S., Park, C. Y., Lee, U., Hadjileontiadis, L. J., & Khandoker, A. (2022). LSTM-modeling of emotion recognition using peripheral physiological signals in naturalistic conversations. IEEE Journal of Biomedical and Health Informatics, 27(2), 912-923.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,172.92,x,"The authors found that the EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the normalization using data from relaxation period of the recording sessions, and the standardization resulted in all*p*-values > 0.9. This explains the beneficial effect of the data pre-processing that was also reflected in an average improvement of classification accuracy of more than 10%, as well as more consistent performances across data from different groups of participants (based on age and gender), rectifying the impact of such inconsistencies in the data.",-,-,0.7575,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The proposed ER framework is based on physiological signals that are normalized and standardized in the resting state, it is anticipated that it could easily be adapted to the characteristics of the physiological signals that are captured from older-adults emotional expression, considering proper annotations and moderate alterations."
125,2,10.1109/JBHI.2022.3225330,"Zitouni, M. S., Park, C. Y., Lee, U., Hadjileontiadis, L. J., & Khandoker, A. (2022). LSTM-modeling of emotion recognition using peripheral physiological signals in naturalistic conversations. IEEE Journal of Biomedical and Health Informatics, 27(2), 912-923.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,172.92,x,"The authors found that the EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the normalization using data from relaxation period of the recording sessions, and the standardization resulted in all*p*-values > 0.9. This explains the beneficial effect of the data pre-processing that was also reflected in an average improvement of classification accuracy of more than 10%, as well as more consistent performances across data from different groups of participants (based on age and gender), rectifying the impact of such inconsistencies in the data.",-,-,0.8206,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The proposed ER framework is based on physiological signals that are normalized and standardized in the resting state, it is anticipated that it could easily be adapted to the characteristics of the physiological signals that are captured from older-adults emotional expression, considering proper annotations and moderate alterations."
126,1,10.1109/ACII52823.2021.9597451,"Khan, A., Hopkins, J., & Gunes, H. (2021, September). Multi-dimensional Affect in Poetry (POCA) Dataset: Acquisition, Annotation and Baseline Results. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,,x,-,150,-,-,-,-,,,,-,-,-,-,-,-,-,-,-,0.54,-,0.92,-,-,-,-,{'SAGR ': ' 0.7200'},Tomi,,yes,include,"EDA was recorded during the inlab study with 30 participants, each of whom listened to 5 poems, resulting in 150 EDA readings and their corresponding emotion labels provided by the participants."
126,2,10.1109/ACII52823.2021.9597451,"Khan, A., Hopkins, J., & Gunes, H. (2021, September). Multi-dimensional Affect in Poetry (POCA) Dataset: Acquisition, Annotation and Baseline Results. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,,x,-,150,-,-,-,-,,,,-,-,-,-,-,-,-,-,-,0.08,-,0.32,-,-,-,-,{'SAGR ': ' 0.7300'},Tomi,,yes,include,"EDA was recorded during the inlab study with 30 participants, each of whom listened to 5 poems, resulting in 150 EDA readings and their corresponding emotion labels provided by the participants."
127,1,10.1515/cdbme-2023-1139,"Anthiyur Aravindan, A., Kalyan Chappidi, S., Thumma, A., & Palanisamy, R. (2023, September). Prediction of arousal and valence state from electrodermal activity using wavelet based resnet50 model. In Current Directions in Biomedical Engineering (Vol. 9, No. 1, pp. 555-558). De Gruyter.",,Dimensional,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,VGG16,x,-,-,,,-,-,-,-,-,-,-,-,-,-,-,-,0.7653,-,-,-,1.0284,-,-,-,,{'plcc': '0.7593'},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
127,2,10.1515/cdbme-2023-1139,"Anthiyur Aravindan, A., Kalyan Chappidi, S., Thumma, A., & Palanisamy, R. (2023, September). Prediction of arousal and valence state from electrodermal activity using wavelet based resnet50 model. In Current Directions in Biomedical Engineering (Vol. 9, No. 1, pp. 555-558). De Gruyter.",,Dimensional,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,ResNet50,x,-,-,,,-,-,-,-,-,-,-,-,-,-,-,-,0.7158,-,-,-,0.8712,-,-,-,,{'plcc': '0.8207'},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
128,1,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The ReliefF algorithm is used to evaluate the importance of features, further optimise the combination of features and improve the accuracy of model recognition. ReliefF is a feature weighting method that can assign different weights to features according to the correlation between features and categories. The larger the weight is, the greater the contribution of the feature to classification, and vice versa.",-,-,0.4263,0.4375,0.5202,0.6436,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{'recall': '81.26%'},Tomi,,yes,include,This paper utilises multimodal physiological signals and machine learning techniques to precisely identify user emotions when observing product images.
128,2,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The ReliefF algorithm is used to evaluate the importance of features, further optimise the combination of features and improve the accuracy of model recognition. ReliefF is a feature weighting method that can assign different weights to features according to the correlation between features and categories. The larger the weight is, the greater the contribution of the feature to classification, and vice versa.",-,-,0.3856,0.3861,0.5353,0.8726,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{'recall': '81.26%'},Tomi,,yes,include,This paper utilises multimodal physiological signals and machine learning techniques to precisely identify user emotions when observing product images.
128,3,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The ReliefF algorithm is used to evaluate the importance of features, further optimise the combination of features and improve the accuracy of model recognition. ReliefF is a feature weighting method that can assign different weights to features according to the correlation between features and categories. The larger the weight is, the greater the contribution of the feature to classification, and vice versa.",-,-,0.4093,0.4145,0.5187,0.693,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{'recall': '81.26%'},Tomi,,yes,include,This paper utilises multimodal physiological signals and machine learning techniques to precisely identify user emotions when observing product images.
128,4,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The ReliefF algorithm is used to evaluate the importance of features, further optimise the combination of features and improve the accuracy of model recognition. ReliefF is a feature weighting method that can assign different weights to features according to the correlation between features and categories. The larger the weight is, the greater the contribution of the feature to classification, and vice versa.",-,-,0.4628,0.4497,0.5668,0.7664,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{'recall': '81.26%'},Tomi,,yes,include,This paper utilises multimodal physiological signals and machine learning techniques to precisely identify user emotions when observing product images.
128,5,10.1080/09544828.2024.2362589,"Zhang, L., Hu, F., Liu, X., Wang, Y., Zhang, H., Liu, Z., & Yu, C. (2024). Intelligent emotion recognition in product design using multimodal physiological signals and machine learning. Journal of Engineering Design, 1-21.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The ReliefF algorithm is used to evaluate the importance of features, further optimise the combination of features and improve the accuracy of model recognition. ReliefF is a feature weighting method that can assign different weights to features according to the correlation between features and categories. The larger the weight is, the greater the contribution of the feature to classification, and vice versa.",-,-,0.4683,0.4991,0.5446,0.5992,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{'recall': '81.26%'},Tomi,,yes,include,This paper utilises multimodal physiological signals and machine learning techniques to precisely identify user emotions when observing product images.
129,1,10.1007/s10916-020-01676-6,"Ganapathy, N., Veeranki, Y. R., Kumar, H., & Swaminathan, R. (2021). Emotion recognition using electrodermal activity signals and multiscale deep convolutional neural network. Journal of Medical Systems, 45(4), 49.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.6933,0.6442,0.7063,0.7816,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
129,2,10.1007/s10916-020-01676-6,"Ganapathy, N., Veeranki, Y. R., Kumar, H., & Swaminathan, R. (2021). Emotion recognition using electrodermal activity signals and multiscale deep convolutional neural network. Journal of Medical Systems, 45(4), 49.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.7143,0.4341,0.4392,0.4444,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
129,2,10.1007/s10916-020-01676-6,"Ganapathy, N., Veeranki, Y. R., Kumar, H., & Swaminathan, R. (2021). Emotion recognition using electrodermal activity signals and multiscale deep convolutional neural network. Journal of Medical Systems, 45(4), 49.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.6875,0.612,0.6754,0.7534,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
129,2,10.1007/s10916-020-01676-6,"Ganapathy, N., Veeranki, Y. R., Kumar, H., & Swaminathan, R. (2021). Emotion recognition using electrodermal activity signals and multiscale deep convolutional neural network. Journal of Medical Systems, 45(4), 49.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.4063,0.2727,0.2849,0.2983,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA signals exclusively and does not combine them with other signals.
130,1,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,AlexNet,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.6624,-,0.4095,-,-,-,-,0.55,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,CASE database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
130,2,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,VGG16,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.8104,-,0.6111,-,-,-,-,0.7472,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,CASE database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
130,3,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,cCNN,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.7979,-,0.611,-,-,-,-,0.7306,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,CASE database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
130,4,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,3,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,AlexNet,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.7082,-,0.6221,-,-,-,-,0.6801,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,WESAD database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
130,5,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,3,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,VGG17,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.6744,-,0.5772,-,-,-,-,0.656,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,WESAD database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
130,6,10.1109/TIM.2024.3420349,"Kumar, P. S., Govarthan, P. K., Gadda, A. A. S., Ganapathy, N., & Ronickom, J. F. A. (2024). Deep learning-based automated emotion recognition using multi modal physiological signals and time-frequency methods. IEEE Transactions on Instrumentation and Measurement.",,Dimensional,x,3,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,cCNN,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.7638,-,0.7055,-,-,-,-,0.7342,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,WESAD database,yes,include,The study uses EDA data and presents models that predict emotional dimensions using only EDA features.
131,1,10.14236/ewic/HCI2022.19,"Pidgeon, M., Kanwal, N., Murray, N., & Asghar, M. (2022, July). End-to-End Emotion Recognition using Peripheral Physiological Signals. In 35th International BCS Human-Computer Interaction Conference (pp. 1-10). BCS Learning & Development.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1028,-,,-,-,0.625,-,0.699,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The preprocessed python version of DEAP dataset has been used. The labels comprise valence, arousal, dominance and liking each with floating point numbers in the range of 1 to 9."
131,2,10.14236/ewic/HCI2022.19,"Pidgeon, M., Kanwal, N., Murray, N., & Asghar, M. (2022, July). End-to-End Emotion Recognition using Peripheral Physiological Signals. In 35th International BCS Human-Computer Interaction Conference (pp. 1-10). BCS Learning & Development.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1028,-,,-,-,0.6018,-,0.663,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The preprocessed python version of DEAP dataset has been used. The labels comprise valence, arousal, dominance and liking each with floating point numbers in the range of 1 to 9."
132,1,10.1109/AIHCIR61661.2023.00066,"He, Y., Chen, L., Zhao, Q., Hong, Z., & Chen, Y. (2023, December). MEDA-CBLSTM: Data Acquisition, Processing and Emotion Recognition Based on Multi-Layer EDA. In 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) (pp. 380-384). IEEE.",,Categorical,x,3,HV; LV; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,-,,-,-,0.823,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs machine learning models, and does not involve clinical populations or foreign languages."
132,2,10.1109/AIHCIR61661.2023.00066,"He, Y., Chen, L., Zhao, Q., Hong, Z., & Chen, Y. (2023, December). MEDA-CBLSTM: Data Acquisition, Processing and Emotion Recognition Based on Multi-Layer EDA. In 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) (pp. 380-384). IEEE.",,Categorical,x,3,HV; LV; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,-,,-,-,0.885,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs machine learning models, and does not involve clinical populations or foreign languages."
132,3,10.1109/AIHCIR61661.2023.00066,"He, Y., Chen, L., Zhao, Q., Hong, Z., & Chen, Y. (2023, December). MEDA-CBLSTM: Data Acquisition, Processing and Emotion Recognition Based on Multi-Layer EDA. In 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) (pp. 380-384). IEEE.",,Categorical,x,3,HV; LV; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,-,,-,-,0.9022,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs machine learning models, and does not involve clinical populations or foreign languages."
132,4,10.1109/AIHCIR61661.2023.00066,"He, Y., Chen, L., Zhao, Q., Hong, Z., & Chen, Y. (2023, December). MEDA-CBLSTM: Data Acquisition, Processing and Emotion Recognition Based on Multi-Layer EDA. In 2023 2nd International Conference on Artificial Intelligence, Human-Computer Interaction and Robotics (AIHCIR) (pp. 380-384). IEEE.",,Categorical,x,3,HV; LV; Calm,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,-,,-,-,0.9231,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, employs machine learning models, and does not involve clinical populations or foreign languages."
133,1,10.3390/electronics12132795,"Dessai, A., & Virani, H. (2023). Emotion classification based on CWT of ECG and GSR signals using various CNN models. Electronics, 12(13), 2795.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.9839,0.98,0.98,0.98,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA (GSR) data for emotion classification and presents models that use only EDA features as input.
133,2,10.3390/electronics12132795,"Dessai, A., & Virani, H. (2023). Emotion classification based on CWT of ECG and GSR signals using various CNN models. Electronics, 12(13), 2795.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.9919,0.97,0.97,0.97,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA (GSR) data for emotion classification and presents models that use only EDA features as input.
134,1,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.747,0.63,0.68,0.75,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,2,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,x,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.662,0.61,0.633,0.66,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,3,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.734,0.622,0.66,0.73,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,4,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.755,0.614,0.66,0.772,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,5,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.726,0.611,0.665,0.73,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,6,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.746,0.62,0.66,0.75,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,7,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,x,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.749,0.61,0.66,0.75,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
134,8,10.1109/JBHI.2024.3405491,"Mercado-Diaz, L. R., Veeranki, Y. R., Marmolejo-Ramos, F., & Posada-Quintero, H. F. (2024). EDA-Graph: Graph Signal Processing of Electrodermal Activity for Emotional States Detection. IEEE Journal of Biomedical and Health Informatics.",,Dimensional,x,5,HVHA; HVLA; LVHA; LVLA; Neutral,-,-,-,-,-,x,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"By mapping EDA into graph structures, our results suggest that emotional states are physiologically encoded not only in the magnitude of skin conductance fluctuations but in the complex, non‐linear relationships between phasic bursts and tonic shifts. For example, higher total load and harmonic centralities in amusement and fear reflect more synchronized, hub‐like bursts of sympathetic activity—indicating rapid, coordinated sweat gland responses—whereas lower centralities in relaxation correspond to more diffuse, baseline‐dominated signaling. Likewise, variations in graph diameter and radius capture differences in how quickly and broadly sympathetic arousal propagates through the network of quantized EDA levels, mirroring the speed and extent of autonomic engagement. In sum, the superior performance of these topology‐based features highlights that emotional differentiation arises from the dynamic interplay of rapid phasic responses and slower tonic modulations of the sympathetic nervous system, a nuance that traditional amplitude‐ or frequency‐based metrics alone cannot fully resolve",-,-,0.748,0.642,0.653,0.745,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The study uses EDA data exclusively for emotion recognition, with no mention of other physiological or non-physiological signals."
135,1,10.1016/j.bspc.2024.106353,"Gahlan, N., & Sethia, D. (2024). AFLEMP: Attention-based federated learning for emotion recognition using multi-modal physiological data. Biomedical Signal Processing and Control, 94, 106353.",,Dimensional,x,2,LA;HA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,Transformer,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.8615,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper uses EDA data and presents models that use only EDA features.
135,2,10.1016/j.bspc.2024.106353,"Gahlan, N., & Sethia, D. (2024). AFLEMP: Attention-based federated learning for emotion recognition using multi-modal physiological data. Biomedical Signal Processing and Control, 94, 106353.",,Dimensional,x,2,LV;HV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,Transformer,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.858,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper uses EDA data and presents models that use only EDA features.
135,3,10.1016/j.bspc.2024.106353,"Gahlan, N., & Sethia, D. (2024). AFLEMP: Attention-based federated learning for emotion recognition using multi-modal physiological data. Biomedical Signal Processing and Control, 94, 106353.",,Dimensional,x,2,LD;HD,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,Transformer,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.8254,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper uses EDA data and presents models that use only EDA features.
136,1,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Boring,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.6,,0.5833,-,-,-,-,0.6,-,-,-,-,-,-,-,-,-,-,-,,Jero,"- affective_model_evidence la sacó del titulo
- Extrajo bien las categorias de output (las 4 emociones) y todos los modelos, pero lo hizo todo junto
- Aunque model_features está bien, model_features_evidence se la inventó
- Puso 'auc' en metric_other (probablemente problema de extracción)",yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,2,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Relaxing,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5833,,0.566,-,-,-,-,0.5833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,3,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Scary,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7333,,0.7297,-,-,-,-,0.7333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,4,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Relaxing,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5333,,0.5065,-,-,-,-,0.5333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,5,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Scary,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7917,,0.7874,-,-,-,-,0.7917,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,6,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Relaxing; Scary,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7916,,0.7874,-,-,-,-,0.7916,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,7,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Boring,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.6167,,0.5873,-,-,-,-,0.6166,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,8,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Relaxing,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5417,,0.4667,-,-,-,-,0.5416,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,9,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Scary,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7333,,0.7327,-,-,-,-,0.7333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,10,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Relaxing,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.4833,,0.4654,-,-,-,-,0.4833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,11,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Scary,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7916,,0.7863,-,-,-,-,0.7916,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,12,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Relaxing; Scary,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7833,,0.7758,-,-,-,-,0.7833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,13,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Boring,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.6417,,0.6416,-,-,-,-,0.6416,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,14,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Relaxing,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5667,,0.5665,-,-,-,-,0.5667,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,15,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Scary,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7333,,0.7333,-,-,-,-,0.7333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,16,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Relaxing,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.4833,,0.4833,-,-,-,-,0.4833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,17,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Scary,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.8417,,0.8417,-,-,-,-,0.8417,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,18,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Relaxing; Scary,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7833,,0.7833,-,-,-,-,0.7833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,19,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Boring,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.6333,,0.6333,-,-,-,-,0.6333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,20,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Relaxing,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5333,,0.5333,-,-,-,-,0.5333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,21,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.6667,,0.6663,-,-,-,-,0.6666,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,22,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Relaxing,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5,,0.4987,-,-,-,-,0.5,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,23,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.825,,0.8249,-,-,-,-,0.825,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,24,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Relaxing; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.808,,0.8082,-,-,-,-,0.8083,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,25,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Boring,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.5917,,0.5852,-,-,-,-,0.5917,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,26,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Relaxing,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.575,,0.5683,-,-,-,-,0.575,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,27,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Amusing; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7333,,0.7315,-,-,-,-,0.7333,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,28,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Relaxing,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.4833,,0.4714,-,-,-,-,0.4833,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,29,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Boring; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.8417,,0.8411,-,-,-,-,0.8417,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
136,30,10.1109/ICCCMLA58983.2023.10346868,"Kumar P, S., & Ronickom, J. F. A. (2023, October). Investigating the Effects of Two-Class Categorical Emotion Classification Through Electrodermal Activity and Machine Learning. In 2023 IEEE 5th International Conference on Cybernetics, Cognition and Machine Learning Applications (ICCCMLA) (pp. 594-599). IEEE.",,Categorical,x,2,Relaxing; Scary,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30,x,"The study focused on the phasic component of EDA signals, which are closely connected to the physiological and psychological reactions triggered by specific stimuli. The features selected through RFECV were found to be more emotionally significant.",-,-,0.7917,,0.791,-,-,-,-,0.7917,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,The study uses only EDA features for emotion classification and does not combine them with other signals.
137,1,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.839,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,"- No hay un affective_model pero la confianza es low y está bien, porque en el paper tampoco se menciona
- class_model_output_number_evidence no tiene nada que ver con el class_model_output_number",yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,2,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.699,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,3,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.839,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,4,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.699,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,5,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.754,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,6,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.688,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,7,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.763,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,8,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.645,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,9,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.746,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,10,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.634,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,11,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,SEL (Stacking Ensemble Learning),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.864,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
137,12,10.1109/MeMeA54994.2022.9856558,"Zhu, L., Spachos, P., & Gregori, S. (2022, June). Multimodal physiological signals and machine learning for stress detection by wearable devices. In 2022 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-6). IEEE.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,SEL (Stacking Ensemble Learning),-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The authors found that EDA signals can reflect emotional changes more than ECG and PPG signals. Minor emotional changes that might not affect the participants’ ECG and PPG signals could still influence the sensitive EDA signals.,-,-,0.723,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features as input.
138,1,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.556,,0.544,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,"- Se inventó la evidencia de class_model_output_number_evidence
- Tiene 2 outputs, pero divide modelos por valencia y arousal. Además no usa solamente una CNN, aunque sea lo principal, sino que usa también SVM, RFC y KNN",yes,include,The study includes models that use only EDA features for emotion recognition.
138,2,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.583,,0.569,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,3,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.553,-,0.512,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,4,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.585,-,0.584,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,5,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.546,-,0.535,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,6,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.563,,0.561,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,7,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.536,-,0.52,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
138,8,10.3389/fnins.2022.965871,"Chen, P., Zou, B., Belkacem, A. N., Lyu, X., Zhao, X., Yi, W., ... & Chen, C. (2022). An improved multi-input deep convolutional neural network for automatic emotion recognition. Frontiers in Neuroscience, 16, 965871.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.543,-,0.523,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study includes models that use only EDA features for emotion recognition.
139,1,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.8021,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,"- class_model_output_number_evidence flashó porque no son 4, son 2
- class_model_output_categories_evidence la flashó mal, encima puso cualquier output",yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,2,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7665,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,3,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7671,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,4,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7476,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,5,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7095,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,Decision Tree,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,6,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7379,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,Decision Tree,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,7,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7492,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,Random Forest,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,8,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7327,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,Random Forest,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,9,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7584,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
139,10,10.1109/AINIT61980.2024.10581751,"Mu, J., Qiao, Y., & Liu, G. (2024, March). Research on Emotion Recognition Strategy Based on Electrocardiogram and Electrodermal activity Signals Induced by Music. In 2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT) (pp. 1574-1578). IEEE.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1030,x,"The authors found that the CNN-LSTM model performed best for both arousal and valence classification tasks of ECG and EDA signals. The arousal recognition rate for ECG signals was 75.03%, and the valence recognition rate was 78.65%. For EDA signals, the arousal recognition rate was 76.65%, and the valence recognition rate was 80.21%. This validates the effectiveness of the proposed CNN-LSTM model.",-,-,0.7398,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The experiment utilized the BIOPAC MP150 multi-channel physiological recorder to collect ECG and EDA signals. The ECG signals were obtained using chest leads with a sampling rate of 1 kHz, while the EDA signals were acquired using wrist sensors with a sampling rate of 1 kHz."
140,1,10.1109/ACII52823.2021.9597434,"Di Lascio, E., Gashi, S., Debus, M. E., & Santini, S. (2021, September). Automatic recognition of flow during work activities using context and physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,x,2,High Flow; Low Flow,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,6 712 five‑min segments ​,x,"Flow is treated as a binary affective state; EDA tonic‑and‑phasic features alone moderately separate high from low flow, in line with theories linking flow to moderate sympathetic arousal.",-,-,0.6291,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"We considered the problem of ﬂow recognition as a binary classiﬁcation task, as in [9]."
140,2,10.1109/ACII52823.2021.9597434,"Di Lascio, E., Gashi, S., Debus, M. E., & Santini, S. (2021, September). Automatic recognition of flow during work activities using context and physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-8). IEEE.",,Dimensional,x,2,High Flow; Low Flow,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,6 712 five‑min segments ​,x,"Flow is treated as a binary affective state; EDA tonic‑and‑phasic features alone moderately separate high from low flow, in line with theories linking flow to moderate sympathetic arousal.",-,-,0.6015,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"We considered the problem of ﬂow recognition as a binary classiﬁcation task, as in [9]."
141,1,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,40 participants,x,"The authors found that the ECG features were more discriminative for arousal detection compared to EDA. Specifically, the RR intervals and their variations were found to be important features. The random forest classifier achieved high accuracy and F1 scores across multiple datasets, supporting the effectiveness of the unsupervised representation learning approach.",-,-,0.67,-,0.77,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: AMIGOS,yes,include,The study uses EDA data as part of a multi-modal approach but also presents EDA-only models for arousal classification.
141,2,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,58 participants,x,"The authors found that the ECG features were more discriminative for arousal detection compared to EDA. Specifically, the RR intervals and their variations were found to be important features. The random forest classifier achieved high accuracy and F1 scores across multiple datasets, supporting the effectiveness of the unsupervised representation learning approach.",-,-,0.66,-,0.79,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: ASCERTAIN,yes,include,The study uses EDA data as part of a multi-modal approach but also presents EDA-only models for arousal classification.
141,3,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,10,x,"The authors found that the ECG features were more discriminative for arousal detection compared to EDA. Specifically, the RR intervals and their variations were found to be important features. The random forest classifier achieved high accuracy and F1 scores across multiple datasets, supporting the effectiveness of the unsupervised representation learning approach.",-,-,0.9,-,0.79,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,- La interpretación es cualquier cosa literaldb: CLEAS,yes,include,The study uses EDA data as part of a multi-modal approach but also presents EDA-only models for arousal classification.
141,4,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,30 participants,x,"The authors found that the ECG features were more discriminative for arousal detection compared to EDA. Specifically, the RR intervals and their variations were found to be important features. The random forest classifier achieved high accuracy and F1 scores across multiple datasets, supporting the effectiveness of the unsupervised representation learning approach.",-,-,0.61,-,0.43,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: MAHNOB-HCI,yes,include,The study uses EDA data as part of a multi-modal approach but also presents EDA-only models for arousal classification.
141,5,10.1007/s12652-021-03462-9,"Ross, K., Hungler, P., & Etemad, A. (2023). Unsupervised multi-modal representation learning for affective computing with multi-corpus wearable data. Journal of Ambient Intelligence and Humanized Computing, 14(4), 3199-3224.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the ECG features were more discriminative for arousal detection compared to EDA. Specifically, the RR intervals and their variations were found to be important features. The random forest classifier achieved high accuracy and F1 scores across multiple datasets, supporting the effectiveness of the unsupervised representation learning approach.",-,-,0.65,-,0.74,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,"db: Overall (no me quedó claro si es un promedio o agarró todo junto, si fuera el primero hay que volarlo)",yes,include,The study uses EDA data as part of a multi-modal approach but also presents EDA-only models for arousal classification.
142,1,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.652,0.741,0.741,0.741,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,2,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.633,0.724,0.741,0.734,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,3,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.763,0.752,0.752,0.752,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,4,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.745,0.745,0.745,0.745,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,5,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.778,0.778,0.778,0.778,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,6,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.745,0.767,0.761,0.756,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,7,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.69,0.732,0.724,0.717,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,8,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.678,0.704,0.724,0.714,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,9,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.828,0.862,0.854,0.847,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,10,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,3554,-,-,-,-,0.744,0.753,0.753,0.753,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PAFEW,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,11,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.77,0.749,0.747,0.745,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,12,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.69,0.732,0.718,0.705,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,13,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.714,0.733,0.736,0.74,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,14,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.734,0.767,0.756,0.745,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,15,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.733,0.702,0.727,0.754,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,16,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.714,0.756,0.753,0.75,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,17,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.68,0.71,0.715,0.72,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,18,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.691,0.744,0.749,0.754,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,19,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.793,0.802,0.803,0.805,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
142,20,10.3389/fnins.2022.911767,"Perry Fordson, H., Xing, X., Guo, K., & Xu, X. (2022). Emotion recognition with knowledge graph based on electrodermal activity. Frontiers in Neuroscience, 16, 911767.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,-,-,-,-,0.802,0.801,0.798,0.804,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The proposed framework is based on observed gender and age information as embedding feature vectors. We also extract time and frequency EDA features in line with cognitive studies.
143,1,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,PhGP,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,105,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.81,-,-,0.81,0.82,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
143,2,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,High Pain; Low Pain,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,PhGP,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.89,-,-,0.87,0.9,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: BVHP,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
143,3,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,Stress; Non-stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,PhGP,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.89,-,-,0.88,0.91,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: Stroop,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
143,4,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.64,-,-,0.6,0.68,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
143,5,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,High Pain; Low Pain,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.84,-,-,0.87,0.81,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: BVHP,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
143,6,10.1109/JBHI.2022.3224775,"Ghiasi, S., Patane, A., Laurenti, L., Gentili, C., Scilingo, E. P., Greco, A., & Kwiatkowska, M. (2022). Physiologically-informed gaussian processes for interpretable modelling of psycho-physiological states. IEEE Journal of Biomedical and Health Informatics, 27(8), 3721-3730.",,Dimensional,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.77,,-,0.72,0.82,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: Stroop,yes,include,The study uses EDA data exclusively for emotion prediction and presents models that use only EDA features as input.
144,1,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6175,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice self-report,yes,include,The study includes EDA-only models as shown in Table II.
144,2,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6585,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice external annotation,yes,include,The study includes EDA-only models as shown in Table II.
144,3,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.8375,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice self-report,yes,include,The study includes EDA-only models as shown in Table II.
144,4,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.8513,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice external annotation,yes,include,The study includes EDA-only models as shown in Table II.
144,5,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7982,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice self-report,yes,include,The study includes EDA-only models as shown in Table II.
144,6,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.8117,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice external annotation,yes,include,The study includes EDA-only models as shown in Table II.
144,7,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6985,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice self-report,yes,include,The study includes EDA-only models as shown in Table II.
144,8,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.7113,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice external annotation,yes,include,The study includes EDA-only models as shown in Table II.
144,9,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6343,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice self-report,yes,include,The study includes EDA-only models as shown in Table II.
144,10,10.1109/GLOBECOM48099.2022.10000909,"Zhu, L., & Spachos, P. (2022, December). Annotation efficiency in multimodal emotion recognition with deep learning. In GLOBECOM 2022-2022 IEEE Global Communications Conference (pp. 560-565). IEEE.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.6667,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,predice external annotation,yes,include,The study includes EDA-only models as shown in Table II.
145,1,10.1109/ICC45041.2023.10278603,"Zhu, L., Spachos, P., & Gregori, S. (2023, May). Electrodermal activity for emotion recognition using cnn and bi-gru model. In ICC 2023-IEEE International Conference on Communications (pp. 5533-5538). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed method uses Bi-GRU for feature extraction from spectrogram images of EDA signals, followed by a CNN for classification. The results show that the method is competitive for emotion recognition based on EDA signals.",-,-,0.81,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively and presents models that use only EDA features.
145,2,10.1109/ICC45041.2023.10278603,"Zhu, L., Spachos, P., & Gregori, S. (2023, May). Electrodermal activity for emotion recognition using cnn and bi-gru model. In ICC 2023-IEEE International Conference on Communications (pp. 5533-5538). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed method uses Bi-GRU for feature extraction from spectrogram images of EDA signals, followed by a CNN for classification. The results show that the method is competitive for emotion recognition based on EDA signals.",-,-,0.83,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively and presents models that use only EDA features.
146,1,10.1007/s11042-022-12711-8,"Katada, S., & Okada, S. (2022). Biosignal-based user-independent recognition of emotion and personality with importance weighting. Multimedia Tools and Applications, 81(21), 30219-30241.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,37,x,"The study found that GSR features, particularly the 2nd difference of skin conductance, were effective for personality estimation. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is linked to emotional arousal.",-,-,-,-,0.349,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features.
146,2,10.1007/s11042-022-12711-8,"Katada, S., & Okada, S. (2022). Biosignal-based user-independent recognition of emotion and personality with importance weighting. Multimedia Tools and Applications, 81(21), 30219-30241.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,37,x,"The study found that GSR features, particularly the 2nd difference of skin conductance, were effective for personality estimation. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is linked to emotional arousal.",-,-,-,-,0.595,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features.
146,3,10.1007/s11042-022-12711-8,"Katada, S., & Okada, S. (2022). Biosignal-based user-independent recognition of emotion and personality with importance weighting. Multimedia Tools and Applications, 81(21), 30219-30241.",,Dimensional,x,2,HV; LV,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,37,x,"The study found that GSR features, particularly the 2nd difference of skin conductance, were effective for personality estimation. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is linked to emotional arousal.",-,-,-,-,0.396,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features.
146,4,10.1007/s11042-022-12711-8,"Katada, S., & Okada, S. (2022). Biosignal-based user-independent recognition of emotion and personality with importance weighting. Multimedia Tools and Applications, 81(21), 30219-30241.",,Dimensional,x,2,HA; LA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,37,x,"The study found that GSR features, particularly the 2nd difference of skin conductance, were effective for personality estimation. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is linked to emotional arousal.",-,-,-,-,0.592,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features.
147,1,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8209,0.752,0.6819,0.9125,-,-,-,-,-,-,-,-,-,-,-,-,0.6983,-,Kappa: 0.3820,Jero,eda en wrist,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,2,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8488,0.7981,0.7655,0.9436,-,-,-,-,-,-,-,-,-,-,-,-,0.7646,-,Kappa: 0.5632,Jero,eda en chest,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,3,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.7137,0.7327,0.6839,0.9096,-,-,-,-,-,-,-,-,-,-,-,-,0.6229,-,Kappa: 0.3415,Jero,eda en wrist,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,4,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.7755,0.7685,0.7479,0.9306,-,-,-,-,-,-,-,-,-,-,-,-,0.7025,-,Kappa: 0.4658,Jero,eda en chest,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,5,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.732,0.7452,0.7156,0.9142,-,-,-,-,-,-,-,-,-,-,-,-,0.6469,-,Kappa: 0.3791,Jero,eda en wrist,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,6,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.7913,0.7587,0.7567,0.9338,-,-,-,-,-,-,-,-,-,-,-,-,0.7058,-,Kappa: 0.5023,Jero,eda en chest,yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,7,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.7728,0.7578,0.6998,0.9159,-,-,-,-,-,-,-,-,-,-,-,-,0.6824,-,Kappa: 0.434,Jero,"MODELO SOLO DICE NN
eda en wrist",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,8,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8258,0.8292,0.7779,0.9407,-,-,-,-,-,-,-,-,-,-,-,-,0.7549,-,Kappa: 0.5775,Jero,"MODELO SOLO DICE NN
eda en chest",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,9,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8001,0.7798,0.7939,0.9355,-,-,-,-,-,-,-,-,-,-,-,-,0.7282,-,Kappa: 0.5283,Jero,"MODELO: DT
eda en wrist",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,10,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8607,0.8423,0.8436,0.9573,-,-,-,-,-,-,-,-,-,-,-,-,0.8061,-,Kappa: 0.6519,Jero,"MODELO: DT
eda en chest",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,11,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8348,0.8314,0.8276,0.9511,-,-,-,-,-,-,-,-,-,-,-,-,0.7816,-,Kappa: 0.6197,Jero,"MODELO: RF
eda en wrist",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
147,12,10.1109/ICACCS57279.2023.10112973,"Gupta, R., Bhongade, A., & Gandhi, T. K. (2023, March). Multimodal wearable sensors-based stress and affective states prediction model. In 2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS) (Vol. 1, pp. 30-35). IEEE.",,Categorical,x,4,Baseline; Stress; Amusement; Meditation,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,15,x,The authors found that the wrist-worn sensors performed moderately well for different classifiers. The RF classifier depicted the best classification accuracy as 86.80±8.72% (p-value<0.05) among all classifiers for the temperature sensor signal.,-,-,,0.8867,0.8742,0.8792,0.9653,-,-,-,-,-,-,-,-,-,-,-,-,0.8455,-,Kappa: 0.7208,Jero,"MODELO: RF
eda en chest",yes,include,The dataset used to conduct this study is available Online [6] and referred to as Wearable Stress and Affect Detection (WESAD) database.
148,1,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,LSLC,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.3300,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,2,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,LSQC,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.5180,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,3,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.4970,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,4,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.5710,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,5,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.3690,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,6,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,DNN,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.4710,Jero,eda en hand,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,7,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,LSLC,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.3620,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,8,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,LSQC,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.6510,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,9,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.6340,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,10,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.5750,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,11,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.5310,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
148,12,10.1016/j.eswa.2024.124305,"Mohino-Herranz, I., Gil-Pita, R., García-Gómez, J., Alonso-Diaz, S., Rosa-Zurera, M., & Seoane, F. (2024). Initializing the weights of a multilayer perceptron for activity and emotion recognition. Expert Systems with Applications, 253, 124305.",,Categorical,x,3,Neutral; Sadness; Disgust,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,DNN,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,800,x,"The authors found that the proposed 2PT (two-phase training) method significantly improves the performance of neural networks in emotion recognition. The initialization technique embeds system information into the weights before training, which helps in mitigating local minima issues and overfitting problems. The results demonstrate that the 2PT method consistently outperforms traditional initialization methods across various scenarios, achieving lower error probabilities.",-,-,,,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Error Probability: 0.5250,Jero,eda en arm,yes,include,The study uses EDA data and presents models that use only EDA features for emotion recognition.
149,1,10.1109/JSEN.2020.3031163,"Woodward, K., & Kanjo, E. (2020). iFidgetCube: tangible fidgeting interfaces (TFIs) to monitor and improve mental wellbeing. IEEE Sensors Journal, 21(13), 14300-14307.",,Categorical,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,,x,-,x,"The authors found that the EDA univariate models outperformed the other univariate models for 6 out of 9 users, with the highest average accuracy of 77.6%, demonstrating its importance in inferring wellbeing.",-,-,0.776,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,El accuracy es promedio de todos los sujetos,yes,include,EDA sensors are located on the opposite face of the PPG sensor where two ﬁngers can be placed to comfortably hold the device while simultaneously recording the sensor data.
150,1,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.7715,-,0.7918,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: DEAP,yes,include,The study uses EDA and includes EDA-only models.
150,2,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.8342,-,0.8377,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: AMIGOS,yes,include,The study uses EDA and includes EDA-only models.
150,3,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.7587,-,0.7448,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
150,4,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.782,-,0.7756,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
150,5,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.597,-,0.6036,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
150,6,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.6095,-,0.6114,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
150,7,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.6452,-,0.6331,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
150,8,10.1145/3490686,"Yin, G., Sun, S., Yu, D., Li, D., & Zhang, K. (2022). A multimodal framework for large-scale emotion recognition by fusing music and electrodermal activity signals. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 18(3), 1-23.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,457,x,The model uses attention mechanisms to focus on relevant EDA features.,x,https://github.com/guanghaoyin/RTCAN-1D,0.6519,-,0.6584,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,db: PMEmo,yes,include,The study uses EDA and includes EDA-only models.
151,1,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.288,0.283,0.277,0.288,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,2,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.291,0.293,0.288,0.29,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,3,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.295,0.296,0.284,0.295,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,4,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.303,0.282,0.279,0.303,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,5,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.273,0.273,0.262,0.273,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,6,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVHA; Other,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.683,0.584,0.569,0.556,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,7,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVHA; Other,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.728,0.673,0.641,0.612,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,8,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVHA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.604,0.523,0.525,0.529,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,9,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVHA; Other,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.634,0.607,0.602,0.598,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,10,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVHA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.681,0.584,0.578,0.592,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,11,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVLA; Other,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.698,0.609,0.612,0.616,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,12,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVLA; Other,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.712,0.573,0.56,0.548,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,13,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVLA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.621,0.498,0.494,0.491,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,14,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVLA; Other,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.604,0.533,0.555,0.579,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,15,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVLA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.643,0.516,0.514,0.513,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,16,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVHA; Other,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.704,0.578,0.558,0.541,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,17,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVHA; Other,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.728,0.684,0.654,0.628,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,18,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVHA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.659,0.567,0.563,0.561,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,19,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVHA; Other,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.485,0.509,0.51,0.512,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,20,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,LVHA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.698,0.608,0.588,0.571,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,21,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVLA; Other,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.709,0.638,0.639,0.641,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,22,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVLA; Other,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.719,0.634,0.617,0.601,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,23,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVLA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.64,0.534,0.531,0.529,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,24,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVLA; Other,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.554,0.573,0.565,0.558,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
151,25,10.3390/s23031608,"Baldassarri, S., García de Quirós, J., Beltrán, J. R., & Álvarez, P. (2023). Wearables and machine learning for improving runners’ motivation from an affective perspective. Sensors, 23(3), 1608.",,Dimensional,x,2,HVLA; Other,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,250,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic EDA level was more informative for valence discrimination, which they related to Lang's dimensional theory of emotion.",-,-,0.704,0.628,0.615,0.603,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion recognition and does not involve any clinical populations or foreign languages.
152,1,10.3389/fnins.2023.1138091,"Li, Z., Xing, Y., Pi, Y., Jiang, M., & Zhang, L. (2023). A novel physiological feature selection method for emotional stress assessment based on emotional state transition. Frontiers in Neuroscience, 17, 1138091.",,Dimensional,x,3,HV; LV; Neutral,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,85,x,"The authors found that the proposed feature selection method based on emotional state transition achieved the highest accuracy in emotion recognition, particularly for ECG and BVP signals. The method focused on changes in physiological features during emotional transitions, which are more significant than static features.",-,-,0.96,0.949,0.955,0.961,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"ECG, BVP, and GSR signals were collected to train the four classiﬁers (KNN, DT, RF, and SVM) in diﬀerent classiﬁcation tasks."
152,2,10.3389/fnins.2023.1138091,"Li, Z., Xing, Y., Pi, Y., Jiang, M., & Zhang, L. (2023). A novel physiological feature selection method for emotional stress assessment based on emotional state transition. Frontiers in Neuroscience, 17, 1138091.",,Dimensional,x,2,LV; Other,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,85,x,"The authors found that the proposed feature selection method based on emotional state transition achieved the highest accuracy in emotion recognition, particularly for ECG and BVP signals. The method focused on changes in physiological features during emotional transitions, which are more significant than static features.",-,-,0.97,0.963,0.958,0.954,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"ECG, BVP, and GSR signals were collected to train the four classiﬁers (KNN, DT, RF, and SVM) in diﬀerent classiﬁcation tasks."
153,1,10.3390/s21113760,"Alanazi, S.A.; Alruwaili, M.; Ahmad, F.; Alaerjan, A.; Alshammari, N. Estimation of Organizational Competitiveness by a Hybrid of One-Dimensional Convolutional Neural Networks and Self-Organizing Maps Using Physiological Signals for Emotional Analysis of Employees. Sensors 2021, 21, 3760.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,x,"The study used physiological signals, including BVP, GSR, SKT, valence, and arousal, to classify emotions. The ODCNN model achieved high accuracy in classifying emotional states, demonstrating the effectiveness of using these features for emotion recognition.",-,-,0.998,-,-,-,-,-,-,0.99,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data (GSR) and focuses on emotion prediction using machine learning models.
153,2,10.3390/s21113760,"Alanazi, S.A.; Alruwaili, M.; Ahmad, F.; Alaerjan, A.; Alshammari, N. Estimation of Organizational Competitiveness by a Hybrid of One-Dimensional Convolutional Neural Networks and Self-Organizing Maps Using Physiological Signals for Emotional Analysis of Employees. Sensors 2021, 21, 3760.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,x,"The SVM model achieved an accuracy rate of 83.5%, demonstrating its effectiveness in classifying emotional states based on physiological signals.",-,-,0.835,-,-,-,-,-,-,0.9,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data (GSR) and focuses on emotion prediction using machine learning models.
153,3,10.3390/s21113760,"Alanazi, S.A.; Alruwaili, M.; Ahmad, F.; Alaerjan, A.; Alshammari, N. Estimation of Organizational Competitiveness by a Hybrid of One-Dimensional Convolutional Neural Networks and Self-Organizing Maps Using Physiological Signals for Emotional Analysis of Employees. Sensors 2021, 21, 3760.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,1200,x,"The ERT model achieved an accuracy rate of 71.4%, demonstrating its effectiveness in classifying emotional states based on physiological signals.",-,-,0.714,-,-,-,-,-,-,0.87,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data (GSR) and focuses on emotion prediction using machine learning models.
154,1,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.9149,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,2,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.6383,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,3,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.5638,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,4,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.8298,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,5,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.5638,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,6,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.617,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,7,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.5638,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,8,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.8689,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,9,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.7466,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,10,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.875,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,11,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.5625,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,12,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.9232,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
154,13,10.3390/electronics13081494,"Joo, J. H., Han, S. H., Park, I., & Chung, T. S. (2024). Immersive Emotion Analysis in VR Environments: A Sensor-Based Approach to Prevent Distortion. Electronics, 13(8), 1494.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The study used XGBoost to predict the category of 360-VEs viewed by users based on GSR sensor data. The feature importance analysis showed that the 'Ratio' feature was the most influential for predicting valence and arousal, indicating that GSR data can effectively capture emotional responses in a VR environment.",-,-,0.7701,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA (GSR) data to predict user emotions in a VR environment, focusing on valence and arousal dimensions. It presents models that use only EDA features, such as GSR, for emotion prediction."
155,1,10.3390/s21062166,"Oh, G., Ryu, J., Jeong, E., Yang, J. H., Hwang, S., Lee, S., & Lim, S. (2021). Drer: Deep learning–based driver’s real emotion recognizer. Sensors, 21(6), 2166.",,Dimensional,x,8,Neutral; Happy; Excited; Fearful; Angry; Depressed; Bored; Relieved,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,x,310.389,x,"The model fuses valence, arousal, and EDA to recognize the driver’s real emotion. The EDA signal provides additional information beyond facial expressions, improving recognition accuracy.",-,-,0.358,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents models that use only EDA features.
156,1,10.1016/j.inffus.2020.08.007,"Raheel, A., Majid, M., & Anwar, S. M. (2021). DEAR-MULSEMEDIA: Dataset for emotion analysis and recognition in response to multiple sensorial media. Information Fusion, 65, 37-49.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the fusion of features from EEG, GSR, and PPG significantly improved the classification accuracy for both valence and arousal. The highest accuracy of 85.18% for valence and 76.54% for arousal was achieved using feature-level fusion, indicating that combining multiple physiological signals enhances emotion recognition performance.",-,-,0.5555,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Kappa: 0.1050,Jero,,yes,include,The study uses EDA data (GSR) as part of a multimodal approach but also presents results for EDA-only models.
156,2,10.1016/j.inffus.2020.08.007,"Raheel, A., Majid, M., & Anwar, S. M. (2021). DEAR-MULSEMEDIA: Dataset for emotion analysis and recognition in response to multiple sensorial media. Information Fusion, 65, 37-49.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the fusion of features from EEG, GSR, and PPG significantly improved the classification accuracy for both valence and arousal. The highest accuracy of 85.18% for valence and 76.54% for arousal was achieved using feature-level fusion, indicating that combining multiple physiological signals enhances emotion recognition performance.",-,-,0.7407,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Kappa: 0.4600,Jero,,yes,include,The study uses EDA data (GSR) as part of a multimodal approach but also presents results for EDA-only models.
157,1,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.528,0.583,0.606,0.63,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,2,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.537,0.577,0.594,0.613,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,3,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.575,0.575,0.73,1,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,4,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.55,0.551,0.71,0.992,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,5,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.559,0.572,0.71,0.932,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,6,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.545,0.553,0.69,0.913,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,7,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.527,0.582,0.606,0.632,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
157,8,10.1109/MeMeA60663.2024.10596800,"Veeranki, Y. R., Mercado-Diaz, L. R., & Posada-Quintero, H. F. (2024, June). Autoencoder Based Nonlinear Feature Extraction from EDA Signals for Emotion Recognition. In 2024 IEEE International Symposium on Medical Measurements and Applications (MeMeA) (pp. 1-5). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,240,x,"The authors found that the phasic EDA features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the physiological mechanisms of EDA, which links phasic activity to emotional arousal. The high classification accuracy for arousal using only these features supports this physiological interpretation.",-,-,0.512,0.554,0.605,0.57,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study focuses on emotion recognition using EDA signals and presents machine learning models that use only EDA features.
158,1,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",,Categorical,x,2,Stress; Non-stress Stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2629,x,"The paper focuses on the performance of the models in terms of accuracy and model size, but does not provide detailed physiological interpretations of the features.",-,-,0.891,0.93,0.9,0.87,0.92,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper focuses on stress detection using EDA data and presents models that use only EDA features.
158,2,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",,Categorical,x,2,Stress; Non-stress Stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2629,x,"The paper focuses on the performance of the models in terms of accuracy and model size, but does not provide detailed physiological interpretations of the features.",-,-,0.8598,0.93,0.87,0.82,0.92,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper focuses on stress detection using EDA data and presents models that use only EDA features.
158,3,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",,Categorical,x,2,Stress; Non-stress Stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2629,x,"The paper focuses on the performance of the models in terms of accuracy and model size, but does not provide detailed physiological interpretations of the features.",-,-,0.8313,0.89,0.85,0.79,0.87,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper focuses on stress detection using EDA data and presents models that use only EDA features.
158,4,10.1109/PerComWorkshops59983.2024.10502631,"Jaiswal, D., Mukhopadhyay, S., & Sharma, V. (2024, March). Tinystressnet: On-device stress assessment with wearable sensors on edge devices. In 2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops) (pp. 166-171). IEEE.",,Categorical,x,2,Stress; Non-stress Stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2629,x,"The paper focuses on the performance of the models in terms of accuracy and model size, but does not provide detailed physiological interpretations of the features.",-,-,0.848,0.92,0.86,0.8,0.91,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper focuses on stress detection using EDA data and presents models that use only EDA features.
159,1,10.2478/jaiscr-2021-0001,"Rahman, J. S., Gedeon, T., Caldwell, S., Jones, R., & Jin, Z. (2021). Towards effective music therapy for mental health care using machine learning tools: human affective reasoning and music genres. Journal of Artificial Intelligence and Soft Computing Research, 11(1), 5-20.",,Dimensional,x,2,Tensing; Relaxing,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.977,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA and includes models that use only EDA features.
159,2,10.2478/jaiscr-2021-0001,"Rahman, J. S., Gedeon, T., Caldwell, S., Jones, R., & Jin, Z. (2021). Towards effective music therapy for mental health care using machine learning tools: human affective reasoning and music genres. Journal of Artificial Intelligence and Soft Computing Research, 11(1), 5-20.",,Dimensional,x,2,Tensing; Relaxing,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.703,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA and includes models that use only EDA features.
159,3,10.2478/jaiscr-2021-0001,"Rahman, J. S., Gedeon, T., Caldwell, S., Jones, R., & Jin, Z. (2021). Towards effective music therapy for mental health care using machine learning tools: human affective reasoning and music genres. Journal of Artificial Intelligence and Soft Computing Research, 11(1), 5-20.",,Dimensional,x,2,Tensing; Relaxing,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.568,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA and includes models that use only EDA features.
160,1,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,Stress; Non-stress Stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.7571,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,2,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,Stress; Non-stress Stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.6452,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,3,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,Stress; Non-stress Stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.7119,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,4,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,Stress; Non-stress Stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.6024,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,5,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,High Stress; Low stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.636,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,6,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,High Stress; Low stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.6156,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,7,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,High Stress; Low stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.5825,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
160,8,10.1109/TAFFC.2021.3056960,"Sabour, R. M., Benezeth, Y., De Oliveira, P., Chappe, J., & Yang, F. (2021). Ubfc-phys: A multimodal database for psychophysiological studies of social stress. IEEE Transactions on Affective Computing, 14(1), 622-636.",,Categorical,x,2,High Stress; Low stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,56,x,"The authors found that EDA features, particularly tonic skin conductance level (SCL) and its variations, were crucial in distinguishing stress states. This aligns with the understanding that EDA reflects sympathetic nervous system activity, which is heightened during stress.",-,-,0.5799,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, such as achieving 82.38% accuracy with EDA features alone."
161,1,10.1109/TAFFC.2019.2901673,"Shukla, J., Barreda-Ángeles, M., Oliver, J., Puig, D., & Nandi, G. C. (2019). Feature Extraction and Selection for Emotion Recognition from Electrodermal Activity. IEEE Transactions on Affective Computing, 12(4), 858-866.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,x,12580,x,"The authors found that MFCC statistical features, along with AUC and SMA features, were the most significant for emotion recognition. These findings support the use of EDA features beyond traditional SCR analysis, aligning with dimensional models of emotion where arousal and valence are continuous dimensions.",-,-,0.8575,-,0.64,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study focuses on emotion recognition using EDA, employs feature extraction and selection methods, and evaluates performance metrics for both arousal and valence dimensions."
161,2,10.1109/TAFFC.2019.2901673,"Shukla, J., Barreda-Ángeles, M., Oliver, J., Puig, D., & Nandi, G. C. (2019). Feature Extraction and Selection for Emotion Recognition from Electrodermal Activity. IEEE Transactions on Affective Computing, 12(4), 858-866.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,x,12580,x,"The authors found that MFCC statistical features, along with AUC and SMA features, were the most significant for emotion recognition. These findings support the use of EDA features beyond traditional SCR analysis, aligning with dimensional models of emotion where arousal and valence are continuous dimensions.",-,-,0.845,-,0.63,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study focuses on emotion recognition using EDA, employs feature extraction and selection methods, and evaluates performance metrics for both arousal and valence dimensions."
162,1,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.769,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,2,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.748,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,3,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.805,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,4,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.773,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,5,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,"GNB (no se si es Gaussian Naive Bayes o algo de boosted, y el paper no lo aclara)",-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.761,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,6,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,"GNB (no se si es Gaussian Naive Bayes o algo de boosted, y el paper no lo aclara)",-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.715,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,7,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.601,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,8,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.623,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,9,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.584,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
162,10,10.1109/TENSYMP54529.2022.9864492,"Chatterjee, D., Gavas, R., & Saha, S. K. (2022, July). Exploring skin conductance features for cross-subject emotion recognition. In 2022 IEEE Region 10 Symposium (TENSYMP) (pp. 1-6). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,2088,x,"The authors found that frequency domain features were significant for arousal, while time domain and entropy features were significant for valence. These findings align with the understanding that arousal is linked to rapid changes in EDA, while valence is associated with more stable tonic activity.",-,-,0.614,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses only EDA features for emotion recognition and presents unimodal models.
163,1,10.1145/3495002,"Tabbaa, L., Searle, R., Bafti, S. M., Hossain, M. M., Intarasisrisawat, J., Glancy, M., & Ang, C. S. (2021). Vreed: Virtual reality emotion recognition dataset using eye tracking & physiological measures. Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies, 5(4), 1-20.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The authors found that the GSR features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the relationship between GSR and emotional arousal. The high classification accuracy (87.5%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic GSR level was more informative for valence discrimination.",-,-,0.875,0.88,0.87,0.88,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,"The study uses GSR (EDA) along with ECG and eye tracking, but also presents models that use only EDA features."
163,2,10.1145/3495002,"Tabbaa, L., Searle, R., Bafti, S. M., Hossain, M. M., Intarasisrisawat, J., Glancy, M., & Ang, C. S. (2021). Vreed: Virtual reality emotion recognition dataset using eye tracking & physiological measures. Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies, 5(4), 1-20.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The authors found that the GSR features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the relationship between GSR and emotional arousal. The high classification accuracy (87.5%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic GSR level was more informative for valence discrimination.",-,-,0.5625,0.62,0.53,0.56,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,"The study uses GSR (EDA) along with ECG and eye tracking, but also presents models that use only EDA features."
163,3,10.1145/3495002,"Tabbaa, L., Searle, R., Bafti, S. M., Hossain, M. M., Intarasisrisawat, J., Glancy, M., & Ang, C. S. (2021). Vreed: Virtual reality emotion recognition dataset using eye tracking & physiological measures. Proceedings of the ACM on interactive, mobile, wearable and ubiquitous technologies, 5(4), 1-20.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,312,x,"The authors found that the GSR features were the most discriminative for distinguishing between high and low arousal states. They interpreted this finding based on the relationship between GSR and emotional arousal. The high classification accuracy (87.5%) for arousal using only these features supports this physiological interpretation. Additionally, they found that tonic GSR level was more informative for valence discrimination.",-,-,0.5313,0.53,0.52,0.53,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,Jero,,yes,include,"The study uses GSR (EDA) along with ECG and eye tracking, but also presents models that use only EDA features."
164,1,10.1049/ccs2.12107,"Zou, C., Deng, Z., He, B., Yan, M., Wu, J., & Zhu, Z. (2024). Emotion classification with multi‐modal physiological signals using multi‐attention‐based neural network. Cognitive Computation and Systems, 6(1-3), 1-11.",,Categorical,x,3,Neutral; Amusement; Stress,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The model uses attention mechanisms to focus on relevant features from multi-modal signals.,-,-,0.648,-,0.6767,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The paper uses EDA in combination with other signals but also evaluates EDA alone.
165,1,10.2478/joeb-2021-0021,"Jacobsen, F. A., Hafli, E. W., Tronstad, C., & Martinsen, Ø. G. (2021). Classification of emotions based on electrodermal activity and transfer learning-a pilot study. Journal of Electrical Bioimpedance, 12(1), 178.",,Categorical,x,3,Amusement; Disgust; Sadness,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.81,0.84,0.81,0.81,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The study focuses on emotion classification using electrodermal activity and transfer learning, indicating the use of EDA data."
165,2,10.2478/joeb-2021-0021,"Jacobsen, F. A., Hafli, E. W., Tronstad, C., & Martinsen, Ø. G. (2021). Classification of emotions based on electrodermal activity and transfer learning-a pilot study. Journal of Electrical Bioimpedance, 12(1), 178.",,Categorical,x,6,Anger; Amusement; Disgust; Fear; Sadness; Neutral,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.35,0.57,0.35,0.35,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The study focuses on emotion classification using electrodermal activity and transfer learning, indicating the use of EDA data."
166,1,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.644,-,0.783,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,2,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,x,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.651,-,0.788,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,3,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.671,-,0.803,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,4,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,High liking; Low liking,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.703,-,0.826,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,5,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HA; LA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.602,-,0.739,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,6,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.587,-,0.715,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,7,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.623,-,0.751,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,8,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,High liking; Low liking,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.679,-,0.805,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,9,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.631,-,0.773,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,10,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.64,-,0.78,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,11,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with SVM achieved the highest performance for arousal, valence, dominance, and liking. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.68,-,0.809,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
166,12,10.3389/fcomp.2023.1264713,"Gohumpu, J., Xue, M., & Bao, Y. (2023). Emotion recognition with multi-modal peripheral physiological signals. Frontiers in Computer Science, 5, 1264713.",,Dimensional,x,2,High liking; Low liking,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the combination of HRV and SKT signals with DT achieved the highest performance for dominance. They interpreted this finding based on the complementary information provided by different physiological signals, which enhances the accuracy of emotion recognition.",-,-,0.701,-,0.824,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA (GSR) along with other signals but also presents EDA-only models in the results.
167,1,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.595,-,0.714,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: CLAS,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,2,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress Stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.586,-,0.351,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: UTD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,3,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.691,-,0.669,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: VerBIO,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,4,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.691,-,0.554,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: WESAD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,5,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.685,-,0.801,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: CLAS,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,6,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.663,-,0.292,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: UTD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,7,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.929,-,0.879,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: VerBIO,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,8,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.752,-,0.614,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: WESAD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,9,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.635,-,0.744,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: CLAS,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,10,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.648,-,0.299,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: UTD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,11,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.679,-,0.602,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: VerBIO,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,12,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.712,-,0.447,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: WESAD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,13,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.666,-,0.799,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: CLAS,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,14,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.68,-,0.38,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: UTD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,15,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.877,-,0.84,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: VerBIO,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,16,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.781,-,0.637,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,db: WESAD,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,17,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.619,-,0.727,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,18,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.731,-,0.582,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,19,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.716,-,0.714,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
167,20,10.1109/JBHI.2023.3239305,"Zhu, L., Spachos, P., Ng, P. C., Yu, Y., Wang, Y., Plataniotis, K., & Hatzinakos, D. (2023). Stress detection through wrist-based electrodermal activity monitoring and machine learning. IEEE Journal of Biomedical and Health Informatics, 27(5), 2155-2165.",,Categorical,x,2,Stress; Non-stress,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,0.865,-,0.792,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,"The proposed system needs to be executable on smartphones and smartwatches so that simple machine learning methods are examined. Among the discussed methods, SVM achieved the highest accuracy of 92.9% in one of the datasets. Compared to other modalities, including PPG and ECG, and different combinations, EDA provides the highest accuracy in stress classification."
168,1,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.503,0.518,0.534,-,-,-,0.514,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
168,2,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.487,0.5094,0.534,-,-,-,0.469,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
168,3,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HV; LV,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.644,0.6002,0.562,-,-,-,0.509,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
168,4,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.511,0.5375,0.567,-,-,-,0.5,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
168,5,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HV; LV,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.618,0.5903,0.565,-,-,-,0.51,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
168,6,10.1142/S0219477522500134,"Veeranki, Y. R., Ganapathy, N., & Swaminathan, R. (2022). Analysis of fluctuation patterns in emotional states using electrodermal activity signals and improved symbolic aggregate approximation. Fluctuation and Noise Letters, 21(02), 2250013.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,0.575,0.5764,0.578,-,-,-,0.498,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The study uses EDA signals exclusively for emotion recognition and does not involve any clinical populations or multimodal models without EDA-only models.
169,1,10.1016/j.bspc.2024.106224,"Umair, M., Rashid, N., Khan, U. S., Hamza, A., & Iqbal, J. (2024). Emotion fusion-sense (Emo Fu-sense)–a novel multimodal emotion classification technique. Biomedical Signal Processing and Control, 94, 106224.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed technique utilizes multimodal data including GSR, EEG, ECG, respiration, and body temperature. The features extracted from GSR include amplitude statistics, time domain descriptors, and frequency domain characteristics. The model's performance is interpreted through the lens of the circumplex model of affect, focusing on arousal and valence dimensions.",-,-,0.29,0.145,0.165,0.2725,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses multiple modalities including GSR (EDA), but does not explicitly present models that use only EDA features."
169,2,10.1016/j.bspc.2024.106224,"Umair, M., Rashid, N., Khan, U. S., Hamza, A., & Iqbal, J. (2024). Emotion fusion-sense (Emo Fu-sense)–a novel multimodal emotion classification technique. Biomedical Signal Processing and Control, 94, 106224.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed technique utilizes multimodal data including GSR, EEG, ECG, respiration, and body temperature. The features extracted from GSR include amplitude statistics, time domain descriptors, and frequency domain characteristics. The model's performance is interpreted through the lens of the circumplex model of affect, focusing on arousal and valence dimensions.",-,-,0.29,0.145,0.165,0.2725,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses multiple modalities including GSR (EDA), but does not explicitly present models that use only EDA features."
169,3,10.1016/j.bspc.2024.106224,"Umair, M., Rashid, N., Khan, U. S., Hamza, A., & Iqbal, J. (2024). Emotion fusion-sense (Emo Fu-sense)–a novel multimodal emotion classification technique. Biomedical Signal Processing and Control, 94, 106224.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed technique utilizes multimodal data including GSR, EEG, ECG, respiration, and body temperature. The features extracted from GSR include amplitude statistics, time domain descriptors, and frequency domain characteristics. The model's performance is interpreted through the lens of the circumplex model of affect, focusing on arousal and valence dimensions.",-,-,0.27,0.2625,0.235,0.26,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses multiple modalities including GSR (EDA), but does not explicitly present models that use only EDA features."
169,4,10.1016/j.bspc.2024.106224,"Umair, M., Rashid, N., Khan, U. S., Hamza, A., & Iqbal, J. (2024). Emotion fusion-sense (Emo Fu-sense)–a novel multimodal emotion classification technique. Biomedical Signal Processing and Control, 94, 106224.",,Dimensional,x,4,HVHA; LVHA; LVLA; HVLA,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The proposed technique utilizes multimodal data including GSR, EEG, ECG, respiration, and body temperature. The features extracted from GSR include amplitude statistics, time domain descriptors, and frequency domain characteristics. The model's performance is interpreted through the lens of the circumplex model of affect, focusing on arousal and valence dimensions.",-,-,0.29,0.145,0.1875,0.27,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses multiple modalities including GSR (EDA), but does not explicitly present models that use only EDA features."
170,1,10.1109/TAFFC.2018.2884461,"Miranda-Correa, J. A., Khomami Abadi, M., Sebe, N., & Patras, I. (2017). AMIGOS: A dataset for affect, personality and mood research on individuals and groups. IEEE Transactions on Affective Computing.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.528,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The dataset consists of multimodal recordings of participants and their responses to emotional fragments of movies.
170,2,10.1109/TAFFC.2018.2884461,"Miranda-Correa, J. A., Khomami Abadi, M., Sebe, N., & Patras, I. (2017). AMIGOS: A dataset for affect, personality and mood research on individuals and groups. IEEE Transactions on Affective Computing.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.541,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The dataset consists of multimodal recordings of participants and their responses to emotional fragments of movies.
170,3,10.1109/TAFFC.2018.2884461,"Miranda-Correa, J. A., Khomami Abadi, M., Sebe, N., & Patras, I. (2017). AMIGOS: A dataset for affect, personality and mood research on individuals and groups. IEEE Transactions on Affective Computing.",,Dimensional,x,2,High positive affect; Low positive affect,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.649,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The dataset consists of multimodal recordings of participants and their responses to emotional fragments of movies.
170,4,10.1109/TAFFC.2018.2884461,"Miranda-Correa, J. A., Khomami Abadi, M., Sebe, N., & Patras, I. (2017). AMIGOS: A dataset for affect, personality and mood research on individuals and groups. IEEE Transactions on Affective Computing.",,Dimensional,x,2,High negative affect; Low negative affect,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,-,-,-,-,-,-,0.547,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Jero,,yes,include,The dataset consists of multimodal recordings of participants and their responses to emotional fragments of movies.
171,1,10.1109/BIBM58861.2023.10385273,"Singh, A., Wittenberg, T., Salman, M. M., Holzer, N., Göb, S., Pahl, J., ... & Sawant, S. (2023, December). Bio-Signal Based Multimodal Fusion with Bilinear Model for Emotion Recognition. In 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) (pp. 4834-4839). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.605,-,0.5878,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents an EDA-only model for emotion recognition.
171,2,10.1109/BIBM58861.2023.10385273,"Singh, A., Wittenberg, T., Salman, M. M., Holzer, N., Göb, S., Pahl, J., ... & Sawant, S. (2023, December). Bio-Signal Based Multimodal Fusion with Bilinear Model for Emotion Recognition. In 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) (pp. 4834-4839). IEEE.",,Dimensional,x,2,HV; LV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,,,-,-,0.6055,-,0.5813,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,The study uses EDA data and presents an EDA-only model for emotion recognition.
172,1,10.1109/BSN63547.2024.10780682,"Gahlan, N., Sethia, D., & Ray, S. B. (2024, October). Emotion Analysis Using Auditory ASMR via Physiological Signals and Federated Learning. In 2024 IEEE 20th International Conference on Body Sensor Networks (BSN) (pp. 1-4). IEEE.",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,The paper does not provide specific interpretations of the model's features in terms of underlying emotion theories or physiological mechanisms.,-,-,0.8612,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Tomi,,yes,include,"The paper uses EDA data, focuses on emotion prediction, and does not involve a clinical population or foreign language."
173,1,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HA; LA,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,0.6731,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Tomi,,yes,include,The study exclusively uses EDA data for emotion classification and presents performance metrics for EDA-only models.
173,2,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6551,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,3,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HA; LA,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7979,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,4,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HV; LV,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7171,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,5,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7815,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,6,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6801,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,7,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6998,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,8,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6718,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,9,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,3,Amusement; Neutral; Stress,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.958,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,10,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,3,Amusement; Neutral; Stress,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.984,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,11,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,3,Amusement; Neutral; Stress,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.9815,,,,,,,,,,,,,,,,,,,,,,yes,include,
173,12,10.1109/TIM.2024.3500058,"Kumar P, S., & Fredo Agastinose Ronickom, J. (2025). Emotion Classification Through Optimal Segments of EDA and Texture Analysis of Time-Encoded Images With Artificial Intelligence. IEEE Transactions on Instrumentation Measurement, 74, 3500058.",,Dimensional,x,3,Amusement; Neutral; Stress,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.9827,,,,,,,,,,,,,,,,,,,,,,yes,include,
174,1,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",,Dimensional,x,2,HA; LA,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Transformer,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,,,,,,,0.5506,,0.535,,,,,,,,,,,,,,,,,,Tomi,,yes,include,The study uses EDA data (GSR) as part of a multimodal approach but also evaluates unimodal models. The EmotionNet-Student model uses only GSR data for emotion recognition.
174,2,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,x,x,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.6918,,0.6833,,,,,,,,,,,,,,,,,,,,yes,include,
174,3,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",,Dimensional,x,2,HA; LA,,,,,,,,,,,,,,,,,x,x,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.5686,,0.5049,,,,,,,,,,,,,,,,,,,,yes,include,
174,4,10.1145/3581783.3612277,"Liu, Y., Jia, Z., & Wang, H. (2023, October). Emotionkd: a cross-modal knowledge distillation framework for emotion recognition based on physiological signals. In Proceedings of the 31st ACM International Conference on Multimedia (pp. 6122-6131).",,Dimensional,x,2,HV; LV,,,,,,,,,,,,,,,,,x,x,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.5956,,0.5781,,,,,,,,,,,,,,,,,,,,yes,include,
175,1,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,Transformer,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the EDA signals were more similar under different emotional states, making it difficult to intuitively judge the participant’s emotions. However, after processing with VMD and RM, the EDA signals achieved an accuracy of 86.96% in emotion recognition.",-,-,0.8696,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,"The study uses EDA data and presents models that use only EDA features as input, achieving an accuracy of 86.96%."
175,2,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8631,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,3,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8542,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,4,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Transformer,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8095,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,5,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7756,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,6,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7583,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,7,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.7435,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,8,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8452,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,9,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8512,,,,,,,,,,,,,,,,,,,,,,yes,include,
175,10,10.3390/electronics13153019,"Feng, G., Wang, H., Wang, M., Zheng, X., & Zhang, R. (2024). A Research on Emotion Recognition of the Elderly Based on Transformer and Physiological Signals. Electronics, 13(15), 3019.",,Dimensional,x,4,HAHV; HALV; LAHV; LALV,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.8214,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,1,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,2,HA; LA,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between calm and distress states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation.",-,-,0.804,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion prediction and meets all inclusion criteria.
176,2,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,2,HA; LA,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,-,x,"The authors found that the phasic EDA features (specifically SCR amplitude and rise time) were the most discriminative for distinguishing between calm and distress states. They interpreted this finding based on Boucsein's (2012) model of EDA, which links phasic activity to emotional arousal. The high classification accuracy (85%) for arousal using only these features supports this physiological interpretation.",-,-,0.739,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data exclusively for emotion prediction and meets all inclusion criteria.
176,3,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,2,HA; LA,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.71,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,4,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,2,HA; LA,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.68,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,5,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,3,HV; LV; Neutral,-,-,-,-,-,x,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.764,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,6,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,3,HV; LV; Neutral,-,x,-,-,-,-,-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.665,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,7,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,3,HV; LV; Neutral,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.629,,,,,,,,,,,,,,,,,,,,,,yes,include,
176,8,10.1109/TAFFC.2023.3315973,"Shui, X., Lin, R., Luo, Z., Lin, B., Mao, X., Li, H., ... & Zhang, D. (2023). Bodily electrodermal representations for affective computing. IEEE Transactions on Affective Computing, 15(3), 1018-1025.",,Dimensional,x,3,HV; LV; Neutral,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,0.652,,,,,,,,,,,,,,,,,,,,,,yes,include,
177,1,10.1109/HRI53351.2022.9889545,"Mohamed, Y., Ballardini, G., Parreira, M. T., Lemaignan, S., & Leite, I. (2022, March). Automatic frustration detection using thermal imaging. In 2022 17th ACM/IEEE International Conference on Human-Robot Interaction (HRI) (pp. 451-459). IEEE.",,Dimensional,x,2,Frustration; Non-frustration,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,x,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,,x,-,,x,"The authors found that phasic EDA features were most discriminative for distinguishing between calm and distress states. They related this to Boucsein's model of EDA, supporting the use of phasic activity for emotional classification.",-,-,0.84,-,0.78,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,{},Jero,,yes,include,The study uses EDA data and presents an EDA-only model for emotion prediction.
178,1,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,,,,,,,,,,,,,,Random Forest,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.48,,,0.33,,,,,,,Jero,,yes,include,
178,2,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,,,,,,,,,x,,,,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.464,,,0.344,,,,,,,Jero,,yes,include,
178,3,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,x,,,,,,,,,,,,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.41,,,0.36,,,,,,,Jero,,yes,include,
178,4,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,,,,,x,,,,,,,,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.51,,,0.41,,,,,,,Jero,,yes,include,
178,5,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,x,,,,,,,,,,,,,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.48,,,0.33,,,,,,,Jero,,yes,include,
178,6,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,,,,,,,,,,,,x,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.43,,,0.28,,,,,,,Jero,,yes,include,
178,6,10.3389/fpsyg.2023.1293513,"Başaran, O. T., Can, Y. S., André, E., & Ersoy, C. (2024). Relieving the burden of intensive labeling for stress monitoring in the wild by using semi-supervised learning. Frontiers in Psychology, 14, 1293513.",,Dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,Stress,,,,,,,,,,,x,,x,,,x,,332,,,x,https://github.com/basarantugay/ssl-stress-paper,,,,,,,,,,,0.41,,,0.25,,,,,,,Jero,,yes,include,
179,1,10.1145/3544793.3563427,"Alchieri, L., Abdalazim, N., Alecci, L., Gashi, S., Di Lascio, E., & Santini, S. (2022, September). On the impact of lateralization in physiological signals from wearable sensors. In Adjunct Proceedings of the 2022 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2022 ACM International Symposium on Wearable Computers (pp. 472-477).",,Categorical,x,2,Joy; Non-Joy,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,640,,,,,0.59,,,,,,,,,,,,,,,,,,,,Jero,,yes,include,
180,1,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,2,Stress; Non-stress,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,x,"The authors observed that higher‑frequency components are attenuated in stress segments and exploited this property by extracting frequency‑band features, noting that these spectra‑based features improved classification performance over time‑domain features.",,,0.8415,,0.8158,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,2,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8195,,0.7858,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,3,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8382,,0.8054,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,4,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8487,,0.8213,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,5,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8484,,0.8182,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,6,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8269,,0.8008,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,7,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8212,,0.7993,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
180,8,10.3390/s23020963,"Stržinar, Ž., Sanchis, A., Ledezma, A., Sipele, O., Pregelj, B., & Škrjanc, I. (2023). Stress detection using frequency spectrum analysis of wrist-measured electrodermal activity. Sensors, 23(2), 963.",,Dimensional,x,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.8386,,0.8029,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
181,1,10.1016/j.bspc.2021.102756,"Acevedo, C. M. D., Gómez, J. K. C., & Rojas, C. A. A. (2021). Academic stress detection on university students during COVID-19 outbreak by using an electronic nose and the galvanic skin response. Biomedical Signal Processing and Control, 68, 102756.",,Dimensional,x,2,Stress; Relaxation,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,1,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.711,,0.67,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,2,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HA; LA,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.7,,0.68,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,3,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.782,,0.74,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,4,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HA; LA,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.791,,0.75,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,5,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.653,,0.58,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,6,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HA; LA,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.646,,0.57,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,7,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HV; LV,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.697,,0.65,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
182,8,10.1109/ACII52823.2021.9597442,"Elalamy, R., Fanourakis, M., & Chanel, G. (2021, September). Multi-modal emotion recognition using recurrence plots and transfer learning on physiological signals. In 2021 9th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",,Dimensional,x,2,HA; LA,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Experimental results showed that recurrence plots can outperform spectrograms, especially when dealing with non‑periodic and non‑stationary signals such as EDA, thus validating our second hypothesis.",,,0.692,,0.63,,,,,,,,,,,,,,,,,,Tomi,,yes,include,
